[
{
	"uri": "/vi/4-logging-in-eks/4.1-control-plane-logs/4.1.1-configuring-control-plane-logs/",
	"title": "Control plane logs",
	"tags": [],
	"description": "",
	"content": "Configuring control plane logs Để kích hoạt các nhật ký điều khiển EKS được thực hiện trên mỗi cụm thông qua API EKS. Thông thường, điều này sẽ được cấu hình bằng Terraform hoặc CloudFormation, nhưng trong lab này chúng ta sẽ sử dụng AWS CLI để kích hoạt chức năng này:\naws eks update-cluster-config \\\r--region $AWS_REGION \\\r--name $EKS_CLUSTER_NAME \\\r--logging \u0026#39;{\u0026#34;clusterLogging\u0026#34;:[{\u0026#34;types\u0026#34;:[\u0026#34;api\u0026#34;,\u0026#34;audit\u0026#34;,\u0026#34;authenticator\u0026#34;,\u0026#34;controllerManager\u0026#34;,\u0026#34;scheduler\u0026#34;],\u0026#34;enabled\u0026#34;:true}]}\u0026#39;\rsleep 30\raws eks wait cluster-active --name $EKS_CLUSTER_NAME Như bạn có thể thấy, chúng ta có thể kích hoạt từng loại log của cluster một cách riêng biệt, và trong bài lab này, chúng ta đang kích hoạt tất cả mọi thứ.\nHãy xem cấu hình này trên bảng điều khiển EKS:\nhttps://console.aws.amazon.com/eks/home#/clusters/eks-workshop?selectedTab=cluster-logging-tab\nTab Logging hiển thị cấu hình hiện tại cho log của điều khiển cho cluster:\nBạn có thể điều chỉnh cấu hình ghi nhật ký bằng cách nhấp vào nút Quản lý: Manage\n"
},
{
	"uri": "/vi/4-logging-in-eks/4.1-control-plane-logs/",
	"title": "Control plane logs",
	"tags": [],
	"description": "",
	"content": "Control plane logs Chuẩn bị môi trường cho phần này:\nprepare-environment observability/logging/cluster Amazon EKS control plane logging cung cấp nhật ký kiểm tra và chẩn đoán trực tiếp từ bảng điều khiển Amazon EKS đến CloudWatch Logs trong tài khoản của bạn. Nhật ký này giúp bạn dễ dàng bảo mật và vận hành các cụm của mình. Bạn có thể chọn chính xác loại nhật ký bạn cần và nhật ký được gửi dưới dạng luồng nhật ký đến một nhóm cho mỗi cụm Amazon EKS trong CloudWatch.\nBạn có thể kích hoạt hoặc vô hiệu hóa mỗi loại nhật ký trên cơ sở từng cụm bằng cách sử dụng Bảng điều khiển Quản lý AWS, AWS CLI (phiên bản 1.16.139 trở lên) hoặc thông qua API Amazon EKS.\nKhi bạn sử dụng nhật ký điều khiển Amazon EKS, bạn sẽ bị tính phí theo giá cơ bản của Amazon EKS cho mỗi cụm bạn chạy cùng với các chi phí tiếp nhận và lưu trữ dữ liệu nhật ký CloudWatch thông thường cho bất kỳ nhật ký nào được gửi đến CloudWatch Logs từ các cụm của bạn.\nCác loại nhật ký điều khiển cụm sau đây có sẵn. Mỗi loại nhật ký tương ứng với một thành phần của bảng điều khiển Kubernetes. Để tìm hiểu thêm về các thành phần này, xem Các thành phần Kubernetes trong tài liệu Kubernetes.\nNhật ký thành phần máy chủ API Kubernetes (api) – Máy chủ API của cụm của bạn là thành phần bảng điều khiển mà tiếp xúc với API Kubernetes. Kiểm tra (audit) – Nhật ký kiểm tra Kubernetes cung cấp một bản ghi về các người dùng, quản trị viên hoặc các thành phần hệ thống cá nhân đã ảnh hưởng đến cụm của bạn. Xác thực viên (authenticator) – Nhật ký xác thực viên là duy nhất đối với Amazon EKS. Nhật ký này đại diện cho thành phần bảng điều khiển mà Amazon EKS sử dụng cho Xác thực dựa trên Vai trò (RBAC) của Kubernetes bằng cách sử dụng các thông tin xác thực IAM. Bộ điều khiển quản lý (controllerManager) – Bộ điều khiển quản lý quản lý các vòng lặp điều khiển cốt lõi được gửi kèm với Kubernetes. Lập lịch (scheduler) – Thành phần lập lịch quản lý khi nào và nơi chạy các pod trong cụm của bạn. "
},
{
	"uri": "/vi/1-introduce/1.1-monitor-cluster-components/",
	"title": "Giám sát Cluster Kubernetes",
	"tags": [],
	"description": "",
	"content": "Giám sát Cluster Kubernetes Trong phần này, chúng ta sẽ tìm hiểu về việc giám sát cluster Kubernetes.\nGiám sát Tiêu Thụ Tài Nguyên trong Kubernetes Làm thế nào bạn có thể giám sát việc tiêu thụ tài nguyên trong Kubernetes? Hoặc quan trọng hơn, bạn muốn giám sát những gì?\nHeapster vs Metrics Server Heapster hiện đã được loại bỏ và một phiên bản thu gọn hơn được hình thành được biết đến là metrics server.\nMetrics Server Làm thế nào các metric được tạo ra cho các POD trên các node này?\nMetrics Server - Bắt Đầu Sao chép metric server từ kho github\n$ git clone https://github.com/kubernetes-incubator/metrics-server.git Triển khai metric server\n$ kubectl create -f metric-server/deploy/1.8+/ Xem hiệu suất của cluster\n$ kubectl top node Xem các metric hiệu suất của pod\n$ kubectl top pod "
},
{
	"uri": "/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu Kubernetes là một nền tảng nguồn mở, khả chuyển, có thể mở rộng để quản lý các ứng dụng được đóng gói và các service, giúp thuận lợi trong việc cấu hình và tự động hoá việc triển khai ứng dụng. Kubernetes là một hệ sinh thái lớn và phát triển nhanh chóng. Các dịch vụ, sự hỗ trợ và công cụ có sẵn rộng rãi.\nTên gọi Kubernetes có nguồn gốc từ tiếng Hy Lạp, có ý nghĩa là người lái tàu hoặc hoa tiêu. Google mở mã nguồn Kubernetes từ năm 2014. Kubernetes xây dựng dựa trên một thập kỷ rưỡi kinh nghiệm mà Google có được với việc vận hành một khối lượng lớn workload trong thực tế, kết hợp với các ý tưởng và thực tiễn tốt nhất từ cộng đồng.\nQuay ngược thời gian Chúng ta hãy xem tại sao Kubernetes rất hữu ích bằng cách quay ngược thời gian.\nThời đại triển khai theo cách truyền thống: Ban đầu, các ứng dụng được chạy trên các máy chủ vật lý. Không có cách nào để xác định ranh giới tài nguyên cho các ứng dụng trong máy chủ vật lý và điều này gây ra sự cố phân bổ tài nguyên. Ví dụ, nếu nhiều ứng dụng cùng chạy trên một máy chủ vật lý, có thể có những trường hợp một ứng dụng sẽ chiếm phần lớn tài nguyên hơn và kết quả là các ứng dụng khác sẽ hoạt động kém đi. Một giải pháp cho điều này sẽ là chạy từng ứng dụng trên một máy chủ vật lý khác nhau. Nhưng giải pháp này không tối ưu vì tài nguyên không được sử dụng đúng mức và rất tốn kém cho các tổ chức để có thể duy trì nhiều máy chủ vật lý như vậy.\nThời đại triển khai ảo hóa: Như một giải pháp, ảo hóa đã được giới thiệu. Nó cho phép bạn chạy nhiều Máy ảo (VM) trên CPU của một máy chủ vật lý. Ảo hóa cho phép các ứng dụng được cô lập giữa các VM và cung cấp mức độ bảo mật vì thông tin của một ứng dụng không thể được truy cập tự do bởi một ứng dụng khác.\nẢo hóa cho phép sử dụng tốt hơn các tài nguyên trong một máy chủ vật lý và cho phép khả năng mở rộng tốt hơn vì một ứng dụng có thể được thêm hoặc cập nhật dễ dàng, giảm chi phí phần cứng và hơn thế nữa. Với ảo hóa, bạn có thể có một tập hợp các tài nguyên vật lý dưới dạng một cụm các máy ảo sẵn dùng.\nMỗi VM là một máy tính chạy tất cả các thành phần, bao gồm cả hệ điều hành riêng của nó, bên trên phần cứng được ảo hóa.\nThời đại triển khai Container: Các container tương tự như VM, nhưng chúng có tính cô lập để chia sẻ Hệ điều hành (HĐH) giữa các ứng dụng. Do đó, container được coi là nhẹ (lightweight). Tương tự như VM, một container có hệ thống tệp (filesystem), CPU, bộ nhớ, process space, v.v. Khi chúng được tách rời khỏi cơ sở hạ tầng bên dưới, chúng có thể khả chuyển (portable) trên cloud hoặc các bản phân phối Hệ điều hành.\nCác container đã trở nên phổ biến vì chúng có thêm nhiều lợi ích, chẳng hạn như:\nTạo mới và triển khai ứng dụng Agile: gia tăng tính dễ dàng và hiệu quả của việc tạo các container image so với việc sử dụng VM image. Phát triển, tích hợp và triển khai liên tục: cung cấp khả năng build và triển khai container image thường xuyên và đáng tin cậy với việc rollbacks dễ dàng, nhanh chóng. Phân biệt giữa Dev và Ops: tạo các images của các application container tại thời điểm build/release thay vì thời gian triển khai, do đó phân tách các ứng dụng khỏi hạ tầng. Khả năng quan sát không chỉ hiển thị thông tin và các metric ở mức Hệ điều hành, mà còn cả application health và các tín hiệu khác. Tính nhất quán về môi trường trong suốt quá trình phát triển, testing và trong production: Chạy tương tự trên laptop như trên cloud. Tính khả chuyển trên cloud và các bản phân phối HĐH: Chạy trên Ubuntu, RHEL, CoreOS, on-premises, Google Kubernetes Engine và bất kì nơi nào khác. Quản lý tập trung ứng dụng: Tăng mức độ trừu tượng từ việc chạy một Hệ điều hành trên phần cứng ảo hóa sang chạy một ứng dụng trên một HĐH bằng logical resources. Các micro-services phân tán, elastic: ứng dụng được phân tách thành các phần nhỏ hơn, độc lập và thể được triển khai và quản lý một cách linh hoạt - chứ không phải một app nguyên khối (monolithic). Cô lập các tài nguyên: dự đoán hiệu năng ứng dụng Sử dụng tài nguyên: hiệu quả Tại sao bạn cần Kubernetes và nó có thể làm những gì? Các container là một cách tốt để đóng gói và chạy các ứng dụng của bạn. Trong môi trường production, bạn cần quản lý các container chạy các ứng dụng và đảm bảo rằng không có khoảng thời gian downtime. Ví dụ, nếu một container bị tắt đi, một container khác cần phải khởi động lên. Điều này sẽ dễ dàng hơn nếu được xử lý bởi một hệ thống.\nĐó là cách Kubernetes đến với chúng ta. Kubernetes cung cấp cho bạn một framework để chạy các hệ phân tán một cách mạnh mẽ. Nó đảm nhiệm việc nhân rộng và chuyển đổi dự phòng cho ứng dụng của bạn, cung cấp các mẫu deployment và hơn thế nữa. Ví dụ, Kubernetes có thể dễ dàng quản lý một triển khai canary cho hệ thống của bạn.\nKubernetes cung cấp cho bạn:\nService discovery và cân bằng tải\nKubernetes có thể expose một container sử dụng DNS hoặc địa chỉ IP của riêng nó. Nếu lượng traffic truy cập đến một container cao, Kubernetes có thể cân bằng tải và phân phối lưu lượng mạng (network traffic) để việc triển khai được ổn định. Điều phối bộ nhớ\nKubernetes cho phép bạn tự động mount một hệ thống lưu trữ mà bạn chọn, như local storages, public cloud providers, v.v. Tự động rollouts và rollbacks\nBạn có thể mô tả trạng thái mong muốn cho các container được triển khai dùng Kubernetes và nó có thể thay đổi trạng thái thực tế sang trạng thái mong muốn với tần suất được kiểm soát. Ví dụ, bạn có thể tự động hoá Kubernetes để tạo mới các container cho việc triển khai của bạn, xoá các container hiện có và áp dụng tất cả các resource của chúng vào container mới. Đóng gói tự động\nBạn cung cấp cho Kubernetes một cluster gồm các node mà nó có thể sử dụng để chạy các tác vụ được đóng gói (containerized task). Bạn cho Kubernetes biết mỗi container cần bao nhiêu CPU và bộ nhớ (RAM). Kubernetes có thể điều phối các container đến các node để tận dụng tốt nhất các resource của bạn. Tự phục hồi\nKubernetes khởi động lại các containers bị lỗi, thay thế các container, xoá các container không phản hồi lại cấu hình health check do người dùng xác định và không cho các client biết đến chúng cho đến khi chúng sẵn sàng hoạt động. Quản lý cấu hình và bảo mật\nKubernetes cho phép bạn lưu trữ và quản lý các thông tin nhạy cảm như: password, OAuth token và SSH key. Bạn có thể triển khai và cập nhật lại secret và cấu hình ứng dụng mà không cần build lại các container image và không để lộ secret trong cấu hình stack của bạn. Kubernetes không phải là gì? Kubernetes không phải là một hệ thống PaaS (Nền tảng như một Dịch vụ) truyền thống, toàn diện. Do Kubernetes hoạt động ở tầng container chứ không phải ở tầng phần cứng, nó cung cấp một số tính năng thường áp dụng chung cho các dịch vụ PaaS, như triển khai, nhân rộng, cân bằng tải, ghi nhật ký và giám sát. Tuy nhiên, Kubernetes không phải là cấu trúc nguyên khối và các giải pháp mặc định này là tùy chọn và có thể cắm được (pluggable).\nKubernetes:\nKhông giới hạn các loại ứng dụng được hỗ trợ. Kubernetes nhằm mục đích hỗ trợ một khối lượng công việc cực kỳ đa dạng, bao gồm cả stateless, stateful và xử lý dữ liệu. Nếu một ứng dụng có thể chạy trong một container, nó sẽ chạy rất tốt trên Kubernetes. Không triển khai mã nguồn và không build ứng dụng của bạn. Quy trình CI/CD được xác định bởi tổ chức cũng như các yêu cầu kỹ thuật. Không cung cấp các service ở mức ứng dụng, như middleware (ví dụ, các message buses), các framework xử lý dữ liệu (ví dụ, Spark), cơ sở dữ liệu (ví dụ, MySQL), bộ nhớ cache, cũng như hệ thống lưu trữ của cluster (ví dụ, Ceph). Các thành phần như vậy có thể chạy trên Kubernetes và/hoặc có thể được truy cập bởi các ứng dụng chạy trên Kubernetes thông qua các cơ chế di động, chẳng hạn như Open Service Broker. Không bắt buộc các giải pháp ghi lại nhật ký (logging), giám sát (monitoring) hoặc cảnh báo (alerting). Nó cung cấp một số sự tích hợp như proof-of-concept, và cơ chế để thu thập và xuất các số liệu. Không cung cấp, không bắt buộc một cấu hình ngôn ngữ/hệ thống (ví dụ: Jsonnet). Nó cung cấp một API khai báo có thể được targeted bởi các hình thức khai báo tùy ý. Không cung cấp cũng như áp dụng bất kỳ cấu hình toàn diện, bảo trì, quản lý hoặc hệ thống tự phục hồi. Ngoài ra, Kubernetes không phải là một hệ thống điều phối đơn thuần. Trong thực tế, nó loại bỏ sự cần thiết của việc điều phối. Định nghĩa kỹ thuật của điều phối là việc thực thi một quy trình công việc được xác định: đầu tiên làm việc A, sau đó là B rồi sau chót là C. Ngược lại, Kubernetes bao gồm một tập các quy trình kiểm soát độc lập, có thể kết hợp, liên tục điều khiển trạng thái hiện tại theo trạng thái mong muốn đã cho. Nó không phải là vấn đề làm thế nào bạn có thể đi được từ A đến C. Kiểm soát tập trung cũng không bắt buộc. Điều này dẫn đến một hệ thống dễ sử dụng hơn, mạnh mẽ hơn, linh hoạt hơn và có thể mở rộng. "
},
{
	"uri": "/vi/",
	"title": "Kubernetes trên AWS",
	"tags": [],
	"description": "",
	"content": "Kubernetes trên AWS Kubernetes là một nền tảng mã nguồn mở, linh hoạt, có khả năng mở rộng, phục vụ việc quản lý các ứng dụng được đóng gói và các dịch vụ liên quan, giúp việc cấu hình và tự động hóa quá trình triển khai ứng dụng trở nên thuận tiện hơn. Được biết đến như một hệ sinh thái lớn và phát triển nhanh chóng, Kubernetes cung cấp sự hỗ trợ rộng rãi qua các dịch vụ và công cụ đa dạng.\nTên Kubernetes bắt nguồn từ tiếng Hy Lạp, nghĩa là người lái tàu hoặc hoa tiêu. Kubernetes được Google công bố mã nguồn vào năm 2014, dựa trên gần một thập kỷ kinh nghiệm quản lý workload lớn trong thực tế của Google, kết hợp với các ý tưởng và best practices từ cộng đồng.\nQuay ngược thời gian Hãy xem xét tại sao Kubernetes lại quan trọng thông qua việc nhìn lại quá khứ.\nThời kỳ triển khai truyền thống: Ban đầu, các ứng dụng được chạy trực tiếp trên máy chủ vật lý, khiến việc phân bổ tài nguyên gặp khó khăn do không có cơ chế xác định ranh giới tài nguyên cho từng ứng dụng. Cách tiếp cận này dẫn đến nguy cơ một ứng dụng có thể sử dụng quá nhiều tài nguyên, ảnh hưởng đến hoạt động của các ứng dụng khác. Giải pháp là chạy mỗi ứng dụng trên một máy chủ vật lý riêng biệt, nhưng điều này lại không hiệu quả về mặt chi phí và tài nguyên.\nThời kỳ triển khai ảo hóa: Ảo hóa được giới thiệu như một giải pháp cho phép chạy nhiều Máy ảo (VM) trên cùng một máy chủ vật lý, giúp cô lập ứng dụng và tăng cường bảo mật. Ảo hóa cũng giúp cải thiện hiệu quả sử dụng tài nguyên và khả năng mở rộng.\nThời kỳ triển khai Container: Container giống như VM nhưng nhẹ hơn và chia sẻ Hệ điều hành (HĐH) với nhau. Container mang lại nhiều lợi ích như tạo mới và triển khai ứng dụng nhanh chóng, phát triển và triển khai liên tục, phân biệt rõ ràng giữa quá trình phát triển và vận hành, cung cấp tính nhất quán qua các môi trường, khả năng di chuyển giữa các cloud và HĐH, và quản lý ứng dụng tập trung.\nTại sao bạn cần Kubernetes và nó có thể làm gì? Container là phương tiện hiệu quả để đóng gói và chạy ứng dụng của bạn. Trong môi trường sản xuất, cần có cơ chế quản lý các container một cách hiệu quả, đảm bảo không có downtime. Kubernetes giúp quản lý các hệ thống phân tán mạnh mẽ, tự động hóa việc nhân rộng, cung cấp các mẫu triển khai và nhiều hơn nữa.\nKubernetes mang lại:\nPhát hiện dịch vụ và cân bằng tải Điều phối bộ nhớ Tự động rollouts và rollbacks Đóng gói tự động Tự phục hồi Quản lý cấu hình và bảo mật Những gì Kubernetes không phải là Kubernetes không phải là một hệ thống PaaS truyền thống, toàn diện. Nó hoạt động ở tầng container, cung cấp tính năng giống như PaaS như triển khai, nhân rộng, cân bằng tải, nhưng là một giải pháp linh hoạt và có thể mở rộng, không giới hạn loại ứng dụng được hỗ trợ, không triển khai mã nguồn hoặc build ứng dụng, không cung cấp dịch vụ ứng dụng cấp cao như middleware, databases, không bắt buộc sử dụng các giải pháp ghi nhật ký, giám sát hoặc cảnh báo, và không cung cấp hoặc áp dụng bất kỳ cấu hình toàn diện, bảo trì, quản lý hoặc hệ thống tự phục hồi. Kubernetes loại bỏ nhu cầu về điều phối truyền thống, thay vào đó là kiểm soát liên tục từ trạng thái hiện tại sang trạng thái mong muốn.\n"
},
{
	"uri": "/vi/5-eks-open-source-observability/5.1-aws-distro/",
	"title": "Scraping metrics sử dụng AWS Distro cho OpenTelemetry",
	"tags": [],
	"description": "",
	"content": "Scraping metrics sử dụng AWS Distro cho OpenTelemetry Trong thí nghiệm này, chúng ta sẽ lưu trữ các metric trong một không gian làm việc Amazon Managed Service for Prometheus đã được tạo sẵn cho bạn. Bạn có thể thấy nó trong bảng điều khiển:\nhttps://console.aws.amazon.com/prometheus/home#/workspaces\nĐể xem không gian làm việc, nhấp vào tab All Workspaces trên bảng điều khiển bên trái. Chọn không gian làm việc bắt đầu bằng eks-workshop và bạn có thể xem một số tab khác nhau dưới không gian làm việc như quản lý luật, quản lý cảnh báo, v.v.\nĐể thu thập các metric từ Cụm Amazon EKS, chúng ta sẽ triển khai một tài nguyên tùy chỉnh OpenTelemetryCollector. Toán tử ADOT chạy trên cụm EKS phát hiện sự hiện diện hoặc thay đổi của tài nguyên này và cho bất kỳ thay đổi nào như vậy, toán tử thực hiện các hành động sau:\nXác minh rằng tất cả các kết nối cần thiết cho các yêu cầu tạo, cập nhật hoặc xóa này đến máy chủ API Kubernetes có sẵn. Triển khai các phiên bản thu thập ADOT theo cách mà người dùng đã biểu diễn trong cấu hình tài nguyên OpenTelemetryCollector. Bây giờ, hãy tạo tài nguyên để cho phép bộ thu ADOT các quyền mà nó cần. Chúng ta sẽ bắt đầu bằng ClusterRole mà cung cấp các quyền cho bộ thu truy cập vào API Kubernetes:\n~/environment/eks-workshop/modules/observability/oss-metrics/adot/clusterrole.yaml\napiVersion: rbac.authorization.k8s.io/v1\rkind: ClusterRole\rmetadata:\rname: otel-prometheus-role\rrules:\r- apiGroups:\r- \u0026#34;\u0026#34;\rresources:\r- nodes\r- nodes/proxy\r- services\r- endpoints\r- pods\rverbs:\r- get\r- list\r- watch\r- apiGroups:\r- extensions\rresources:\r- ingresses\rverbs:\r- get\r- list\r- watch\r- nonResourceURLs:\r- /metrics\rverbs:\r- get Chúng ta sẽ sử dụng chính sách IAM quản lý AmazonPrometheusRemoteWriteAccess để cung cấp cho bộ thu thập quyền IAM mà nó cần thông qua IAM Roles for Service Accounts:\naws iam list-attached-role-policies \\\r--role-name $EKS_CLUSTER_NAME-adot-collector | jq . IAM role này sẽ được thêm vào ServiceAccount cho collector:\n~/environment/eks-workshop/modules/observability/oss-metrics/adot/serviceaccount.yaml\napiVersion: v1\rkind: ServiceAccount\rmetadata:\rname: adot-collector\rannotations:\reks.amazonaws.com/role-arn: ${ADOT_IAM_ROLE} Tạo các tài nguyên:\nkubectl kustomize ~/environment/eks-workshop/modules/observability/oss-metrics/adot \\\r| envsubst | kubectl apply -f-\rkubectl rollout status -n other deployment/adot-collector --timeout=120s Thông số kỹ thuật cho bộ thu là quá dài để hiển thị ở đây, nhưng bạn có thể xem nó như sau:\nkubectl -n other get opentelemetrycollector adot -o yaml Hãy phân tích thành các phần để hiểu rõ hơn về những gì đã được triển khai. Đây là cấu hình của bộ thu thập OpenTelemetry:\nkubectl -n other get opentelemetrycollector adot -o jsonpath=\u0026#39;{.spec.config}\u0026#39; | yq Dưới đây là cấu hình một OpenTelemetry pipeline với cấu trúc sau:\nReceivers\nPrometheus receiver: được thiết kế để thu thập số liệu từ các mục tiêu mà mở ra một điểm cuối Prometheus.\nProcessors\nKhông có trong ống dẫn này.\nExporters\nPrometheus remote write exporter: gửi số liệu tới một điểm cuối ghi xa Prometheus như AMP.\nCollector này cũng được cấu hình để chạy như một Deployment với một đại diện của bộ thu thập đang chạy.\nkubectl -n other get opentelemetrycollector adot -o jsonpath=\u0026#39;{.spec.mode}{\u0026#34;\\n\u0026#34;}\u0026#39; Chúng ta có thể xác nhận điều này bằng cách kiểm tra các Pods thu thập ADOT đang chạy:\nkubectl get pods -n other "
},
{
	"uri": "/vi/4-logging-in-eks/4.2-pod-logging/4.2.1-using-fluent-bit/",
	"title": "Using Fluent Bit",
	"tags": [],
	"description": "",
	"content": "Sử dụng Fluent Bit Đối với các thành phần của cụm Kubernetes chạy trong các pod, chúng ghi vào các tệp trong thư mục /var/log, bỏ qua cơ chế ghi nhật ký mặc định. Chúng ta có thể triển khai ghi nhật ký ở mức pod bằng cách triển khai một đại diện ghi nhật ký ở mức nút dưới dạng DaemonSet trên mỗi nút, chẳng hạn như Fluent Bit.\nFluent Bit là một trình xử lý nhật ký nhẹ và chuyển tiếp cho phép bạn thu thập dữ liệu và nhật ký từ các nguồn khác nhau, làm phong phú chúng bằng bộ lọc và gửi chúng đến nhiều địa điểm như CloudWatch, Kinesis Data Firehose, Kinesis Data Streams và Dịch vụ Amazon OpenSearch.\nAWS cung cấp một hình ảnh Fluent Bit với các plugin cho cả CloudWatch Logs và Kinesis Data Firehose. Hình ảnh AWS cho Fluent Bit có sẵn trên Amazon ECR Public Gallery.\nTrong phần tiếp theo, bạn sẽ thấy cách xác nhận rằng đại diện Fluent Bit đang chạy như một DaemonSet để gửi nhật ký của các container/pod đến CloudWatch Logs.\nTrước tiên, chúng ta có thể xác nhận các tài nguyên được tạo cho Fluent Bit bằng cách nhập lệnh sau. Mỗi nút nên có một pod:\nkubectl get all -n aws-for-fluent-bit ConfigMap cho aws-for-fluent-bit được cấu hình để stream nội dung của các tệp trong thư mục /var/log/containers/*.log từ mỗi node đến nhóm log CloudWatch /eks-workshop/worker-fluentbit-logs:\nkubectl describe configmaps -n aws-for-fluent-bit "
},
{
	"uri": "/vi/3-view-resources-in-eks-console/3.1-workloads/",
	"title": "Workloads",
	"tags": [],
	"description": "",
	"content": "Để xem các tài nguyên Kubernetes, nhấp vào tab Resources. Tiến sâu vào phần Workload và bạn có thể xem một số loại tài nguyên API Kubernetes nằm trong phần công việc. Công việc bao gồm các container đang chạy trong cụm của bạn, và bao gồm Pods, ReplicaSets, Deployments, và DaemonSets. Đây là các khối cơ bản cho việc chạy các container trong một cụm.\nWorkloads Pods Pods resource view hiển thị tất cả các pods đại diện cho đối tượng Kubernetes nhỏ nhất và đơn giản nhất.\nMặc định, tất cả các loại tài nguyên API Kubernetes được hiển thị, nhưng bạn có thể lọc theo namespace hoặc tìm kiếm các giá trị cụ thể để nhanh chóng tìm thấy điều bạn đang tìm kiếm. Dưới đây, bạn sẽ thấy các pods được lọc theo namespace=catalog. Xem tài nguyên cho tất cả các loại tài nguyên API Kubernetes, cung cấp hai chế độ xem - cấu trúc và raw. Chế độ xem cấu trúc cung cấp một biểu diễn hình ảnh của tài nguyên để giúp truy cập dữ liệu cho tài nguyên. Trong ví dụ này (dưới đây), bạn có thể thấy một chế độ xem cấu trúc cho pod catalog phân chia thông tin pod thành các phần Info, Containers, Labels và Annotations. Nó cũng mô tả replicaset, namespace và node liên quan. Chế độ xem raw hiển thị đầu ra JSON đầy đủ từ API Kubernetes, có ích để hiểu cấu hình và trạng thái của các loại tài nguyên không có sự hỗ trợ xem cấu trúc trong bảng điều khiển Amazon EKS. Trong ví dụ xem raw, chúng tôi hiển thị chế độ xem raw cho pod catalog. ReplicaSets Một ReplicaSet là một đối tượng Kubernetes đảm bảo một tập hợp ổn định các replica pods luôn chạy. Do đó, nó thường được sử dụng để đảm bảo sẵn có một số lượng xác định các pods giống nhau. Trong ví dụ này (dưới đây), bạn có thể thấy 2 replicasets cho namespace orders. ReplicaSet cho orders-d6b4566fc xác định cấu hình cho số lượng pods mong muốn và hiện tại.\nNhấp vào replicaset orders-d6b4566fc và khám phá cấu hình. Bạn sẽ thấy các cấu hình dưới Info, Pods, nhãn và chi tiết của replica tối đa và mong muốn.\nDaemonSet DaemonSet đảm bảo rằng tất cả (hoặc một số) Nodes chạy một bản sao của một pod. Trong ứng dụng mẫu, chúng ta có DaemonSet chạy trên mỗi node như được hiển thị (dưới đây).\nNhấp vào daemonset kube-proxy và khám phá cấu hình. Bạn sẽ thấy các cấu hình dưới phần Thông tin, các pod đang chạy trên mỗi node, nhãn và chú thích.\nDeployments Deployment là một đối tượng Kubernetes cung cấp cập nhật theo cách tuyên bố cho các pods và replicaSets. Nó cho biết Kubernetes cách tạo ra hoặc sửa đổi các phiên bản của pods. Các Deployment giúp tự động mở rộng số lượng replica pods và cho phép triển khai hoặc quay lại phiên bản triển khai một cách kiểm soát. Trong ví dụ này (dưới đây), bạn có thể thấy 2 deployments cho namespace carts.\nNhấp vào deployment orders và khám phá cấu hình. Bạn sẽ thấy chiến lược triển khai dưới mục Thông tin, chi tiết pod dưới mục Pods, các nhãn và phiên bản triển khai.\n"
},
{
	"uri": "/vi/2-prerequiste/",
	"title": "Các Bước Chuẩn Bị",
	"tags": [],
	"description": "",
	"content": "Các Bước Chuẩn Bị Chúng ta sẽ tạo một môi trường Cloud9 để thực hiện workshop.\nMọi người có thể tham khảo bài lab này để tạo Cloud9.\n"
},
{
	"uri": "/vi/3-view-resources-in-eks-console/3.2-cluster/",
	"title": "Cluster",
	"tags": [],
	"description": "",
	"content": "Cluster Để xem tài nguyên của cụm Kubernetes, nhấp vào tab Resources. Tiếp tục vào phần Cluster và bạn có thể xem nhiều loại tài nguyên API Kubernetes mà là một phần của cụm. Chi tiết xem cụm hiển thị tất cả các thành phần của kiến trúc cụm như Nodes, Namespaces và API Services chạy các công việc.\nNodes Kubernetes chạy công việc của bạn bằng cách đặt các container vào các pod để chạy trên các Node. Một node có thể là máy ảo hoặc máy vật lý, tùy thuộc vào cụm. eks-workshop đang chạy 3 node mà trên đó các công việc được triển khai. Nhấp vào Nodes để liệt kê các node.\nNếu bạn nhấp vào bất kỳ tên node nào, bạn sẽ tìm thấy phần Thông tin có rất nhiều chi tiết về node - hệ điều hành, container runtime, loại instance, EC2 instance và Managed node group (giúp việc cung cấp khả năng tính toán cho cụm trở nên dễ dàng). Phần tiếp theo, Phân bổ dung lượng, hiển thị việc sử dụng và đặt hàng của các tài nguyên khác nhau trên các node worker EC2 được kết nối vào cụm.\nPhần tiếp theo, Pods, mô tả tất cả các pod được triển khai trên node. Trong ví dụ này, có 12 pod đang chạy trên node này.\nPhần tiếp theo mô tả bất kỳ Taints, nhãn và chú thích nào có liên quan.\nNamespaces Namespaces là một cơ chế để tổ chức các cụm (clusters), có thể rất hữu ích khi các nhóm hoặc dự án khác nhau chia sẻ một cụm Kubernetes. Trong ứng dụng mẫu của chúng ta, chúng ta có các dịch vụ nhỏ - carts, checkout, catalog, assets mà tất cả đều chia sẻ cùng một cụm sử dụng cấu trúc namespace.\n"
},
{
	"uri": "/vi/5-eks-open-source-observability/5.2-storing-metrics-with-amp/",
	"title": "Lưu trữ số liệu với AMP",
	"tags": [],
	"description": "",
	"content": "Lưu trữ số liệu với AMP Một không gian làm việc Amazon Managed Service for Prometheus đã được tạo sẵn cho bạn. Bạn có thể xem nó trong bảng điều khiển tại đây:\nhttps://console.aws.amazon.com/prometheus/home#/workspaces\nĐể xem không gian làm việc, hãy nhấp vào tab Tất cả các Không gian làm việc ở bảng điều khiển điều khiển bên trái. Chọn không gian làm việc bắt đầu bằng eks-workshop và bạn có thể xem nhiều tab khác nhau dưới không gian làm việc như quản lý quy tắc, quản lý cảnh báo, v.v.\nHãy xác nhận việc chúng ta đã thành công trong việc nhập các số liệu:\nawscurl -X POST --region $AWS_REGION --service aps \u0026#34;${AMP_ENDPOINT}api/v1/query?query=up\u0026#34; | jq \u0026#39;.data.result[1]\u0026#39; "
},
{
	"uri": "/vi/1-introduce/1.2-managing-application-logs/",
	"title": "Managing Application Logs",
	"tags": [],
	"description": "",
	"content": "Bắt đầu với logging trong Docker:\nLogs - Kubernetes\rapiVersion: v1\rkind: Pod\rmetadata:\rname: event-simulator-pod\rspec:\rcontainers:\r- name: event-simulator\rimage: kodekloud/event-simulator Để xem logs:\n$ kubectl logs -f event-simulator-pod Nếu có nhiều containers trong một pod, bạn phải chỉ định tên của container một cách rõ ràng trong lệnh.\n$ kubectl logs -f \u0026lt;pod-name\u0026gt; \u0026lt;container-name\u0026gt;\r$ kubectl logs -f even-simulator-pod event-simulator K8s Reference Docs https://kubernetes.io/blog/2015/06/cluster-level-logging-with-kubernetes/\n"
},
{
	"uri": "/vi/4-logging-in-eks/4.2-pod-logging/",
	"title": "Pod logging",
	"tags": [],
	"description": "",
	"content": "Chuẩn bị môi trường cho phần này:\nprepare-environment observability/logging/pods Lệnh này sẽ thực hiện các thay đổi sau vào môi trường lab của bạn:\nCài đặt AWS cho Fluent Bit trong cụm Amazon EKS Bạn có thể xem Terraform áp dụng các thay đổi này ở đây. Theo nguyên tắc Twelve-Factor App manifesto, cung cấp tiêu chuẩn vàng cho việc thiết kế các ứng dụng hiện đại, các ứng dụng container nên đầu ra log của chúng ra stdout và stderr. Điều này cũng được coi là thực hành tốt nhất trong Kubernetes và các hệ thống thu thập log cấp cụm được xây dựng dựa trên tiền đề này.\nKiến trúc ghi log của Kubernetes xác định ba cấp độ phân biệt:\nGhi log cấp cơ bản: khả năng lấy log của các pod bằng cách sử dụng kubectl (ví dụ: kubectl logs myapp - trong đó myapp là một pod đang chạy trong cụm của tôi) Ghi log cấp node: Bộ máy container ghi lại log từ stdout và stderr của ứng dụng, và ghi chúng vào một tập tin log. Ghi log cấp cụm: Xây dựng trên cơ sở ghi log cấp node; một đại diện ghi log chạy trên mỗi node. Đại diện này thu thập log trên hệ thống tệp cục bộ và gửi chúng đến một đích ghi log tập trung như Elasticsearch hoặc CloudWatch. Đại diện thu thập hai loại log: Log của container được ghi lại bởi bộ máy container trên node. Log hệ thống. Kubernetes, mặc định, không cung cấp một giải pháp tự nhiên để thu thập và lưu trữ log. Nó cấu hình runtime của container để lưu log dưới định dạng JSON trên hệ thống tệp cục bộ. Runtime của container - như Docker - chuyển hướng luồng stdout và stderr của container sang một trình điều khiển ghi log. Trong Kubernetes, log của container được ghi vào /var/log/pods/*.log trên node. Kubelet và runtime của container ghi log của chúng vào /var/logs hoặc vào journald, trong các hệ điều hành có systemd. Sau đó, các hệ thống thu thập log trên toàn cụm như Fluentd có thể theo dõi các tệp log này trên node và gửi log để lưu trữ. Các hệ thống thu thập log này thường chạy như DaemonSets trên các node worker.\nTrong lab này, chúng tôi sẽ chỉ ra cách một đại diện ghi log có thể được thiết lập để thu thập log từ các node trong EKS và gửi chúng đến CloudWatch Logs.\n"
},
{
	"uri": "/vi/4-logging-in-eks/4.2-pod-logging/4.2.2-verify-the-logs-in-cloudwatch/",
	"title": "Verify the logs in CloudWatch",
	"tags": [],
	"description": "",
	"content": "Verify the logs in CloudWatch Trong bài thực hành này, chúng ta sẽ tìm hiểu cách kiểm tra các nhật ký pod Kubernetes được chuyển tiếp bởi Fluent Bit agent triển khai trên mỗi nút tới Amazon CloudWatch Logs. Các thành phần ứng dụng đã triển khai ghi lại nhật ký vào stdout, được lưu trữ trong đường dẫn /var/log/containers/*.log trên mỗi nút.\nĐầu tiên, hãy tái sử dụng các pod cho thành phần ui để đảm bảo nhật ký mới được ghi từ khi chúng ta bật Fluent Bit:\nkubectl delete pod -n ui --all\rkubectl rollout status deployment/ui \\\r-n ui --timeout 30s Bây giờ chúng ta có thể kiểm tra rằng thành phần giao diện người dùng của chúng ta đang tạo ra các nhật ký bằng cách sử dụng trực tiếp kubectl logs:\nkubectl logs -n ui deployment/ui Mở Console CloudWatch Logs để kiểm tra các log này xuất hiện:\nhttps://console.aws.amazon.com/cloudwatch/home?#logsV2:log-groups\nLọc cho fluentbit-cloudwatch để tìm các nhóm log được tạo bởi Fluent Bit:\nChọn /aws/eks/fluentbit-cloudwatch/workload/ui để xem các luồng log, mỗi luồng tương ứng với một pod cá nhân:\nBạn có thể mở rộng một trong các mục log để xem toàn bộ dữ liệu JSON đầy đủ:\n"
},
{
	"uri": "/vi/4-logging-in-eks/4.1-control-plane-logs/4.1.2-viewing-in-cloudwatch/",
	"title": "Viewing in CloudWatch",
	"tags": [],
	"description": "",
	"content": "Viewing in CloudWatch Hãy xem các logs trong bảng điều khiển CloudWatch Logs:\nhttps://console.aws.amazon.com/cloudwatch/home?#logsV2:log-groups\nLọc cho tiền tố /aws/eks và chọn cluster mà bạn muốn kiểm tra logs:\nBạn sẽ thấy một số luồng log trong nhóm:\nChọn bất kỳ luồng log nào để xem các mục được gửi đến CloudWatch Logs bởi EKS control plane.\n"
},
{
	"uri": "/vi/3-view-resources-in-eks-console/3.3-service-and-networking/",
	"title": "Service and Networking",
	"tags": [],
	"description": "",
	"content": "Service and Networking Services and Endpoints Service resource view hiển thị tất cả các dịch vụ mà expose ứng dụng đang chạy trên một tập hợp các pods trong một cluster. Nếu bạn chọn service cart, phần hiển thị sẽ bao gồm thông tin về dịch vụ trong phần Info bao gồm selector (Tập hợp các pods mà dịch vụ đích đến thường được xác định bởi một selector), giao thức và cổng mà nó đang chạy và bất kỳ labels và annotations nào.\nPods expose chính mình thông qua các endpoints đến một dịch vụ. Một endpoint là một resource mà nhận một địa chỉ IP và cổng của các pods được gán động đến nó. Một endpoint được tham chiếu bởi một dịch vụ Kubernetes.\nĐối với ứng dụng mẫu này, nhấp vào Endpoints và nó sẽ liệt kê tất cả các endpoints cho cluster của bạn.\nNhấp vào endpoint của catalog và khi bạn khám phá chi tiết bạn có thể thấy địa chỉ IP và cổng được liên kết với endpoint cùng với các phần Info, Labels và Annotations.\n"
},
{
	"uri": "/vi/5-eks-open-source-observability/5.3-accessing-grafana/",
	"title": "Truy cập Grafana",
	"tags": [],
	"description": "",
	"content": "Truy cập Grafana Một instance của Grafana đã được cài đặt sẵn trong cụm EKS của bạn. Để truy cập nó, bạn cần trước tiên lấy URL:\nkubectl get ingress -n grafana grafana -o=jsonpath=\u0026#39;{.status.loadBalancer.ingress[0].hostname}\u0026#39; Mở URL này trong trình duyệt sẽ hiển thị màn hình đăng nhập.\n"
},
{
	"uri": "/vi/3-view-resources-in-eks-console/",
	"title": "View resources in EKS console",
	"tags": [],
	"description": "",
	"content": "View resources in EKS console Các bước chuẩn bị "
},
{
	"uri": "/vi/4-logging-in-eks/4.1-control-plane-logs/4.1.3-cloudwatch-log-insights/",
	"title": "Viewing in CloudWatch",
	"tags": [],
	"description": "",
	"content": "CloudWatch Logs Insights cho phép bạn tìm kiếm và phân tích dữ liệu log của bạn trong CloudWatch Logs một cách tương tác. Bạn có thể thực hiện các truy vấn để giúp bạn phản ứng một cách hiệu quả hơn và hiệu quả hơn đối với các vấn đề vận hành. Nếu có vấn đề xảy ra, bạn có thể sử dụng CloudWatch Logs Insights để xác định nguyên nhân tiềm ẩn và xác nhận các sửa đổi đã triển khai. Nó bao gồm một ngôn ngữ truy vấn được xây dựng với một số lệnh đơn giản nhưng mạnh mẽ.\nTrong bài thực hành này, chúng ta sẽ xem một ví dụ về việc sử dụng CloudWatch Log Insights để truy vấn các logs điều khiển EKS. Trước tiên, điều hướng đến CloudWatch Log Insights trong bảng điều khiển:\nhttps://console.aws.amazon.com/cloudwatch/home#logsV2:logs-insights\nBạn sẽ nhìn thấy một màn hình giống như sau:\nMột trường hợp sử dụng phổ biến cho CloudWatch Log Insights là xác định các thành phần trong một cụm EKS đang tạo ra một lượng lớn các yêu cầu đến máy chủ API Kubernetes. Một cách để làm điều này là với truy vấn sau:\nfields userAgent, requestURI, @timestamp, @message\r| filter @logStream ~= \u0026#34;kube-apiserver-audit\u0026#34;\r| stats count(userAgent) as count by userAgent\r| sort count desc Truy vấn này kiểm tra các log kiểm toán Kubernetes và đếm số lượng yêu cầu API được thực hiện được nhóm theo userAgent và sắp xếp chúng theo thứ tự giảm dần. Trong bảng điều khiển Log Insights, chọn nhóm log cho cụm EKS của bạn.\nSao chép truy vấn vào bảng điều khiển và nhấn Chạy truy vấn, điều này sẽ trả về kết quả:\nThông tin này có thể rất quý giá để hiểu rõ các thành phần nào đang gửi yêu cầu đến máy chủ API.\n"
},
{
	"uri": "/vi/3-view-resources-in-eks-console/3.4-config-and-secrets/",
	"title": "Config and Secrets",
	"tags": [],
	"description": "",
	"content": "Config and Secrets Để xem tài nguyên Kubernetes ConfigMap và Secrets, hãy nhấp vào tab Resources. Tiếp tục vào phần Config và secrets và bạn có thể xem một số loại tài nguyên API Kubernetes mà là phần của ConfigMap và Secrets API. Bài thực hành lab này mô tả các tài nguyên mà Kubernetes cung cấp để cấu hình các workloads với dữ liệu không bảo mật sử dụng ConfigMap và dữ liệu nhạy cảm sử dụng Secrets.\nConfigMaps là một đối tượng tài nguyên của Kubernetes được sử dụng để lưu trữ dữ liệu cấu hình dưới định dạng key-value. ConfigMaps hữu ích để lưu trữ biến môi trường, tham số dòng lệnh, cấu hình ứng dụng có thể được truy cập bởi các ứng dụng triển khai trong các pod. ConfigMaps cũng có thể được lưu trữ dưới dạng các tệp cấu hình trong một khối lưu trữ. Điều này giúp tách biệt dữ liệu cấu hình khỏi mã ứng dụng.\nNhấp vào ConfigMap drill down và bạn có thể xem tất cả các cấu hình cho cụm máy chủ.\nNếu bạn nhấp vào ConfigMap checkout, bạn có thể xem các thuộc tính liên quan đến nó, trong trường hợp này, key REDIS_URL với giá trị của địa chỉ endpoint của redis. Như bạn thấy, giá trị không được mã hóa và ConfigMaps không nên được sử dụng để lưu trữ bất kỳ cặp key-value nào có tính bảo mật.\nSecrets là một đối tượng tài nguyên Kubernetes dùng để lưu trữ các dữ liệu nhạy cảm như tên người dùng, mật khẩu, token và các thông tin chứng thực khác. Secrets hữu ích để tổ chức và phân phối thông tin nhạy cảm qua các pod trong một cụm. Secrets có thể được sử dụng theo nhiều cách khác nhau, như được gắn kết như các thư mục dữ liệu hoặc được tiết lộ như các biến môi trường để sử dụng bởi một container trong một Pod.\nNhấp vào liên kết Secrets để xem tất cả các secrets cho cụm.\nNếu bạn nhấp vào Secrets checkout-config, bạn có thể xem các secrets liên quan đến nó. Trong trường hợp này, lưu ý token được mã hóa. Bạn nên thấy giá trị giải mã cũng với nút chuyển đổi giải mã.\n"
},
{
	"uri": "/vi/4-logging-in-eks/",
	"title": "Logging in EKS",
	"tags": [],
	"description": "",
	"content": "Logging in EKS Trong Kubernetes, việc ghi log có thể được chia thành ghi log của control plane, ghi log của node và ghi log của ứng dụng. Control plane của Kubernetes là một bộ các thành phần quản lý các cụm Kubernetes và tạo ra các log được sử dụng cho mục đích kiểm toán và chẩn đoán. Với Amazon EKS, bạn có thể bật log cho các thành phần control plane khác nhau và gửi chúng đến Amazon CloudWatch.\nCác container được nhóm lại thành các Pod trong một cụm Kubernetes và được lên lịch để chạy trên các node Kubernetes của bạn. Hầu hết các ứng dụng container viết vào standard output và standard error, và engine của container chuyển hướng đầu ra đến một driver ghi log. Trong Kubernetes, các log của container được tìm thấy trong thư mục /var/log/pods trên một node. Bạn có thể cấu hình CloudWatch và Container Insights để ghi lại các log này cho mỗi Pod của Amazon EKS của bạn.\nTrong lab này, chúng ta sẽ:\nLàm thế nào để bật log Control Plane của EKS và xác minh nó trong Amazon CloudWatch Làm thế nào để thiết lập agent ghi log (Fluent Bit) để stream các log của Pod đến Amazon CloudWatch "
},
{
	"uri": "/vi/5-eks-open-source-observability/",
	"title": "EKS open source observability",
	"tags": [],
	"description": "",
	"content": "EKS open source observability Mở CloudWatch Logs console để kiểm tra các log này có xuất hiện:\nTRƯỚC KHI BẮT ĐẦU Chuẩn bị môi trường cho phần này:\nprepare-environment observability/oss-metrics Điều này sẽ thực hiện các thay đổi sau vào môi trường lab của bạn:\nCài đặt phần bổ sung quản lý EKS cho AWS Distro cho OpenTelemetry Tạo một vai trò IAM cho bộ thu thập ADOT để truy cập Amazon Managed Prometheus Bạn có thể xem Terraform áp dụng các thay đổi này tại đây.\nTrong lab này, chúng ta sẽ thu thập các số liệu từ ứng dụng bằng cách sử dụng AWS Distro cho OpenTelemetry, lưu trữ các số liệu trong Amazon Managed Service for Prometheus và trực quan hóa bằng cách sử dụng Amazon Managed Grafana.\nAWS Distro cho OpenTelemetry là một bản phân phối được hỗ trợ bởi AWS, an toàn và sẵn sàng cho sản xuất của dự án OpenTelemetry. Là một phần của Cloud Native Computing Foundation, OpenTelemetry cung cấp các API, thư viện và agent mã nguồn mở để thu thập các dấu vết phân tán và số liệu cho việc giám sát ứng dụng. Với AWS Distro cho OpenTelemetry, bạn chỉ cần instrument ứng dụng của mình một lần để gửi các số liệu và dấu vết tương quan đến nhiều giải pháp giám sát của AWS và đối tác. Sử dụng các agent tự động instrument để thu thập các dấu vết mà không cần thay đổi mã của bạn. AWS Distro cho OpenTelemetry cũng thu thập dữ liệu về siêu dữ liệu từ tài nguyên AWS và các dịch vụ quản lý, giúp bạn liên kết dữ liệu hiệu suất ứng dụng với dữ liệu cơ sở hạ tầng bên dưới, giảm thiểu thời gian trung bình để giải quyết vấn đề. Sử dụng AWS Distro cho OpenTelemetry để instrument các ứng dụng đang chạy trên Amazon Elastic Compute Cloud (EC2), Amazon Elastic Container Service (ECS), và Amazon Elastic Kubernetes Service (EKS) trên EC2, AWS Fargate, và AWS Lambda, cũng như on-premises.\nAmazon Managed Service for Prometheus là một dịch vụ giám sát cho các số liệu tương thích với dự án mã nguồn mở Prometheus, giúp bạn dễ dàng giám sát môi trường container một cách an toàn hơn. Amazon Managed Service for Prometheus là một giải pháp để giám sát các container dựa trên dự án Prometheus của Cloud Native Computing Foundation (CNCF). Amazon Managed Service for Prometheus giảm bớt công việc nặng nề cần thiết để bắt đầu giám sát ứng dụng trên Amazon Elastic Kubernetes Service và Amazon Elastic Container Service, cũng như các cụm Kubernetes tự quản lý.\n"
},
{
	"uri": "/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]