[
{
	"uri": "//localhost:1313/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu Kubernetes trên AWS Kubernetes là một nền tảng mã nguồn mở, linh hoạt, có khả năng mở rộng, phục vụ việc quản lý các ứng dụng được đóng gói và các dịch vụ liên quan, giúp việc cấu hình và tự động hóa quá trình triển khai ứng dụng trở nên thuận tiện hơn. Được biết đến như một hệ sinh thái lớn và phát triển nhanh chóng, Kubernetes cung cấp sự hỗ trợ rộng rãi qua các dịch vụ và công cụ đa dạng.\nTên Kubernetes bắt nguồn từ tiếng Hy Lạp, nghĩa là người lái tàu hoặc hoa tiêu. Kubernetes được Google công bố mã nguồn vào năm 2014, dựa trên gần một thập kỷ kinh nghiệm quản lý workload lớn trong thực tế của Google, kết hợp với các ý tưởng và best practices từ cộng đồng.\nQuay ngược thời gian Hãy xem xét tại sao Kubernetes lại quan trọng thông qua việc nhìn lại quá khứ.\nThời kỳ triển khai truyền thống: Ban đầu, các ứng dụng được chạy trực tiếp trên máy chủ vật lý, khiến việc phân bổ tài nguyên gặp khó khăn do không có cơ chế xác định ranh giới tài nguyên cho từng ứng dụng. Cách tiếp cận này dẫn đến nguy cơ một ứng dụng có thể sử dụng quá nhiều tài nguyên, ảnh hưởng đến hoạt động của các ứng dụng khác. Giải pháp là chạy mỗi ứng dụng trên một máy chủ vật lý riêng biệt, nhưng điều này lại không hiệu quả về mặt chi phí và tài nguyên.\nThời kỳ triển khai ảo hóa: Ảo hóa được giới thiệu như một giải pháp cho phép chạy nhiều Máy ảo (VM) trên cùng một máy chủ vật lý, giúp cô lập ứng dụng và tăng cường bảo mật. Ảo hóa cũng giúp cải thiện hiệu quả sử dụng tài nguyên và khả năng mở rộng.\nThời kỳ triển khai Container: Container giống như VM nhưng nhẹ hơn và chia sẻ Hệ điều hành (HĐH) với nhau. Container mang lại nhiều lợi ích như tạo mới và triển khai ứng dụng nhanh chóng, phát triển và triển khai liên tục, phân biệt rõ ràng giữa quá trình phát triển và vận hành, cung cấp tính nhất quán qua các môi trường, khả năng di chuyển giữa các cloud và HĐH, và quản lý ứng dụng tập trung.\nTại sao bạn cần Kubernetes và nó có thể làm gì? Container là phương tiện hiệu quả để đóng góp và chạy ứng dụng của bạn. Trong môi trường sản xuất, cần có cơ chế quản lý các container một cách hiệu quả, đảm bảo không có downtime. Kubernetes giúp quản lý các hệ thống phân tán mạnh mẽ, tự động hóa việc nhân rộng, cung cấp các mẫu triển khai và nhiều hơn nữa.\nKubernetes mang lại:\nPhát hiện dịch vụ và cân bằng tải Điều phối bộ nhớ Tự động rollouts và rollbacks Đóng gói tự động Tự phục hồi Quản lý cấu hình và bảo mật Những gì Kubernetes không phải là Kubernetes không phải là một hệ thống PaaS truyền thống, toàn diện. Nó hoạt động ở tầng container, cung cấp tính năng giống như PaaS như triển khai, nhân rộng, cân bằng tải, nhưng là một giải pháp linh hoạt và có thể mở rộng, không giới hạn loại ứng dụng được hỗ trợ, không triển khai mã nguồn hoặc build ứng dụng, không cung cấp dịch vụ ứng dụng cấp cao như middleware, databases, không bắt buộc sử dụng các giải pháp ghi nhật ký, giám sát hoặc cảnh báo, và không cung cấp hoặc áp dụng bất kỳ cấu hình toàn diện, bảo trì, quản lý hoặc hệ thống tự phục hồi. Kubernetes loại bỏ nhu cầu về điều phối truyền thống, thay vào đó là kiểm soát liên tục từ trạng thái hiện tại sang trạng thái mong muốn.\n"
},
{
	"uri": "//localhost:1313/vi/",
	"title": "Kubernetes trên AWS",
	"tags": [],
	"description": "",
	"content": "Kubernetes trên AWS Kubernetes là một nền tảng mã nguồn mở, linh hoạt, có khả năng mở rộng, phục vụ việc quản lý các ứng dụng được đóng gói và các dịch vụ liên quan, giúp việc cấu hình và tự động hóa quá trình triển khai ứng dụng trở nên thuận tiện hơn. Được biết đến như một hệ sinh thái lớn và phát triển nhanh chóng, Kubernetes cung cấp sự hỗ trợ rộng rãi qua các dịch vụ và công cụ đa dạng.\nTên Kubernetes bắt nguồn từ tiếng Hy Lạp, nghĩa là người lái tàu hoặc hoa tiêu. Kubernetes được Google công bố mã nguồn vào năm 2014, dựa trên gần một thập kỷ kinh nghiệm quản lý khối lượng công việc lớn trong thực tế của Google, kết hợp với các ý tưởng và best practices từ cộng đồng.\nQuay ngược thời gian Hãy xem xét tại sao Kubernetes lại quan trọng thông qua việc nhìn lại quá khứ.\nThời kỳ triển khai truyền thống: Ban đầu, các ứng dụng được chạy trực tiếp trên máy chủ vật lý, khiến việc phân bổ tài nguyên gặp khó khăn do không có cơ chế xác định ranh giới tài nguyên cho từng ứng dụng. Cách tiếp cận này dẫn đến nguy cơ một ứng dụng có thể sử dụng quá nhiều tài nguyên, ảnh hưởng đến hoạt động của các ứng dụng khác. Giải pháp là chạy mỗi ứng dụng trên một máy chủ vật lý riêng biệt, nhưng điều này lại không hiệu quả về mặt chi phí và tài nguyên.\nThời kỳ triển khai ảo hóa: Ảo hóa được giới thiệu như một giải pháp cho phép chạy nhiều Máy ảo (VM) trên cùng một máy chủ vật lý, giúp cô lập ứng dụng và tăng cường bảo mật. Ảo hóa cũng giúp cải thiện hiệu quả sử dụng tài nguyên và khả năng mở rộng.\nThời kỳ triển khai Container: Container giống như VM nhưng nhẹ hơn và chia sẻ Hệ điều hành (HĐH) với nhau. Container mang lại nhiều lợi ích như tạo mới và triển khai ứng dụng nhanh chóng, phát triển và triển khai liên tục, phân biệt rõ ràng giữa quá trình phát triển và vận hành, cung cấp tính nhất quán qua các môi trường, khả năng di chuyển giữa các cloud và HĐH, và quản lý ứng dụng tập trung.\nTại sao bạn cần Kubernetes và nó có thể làm gì? Container là phương tiện hiệu quả để đóng góp và chạy ứng dụng của bạn. Trong môi trường sản xuất, cần có cơ chế quản lý các container một cách hiệu quả, đảm bảo không có downtime. Kubernetes giúp quản lý các hệ thống phân tán mạnh mẽ, tự động hóa việc nhân rộng, cung cấp các mẫu triển khai và nhiều hơn nữa.\nKubernetes mang lại:\nPhát hiện dịch vụ và cân bằng tải Điều phối bộ nhớ Tự động rollouts và rollbacks Đóng gói tự động Tự phục hồi Quản lý cấu hình và bảo mật Những gì Kubernetes không phải là Kubernetes không phải là một hệ thống PaaS truyền thống, toàn diện. Nó hoạt động ở tầng container, cung cấp tính năng giống như PaaS như triển khai, nhân rộng, cân bằng tải, nhưng là một giải pháp linh hoạt và có thể mở rộng, không giới hạn loại ứng dụng được hỗ trợ, không triển khai mã nguồn hoặc build ứng dụng, không cung cấp dịch vụ ứng dụng cấp cao như middleware, databases, không bắt buộc sử dụng các giải pháp ghi nhật ký, giám sát hoặc cảnh báo, và không cung cấp hoặc áp dụng bất kỳ cấu hình toàn diện, bảo trì, quản lý hoặc hệ thống tự phục hồi. Kubernetes loại bỏ nhu cầu về điều phối truyền thống, thay vào đó là kiểm soát liên tục từ trạng thái hiện tại sang trạng thái mong muốn.\n"
},
{
	"uri": "//localhost:1313/vi/3-aws-load-balancer-controller/3.1-introduction/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu Chúng tôi xác nhận rằng các Service microservices của chúng tôi chỉ có thể truy cập nội bộ bằng cách nhìn vào các tài nguyên current Service trong cụm:\n$ kubectl get svc -l app.kubernetes.io/created-by=eks-workshop -A NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE assets assets ClusterIP 172.20.119.246 \u0026lt;none\u0026gt; 80/TCP 1h carts carts ClusterIP 172.20.180.149 \u0026lt;none\u0026gt; 80/TCP 1h carts carts-dynamodb ClusterIP 172.20.92.137 \u0026lt;none\u0026gt; 8000/TCP 1h catalog catalog ClusterIP 172.20.83.84 \u0026lt;none\u0026gt; 80/TCP 1h catalog catalog-mysql ClusterIP 172.20.181.252 \u0026lt;none\u0026gt; 3306/TCP 1h checkout checkout ClusterIP 172.20.77.176 \u0026lt;none\u0026gt; 80/TCP 1h checkout checkout-redis ClusterIP 172.20.32.208 \u0026lt;none\u0026gt; 6379/TCP 1h orders orders ClusterIP 172.20.146.72 \u0026lt;none\u0026gt; 80/TCP 1h orders orders-mysql ClusterIP 172.20.54.235 \u0026lt;none\u0026gt; 3306/TCP 1h rabbitmq rabbitmq ClusterIP 172.20.107.54 \u0026lt;none\u0026gt; 5672/TCP,4369/TCP,25672/TCP,15672/TCP 1h ui ui ClusterIP 172.20.62.119 \u0026lt;none\u0026gt; 80/TCP 1h Tất cả các thành phần ứng dụng của chúng tôi hiện đang sử dụng các Service ClusterIP, chỉ cho phép truy cập đến các công việc khác trong cùng một cụm Kubernetes. Để người dùng có thể truy cập ứng dụng của chúng tôi, chúng tôi cần phải tiết lộ ứng dụng ui, và trong ví dụ này, chúng tôi sẽ làm điều đó bằng cách sử dụng Kubernetes services loại LoadBalancer.\nTrước tiên, hãy xem xét cẩn thận thông số kỹ thuật hiện tại của Service cho thành phần ui:\n$ kubectl -n ui describe service ui Name: ui Namespace: ui Labels: app.kubernetes.io/component=service app.kubernetes.io/created-by: eks-workshop app.kubernetes.io/instance=ui app.kubernetes.io/managed-by=Helm app.kubernetes.io/name=ui helm.sh/chart=ui-0.0.1 Annotations: \u0026lt;none\u0026gt; Selector: app.kubernetes.io/component=service,app.kubernetes.io/instance=ui,app.kubernetes.io/name=ui Type: ClusterIP IP Family Policy: SingleStack IP Families: IPv4 IP: 172.20.62.119 IPs: 172.20.62.119 Port: http 80/TCP TargetPort: http/TCP Endpoints: 10.42.105.38:8080 Session Affinity: None Events: \u0026lt;none\u0026gt; Như chúng ta đã thấy trước đó, hiện đang sử dụng loại ClusterIP và nhiệm vụ của chúng tôi trong module này là thay đổi điều này để giao diện người dùng của cửa hàng bán lẻ có thể truy cập thông qua Public internet.\n"
},
{
	"uri": "//localhost:1313/vi/4-ingress/4.1-introduction/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu Hiện tại, trong cụm của chúng ta không có tài nguyên Ingress, bạn có thể kiểm tra bằng lệnh sau:\n$ kubectl get ingress -n ui No resources found in ui namespace. Cũng không có tài nguyên Service loại LoadBalancer, bạn có thể xác nhận bằng lệnh sau:\n$ kubectl get svc -n ui NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ui ClusterIP 10.100.221.103 \u0026lt;none\u0026gt; 80/TCP 29m "
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.1-replicasets/",
	"title": "ReplicaSets",
	"tags": [],
	"description": "",
	"content": "ReplicaSets Trong phần này, chúng ta sẽ tìm hiểu về các khái niệm sau:\nReplicaSet Controllers là bộ não đằng sau Kubernetes. Replica là gì và tại sao chúng ta cần một replication controller?\nSự khác biệt giữa ReplicaSet và Replication Controller Replication Controller là công nghệ cũ được thay thế bằng ReplicaSet. ReplicaSet là cách mới để thiết lập replication. File Định nghĩa Replication Controller có dạng:\napiVersion: v1 kind: ReplicationController metadata: name: myapp-rc labels: app: myapp type: front-end spec: template: metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx replicas: 3 Để tạo replication controller\n$ kubectl create -f rc-definition.yaml Để liệt kê tất cả các replication controllers\n$ kubectl get replicationcontroller Để liệt kê các pod được khởi chạy bởi replication controller\n$ kubectl get pods Tạo một ReplicaSet File Định nghĩa ReplicaSet\napiVersion: apps/v1\rkind: ReplicaSet\rmetadata:\rname: myapp-replicaset\rlabels:\rapp: myapp\rtype: front-end\rspec:\rtemplate:\rmetadata:\rname: myapp-pod\rlabels:\rapp: myapp\rtype: front-end\rspec:\rcontainers:\r- name: nginx-container\rimage: nginx\rreplicas: 3\rselector:\rmatchLabels:\rtype: front-end ReplicaSet yêu cầu thêm định nghĩa selector so với Replication Controller. Để tạo ReplicaSet\n$ kubectl create -f replicaset-definition.yaml Để liệt kê tất cả các ReplicaSet\n$ kubectl get replicaset Để liệt kê các pod được khởi chạy bởi ReplicaSet\n$ kubectl get pods Nhãn và Selector Vấn đề với Nhãn và Selector là gì? Tại sao chúng ta đánh dấu các pod và đối tượng trong Kubernetes?\nLàm thế nào để mở rộng ReplicaSet Có nhiều cách để mở rộng ReplicaSet Cách đầu tiên là cập nhật số lượng bản sao trong file định nghĩa replicaset-definition.yaml. Ví dụ: replicas: 6 và sau đó chạy apiVersion: apps/v1 kind: ReplicaSet metadata: name: myapp-replicaset labels: app: myapp type: front-end spec: template: metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx replicas: 6 selector: matchLabels: type: front-end $ kubectl apply -f replicaset-definition.yaml Cách thứ hai là sử dụng lệnh kubectl scale.\n$ kubectl scale --replicas=6 -f replicaset-definition.yaml Cách thứ ba là sử dụng lệnh kubectl scale với loại và tên\n$ kubectl scale --replicas=6 replicaset myapp-replicaset Tài liệu Tham khảo K8s: Kubernetes: Replicaset Kubernetes: Replication Controller "
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/",
	"title": "Các Bước Chuẩn Bị",
	"tags": [],
	"description": "",
	"content": "Các Bước Chuẩn Bị Chuẩn bị môi trường cho phần này: $ prepare-environment exposing/load-balancer Thao tác này sẽ thực hiện các thay đổi sau vào môi trường lab của bạn:\nCài đặt AWS Load Balancer Controller trong cụm Amazon EKS Kubernetes sử dụng dịch vụ để phơi bày các pod ra bên ngoài một cụm. Một trong những cách phổ biến nhất để sử dụng dịch vụ trong AWS là với kiểu LoadBalancer. Với một tệp YAML đơn giản khai báo tên dịch vụ, cổng và bộ chọn nhãn, bộ điều khiển đám mây sẽ tự động cung cấp một bộ cân bằng tải cho bạn.\napiVersion: v1 kind: Service metadata: name: search-svc # tên của dịch vụ của chúng tôi spec: type: loadBalancer selector: app: SearchApp # các pod được triển khai với nhãn app=SearchApp ports: - port: 80 Điều này rất tuyệt vì tính đơn giản của việc đặt một bộ cân bằng tải trước ứng dụng của bạn. Đặc tả dịch vụ đã được mở rộng qua các năm với các chú thích và cấu hình bổ sung. Một lựa chọn thứ hai là sử dụng quy tắc nhập và một bộ điều khiển nhập để định tuyến lưu lượng bên ngoài vào các pod Kubernetes.\nTrong chương này, chúng tôi sẽ thể hiện cách phơi bày một ứng dụng đang chạy trong cụm EKS ra Internet bằng cách sử dụng một Bộ cân bằng Tải Mạng ở tầng 4.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.2-deployments/",
	"title": "Triển khai (Deployments) trong Kubernetes",
	"tags": [],
	"description": "",
	"content": "Triển khai (Deployments) trong Kubernetes Trong phần này, chúng ta sẽ tìm hiểu về các triển khai (deployments) trong Kubernetes.\nTriển khai (Deployment) là một đối tượng trong Kubernetes.\napiVersion: apps/v1 kind: Deployment metadata: name: myapp-deployment labels: app: myapp type: front-end spec: template: metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx replicas: 3 selector: matchLabels: type: front-end Sau khi tệp này đã sẵn sàng, tạo triển khai bằng cách sử dụng tệp định nghĩa triển khai:\n$ kubectl create -f deployment-definition.yaml Để xem triển khai đã được tạo:\n$ kubectl get deployment Triển khai tự động tạo một ReplicaSet. Để xem các ReplicaSet:\n$ kubectl get replicaset Các ReplicaSet cuối cùng sẽ tạo ra các POD. Để xem các POD:\n$ kubectl get pods Để xem tất cả các đối tượng cùng một lúc:\n$ kubectl get all Tài liệu tham khảo về Kubernetes: Triển khai (Deployments) Giới thiệu về triển khai Quản lý triển khai Làm việc với các đối tượng Kubernetes "
},
{
	"uri": "//localhost:1313/vi/4-ingress/4.2-creating-the-ingress/",
	"title": "Tạo Ingress",
	"tags": [],
	"description": "",
	"content": "Tạo Ingress Hãy tạo một tài nguyên Ingress với bản mô tả sau:\nmanifests/modules/exposing/ingress/creating-ingress/ingress.yaml Điều này sẽ khiến AWS Load Balancer Controller triển khai một Application Load Balancer và cấu hình nó để định tuyến lưu lượng đến các Pod cho ứng dụng ui.\n$ kubectl apply -k ~/environment/eks-workshop/modules/exposing/ingress/creating-ingress Hãy kiểm tra tài nguyên Ingress đã được tạo:\n$ kubectl get ingress ui -n ui NAME CLASS HOSTS ADDRESS PORTS AGE ui alb * k8s-ui-ui-1268651632.us-west-2.elb.amazonaws.com 80 15s ALB sẽ mất vài phút để triển khai và đăng ký các mục tiêu của nó, vì vậy hãy dành một chút thời gian để xem xét cẩn thận về ALB được triển khai cho Ingress này để xem cách nó được cấu hình:\n$ aws elbv2 describe-load-balancers --query \u0026#39;LoadBalancers[?contains(LoadBalancerName, `k8s-ui-ui`) == `true`]\u0026#39; [ { \u0026#34;LoadBalancerArn\u0026#34;: \u0026#34;arn:aws:elasticloadbalancing:us-west-2:1234567890:loadbalancer/app/k8s-ui-ui-cb8129ddff/f62a7bc03db28e7c\u0026#34;, \u0026#34;DNSName\u0026#34;: \u0026#34;k8s-ui-ui-cb8129ddff-1888909706.us-west-2.elb.amazonaws.com\u0026#34;, \u0026#34;CanonicalHostedZoneId\u0026#34;: \u0026#34;Z1H1FL5HABSF5\u0026#34;, \u0026#34;CreatedTime\u0026#34;: \u0026#34;2022-09-30T03:40:00.950000+00:00\u0026#34;, \u0026#34;LoadBalancerName\u0026#34;: \u0026#34;k8s-ui-ui-cb8129ddff\u0026#34;, \u0026#34;Scheme\u0026#34;: \u0026#34;internet-facing\u0026#34;, \u0026#34;VpcId\u0026#34;: \u0026#34;vpc-0851f873025a2ece5\u0026#34;, \u0026#34;State\u0026#34;: { \u0026#34;Code\u0026#34;: \u0026#34;active\u0026#34; }, \u0026#34;Type\u0026#34;: \u0026#34;application\u0026#34;, \u0026#34;AvailabilityZones\u0026#34;: [ { \u0026#34;ZoneName\u0026#34;: \u0026#34;us-west-2b\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;subnet-00415f527bbbd999b\u0026#34;, \u0026#34;LoadBalancerAddresses\u0026#34;: [] }, { \u0026#34;ZoneName\u0026#34;: \u0026#34;us-west-2a\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;subnet-0264d4b9985bd8691\u0026#34;, \u0026#34;LoadBalancerAddresses\u0026#34;: [] }, { \u0026#34;ZoneName\u0026#34;: \u0026#34;us-west-2c\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;subnet-05cda6deed7f3da65\u0026#34;, \u0026#34;LoadBalancerAddresses\u0026#34;: [] } ], \u0026#34;SecurityGroups\u0026#34;: [ \u0026#34;sg-0f8e704ee37512eb2\u0026#34;, \u0026#34;sg-02af06ec605ef8777\u0026#34; ], \u0026#34;IpAddressType\u0026#34;: \u0026#34;ipv4\u0026#34; } ] Điều này nói cho chúng ta điều gì?\nALB có thể truy cập qua public internet Nó sử dụng các public subnet trong VPC của chúng tôi Kiểm tra các mục tiêu trong nhóm mục tiêu được tạo ra bởi bộ điều khiển:\n$ ALB_ARN=$(aws elbv2 describe-load-balancers --query \u0026#39;LoadBalancers[?contains(LoadBalancerName, `k8s-ui-ui`) == `true`].LoadBalancerArn\u0026#39; | jq -r \u0026#39;.[0]\u0026#39;) $ TARGET_GROUP_ARN=$(aws elbv2 describe-target-groups --load-balancer-arn $ALB_ARN | jq -r \u0026#39;.TargetGroups[0].TargetGroupArn\u0026#39;) $ aws elbv2 describe-target-health --target-group-arn $TARGET_GROUP_ARN { \u0026#34;TargetHealthDescriptions\u0026#34;: [ { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;10.42.180.183\u0026#34;, \u0026#34;Port\u0026#34;: 8080, \u0026#34;AvailabilityZone\u0026#34;: \u0026#34;us-west-2c\u0026#34; }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;8080\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;healthy\u0026#34; } } ] } Vì chúng tôi đã chỉ định sử dụng chế độ IP trong đối tượng Ingress của chúng tôi, mục tiêu được đăng ký bằng địa chỉ IP của pod ui và cổng mà nó phục vụ lưu lượng.\nBạn cũng có thể kiểm tra ALB và các nhóm mục tiêu của nó trong bảng điều khiển bằng cách nhấp vào liên kết này:\nhttps://console.aws.amazon.com/ec2/home#LoadBalancers:tag:ingress.k8s.aws/stack=ui/ui;sort=loadBalancerName\nLấy URL từ tài nguyên Ingress:\n$ kubectl get ingress -n ui ui -o jsonpath=\u0026#34;{.status.loadBalancer.ingress[*].hostname}{\u0026#39;\\n\u0026#39;}\u0026#34; k8s-ui-uinlb-a9797f0f61.elb.us-west-2.amazonaws.com Để chờ đến khi bộ cân bằng tải hoàn tất triển khai, bạn có thể chạy lệnh này:\n$ wait-for-lb $(kubectl get ingress -n ui ui -o jsonpath=\u0026#34;{.status.loadBalancer.ingress[*].hostname}{\u0026#39;\\n\u0026#39;}\u0026#34;) Và truy cập vào trình duyệt web của bạn. Bạn sẽ thấy giao diện người dùng từ cửa hàng web được hiển thị và sẽ có thể di chuyển xung quanh trang web như một người dùng.\n"
},
{
	"uri": "//localhost:1313/vi/3-aws-load-balancer-controller/3.2-creating-the-load-balancer/",
	"title": "Tạo load balancer",
	"tags": [],
	"description": "",
	"content": "Tạo load balancer Trong môi trường AWS và Kubernetes, việc triển khai một load balancer là một phần quan trọng của quá trình triển khai ứng dụng. Load balancer giúp phân phối tải và cung cấp sự ổn định cho các ứng dụng đang chạy trên các cluster. Dưới đây là hướng dẫn chi tiết để tạo một load balancer.\nmanifests/modules/exposing/load-balancer/nlb/nlb.yaml Dịch vụ này sẽ tạo ra một Trình cân bằng tải Mạng lắng nghe trên cổng 80 và chuyển tiếp kết nối đến các Pod ui trên cổng 8080. Một NLB là một trình cân bằng tải tầng 4 hoạt động ở tầng TCP trong trường hợp của chúng tôi.\n$ kubectl apply -k ~/environment/eks-workshop/modules/exposing/load-balancer/nlb Hãy kiểm tra lại tài nguyên Dịch vụ cho ứng dụng ui:\n$ kubectl get service -n ui Chúng ta thấy hai tài nguyên riêng biệt, với mục nhập ui-nlb mới có kiểu LoadBalancer. Quan trọng nhất là lưu ý rằng nó có giá trị \u0026ldquo;địa chỉ IP bên ngoài\u0026rdquo;, đây là mục nhập DNS có thể được sử dụng để truy cập ứng dụng của chúng ta từ bên ngoài cụm Kubernetes.\nNLB sẽ mất vài phút để triển khai và đăng ký các mục tiêu của nó nên hãy dành thời gian để kiểm tra các tài nguyên trình cân bằng tải mà bộ điều khiển đã tạo ra.\nTrước tiên, hãy xem xét trình cân bằng tải:\n$ aws elbv2 describe-load-balancers --query \u0026#39;LoadBalancers[?contains(LoadBalancerName, `k8s-ui-uinlb`) == `true`]\u0026#39; [ { \u0026#34;LoadBalancerArn\u0026#34;: \u0026#34;arn:aws:elasticloadbalancing:us-west-2:1234567890:loadbalancer/net/k8s-ui-uinlb-e1c1ebaeb4/28a0d1a388d43825\u0026#34;, \u0026#34;DNSName\u0026#34;: \u0026#34;k8s-ui-uinlb-e1c1ebaeb4-28a0d1a388d43825.elb.us-west-2.amazonaws.com\u0026#34;, \u0026#34;CanonicalHostedZoneId\u0026#34;: \u0026#34;Z18D5FSROUN65G\u0026#34;, \u0026#34;CreatedTime\u0026#34;: \u0026#34;2022-11-17T04:47:30.516000+00:00\u0026#34;, \u0026#34;LoadBalancerName\u0026#34;: \u0026#34;k8s-ui-uinlb-e1c1ebaeb4\u0026#34;, \u0026#34;Scheme\u0026#34;: \u0026#34;internet-facing\u0026#34;, \u0026#34;VpcId\u0026#34;: \u0026#34;vpc-00be6fc048a845469\u0026#34;, \u0026#34;State\u0026#34;: { \u0026#34;Code\u0026#34;: \u0026#34;active\u0026#34; }, \u0026#34;Type\u0026#34;: \u0026#34;network\u0026#34;, \u0026#34;AvailabilityZones\u0026#34;: [ { \u0026#34;ZoneName\u0026#34;: \u0026#34;us-west-2c\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;subnet-0a2de0809b8ee4e39\u0026#34;, \u0026#34;LoadBalancerAddresses\u0026#34;: [] }, { \u0026#34;ZoneName\u0026#34;: \u0026#34;us-west-2a\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;subnet-0ff71604f5b58b2ba\u0026#34;, \u0026#34;LoadBalancerAddresses\u0026#34;: [] }, { \u0026#34;ZoneName\u0026#34;: \u0026#34;us-west-2b\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;subnet-0c584c4c6a831e273\u0026#34;, \u0026#34;LoadBalancerAddresses\u0026#34;: [] } ], \u0026#34;IpAddressType\u0026#34;: \u0026#34;ipv4\u0026#34; } ] Điều này nói với chúng ta gì?\nNLB có thể truy cập qua public internet Nó sử dụng các public subnet trong VPC của chúng tôi Chúng ta cũng có thể kiểm tra các mục tiêu trong nhóm mục tiêu được tạo ra bởi bộ điều khiển:\n$ ALB_ARN=$(aws elbv2 describe-load-balancers --query \u0026#39;LoadBalancers[?contains(LoadBalancerName, `k8s-ui-uinlb`) == `true`].LoadBalancerArn\u0026#39; | jq -r \u0026#39;.[0]\u0026#39;) $ TARGET_GROUP_ARN=$(aws elbv2 describe-target-groups --load-balancer-arn $ALB_ARN | jq -r \u0026#39;.TargetGroups[0].TargetGroupArn\u0026#39;) $ aws elbv2 describe-target-health --target-group-arn $TARGET_GROUP_ARN { \u0026#34;TargetHealthDescriptions\u0026#34;: [ { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;i-06a12e62c14e0c39a\u0026#34;, \u0026#34;Port\u0026#34;: 31338 }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;31338\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;healthy\u0026#34; } }, { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;i-088e21d0af0f2890c\u0026#34;, \u0026#34;Port\u0026#34;: 31338 }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;31338\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;healthy\u0026#34; } }, { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;i-0fe2202d18299816f\u0026#34;, \u0026#34;Port\u0026#34;: 31338 }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;31338\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;healthy\u0026#34; } } ] } Đầu ra trên cho thấy chúng ta có 3 mục tiêu đã đăng ký vào trình cân bằng tải bằng các ID instance EC2 (i-) mỗi cái trên cùng một cổng. Lý do cho điều này là mặc định, Bộ Điều khiển Trình Cân bằng Tải AWS hoạt động ở \u0026ldquo;chế độ instance\u0026rdquo;, chuyển hướng lưu lượng đến các nút worker trong cụm EKS và cho phép kube-proxy chuyển tiếp lưu lượng đến các Pod cá nhân.\nBạn cũng có thể kiểm tra NLB trong bảng điều khiển bằng cách nhấp vào liên kết này.\n"
},
{
	"uri": "//localhost:1313/vi/3-aws-load-balancer-controller/",
	"title": "AWS Load Balancer Controller",
	"tags": [],
	"description": "",
	"content": "Quản lý AWS Load Balancer Controller trong Kubernetes AWS Load Balancer Controller là một controller giúp quản lý Elastic Load Balancers cho một cluster Kubernetes.\nController này có thể cung cấp các tài nguyên sau:\nMột AWS Application Load Balancer khi bạn tạo một Ingress trong Kubernetes. Một AWS Network Load Balancer khi bạn tạo một Service trong Kubernetes với loại LoadBalancer. Các Application Load Balancers hoạt động ở tầng L7 của mô hình OSI, cho phép bạn phơi bày dịch vụ Kubernetes bằng các quy tắc ingress và hỗ trợ lưu lượng có chiều ra ngoài. Network Load Balancers hoạt động ở tầng L4 của mô hình OSI, cho phép bạn tận dụng các Services Kubernetes để phơi bày một tập hợp các pods như một dịch vụ mạng ứng dụng.\nController này giúp bạn đơn giản hóa hoạt động và tiết kiệm chi phí bằng cách chia sẻ một Application Load Balancer qua nhiều ứng dụng trong cluster Kubernetes của bạn.\nAWS Load Balancer Controller đã được cài đặt sẵn trong cluster của chúng ta, vì vậy chúng ta có thể bắt đầu tạo các tài nguyên.\nAWS Load Balancer Controller trước đây được gọi là AWS ALB Ingress Controller.\n"
},
{
	"uri": "//localhost:1313/vi/3-aws-load-balancer-controller/3.3-ip-mode/",
	"title": "IP mode",
	"tags": [],
	"description": "",
	"content": "IP mode Như đã đề cập trước đó, NLB chúng ta đã tạo đang hoạt động ở chế độ \u0026ldquo;instance mode\u0026rdquo;. Chế độ mục tiêu instance hỗ trợ các pod đang chạy trên các máy EC2 của AWS. Trong chế độ này, AWS NLB gửi lưu lượng đến các instance và kube-proxy trên các nút làm việc cá nhân chuyển tiếp nó đến các pod thông qua một hoặc nhiều nút làm việc trong cụm Kubernetes.\nBộ điều khiển Cân bằng Tải AWS cũng hỗ trợ tạo NLB hoạt động ở chế độ \u0026ldquo;IP mode\u0026rdquo;. Trong chế độ này, AWS NLB gửi lưu lượng trực tiếp đến các pod Kubernetes đằng sau dịch vụ, loại bỏ nhu cầu cho một bước nhảy mạng phụ qua các nút làm việc trong cụm Kubernetes. Chế độ mục tiêu IP hỗ trợ các pod đang chạy trên cả các máy EC2 của AWS và AWS Fargate.\nCó một số lý do mà chúng ta có thể muốn cấu hình NLB để hoạt động ở chế độ mục tiêu IP:\nTạo một đường mạng hiệu quả hơn cho các kết nối đến, bỏ qua kube-proxy trên nút làm việc EC2. Loại bỏ nhu cầu xem xét các khía cạnh như externalTrafficPolicy và các tùy chọn cấu hình khác nhau của nó. Một ứng dụng đang chạy trên Fargate thay vì EC2. Tái cấu hình NLB Hãy tái cấu hình NLB của chúng ta để sử dụng chế độ IP và xem xét tác động của nó đối với cơ sở hạ tầng.\nĐây là đoạn mã patch chúng ta sẽ áp dụng để tái cấu hình Dịch vụ:\nmodules/exposing/load-balancer/ip-mode/nlb.yaml\rService/ui-nlb Áp dụng các bản mẫu với kustomize:\n$ kubectl apply -k ~/environment/eks-workshop/modules/exposing/load-balancer/ip-mode Sẽ mất vài phút để cấu hình của cân bằng tải được cập nhật. Chạy lệnh sau để đảm bảo chú thích được cập nhật:\n$ kubectl describe service/ui-nlb -n ui ... Annotations: service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip ... Bạn nên có thể truy cập ứng dụng bằng cùng một URL như trước đó, với NLB bây giờ sử dụng chế độ IP để tiết lộ ứng dụng của bạn.\n$ ALB_ARN=$(aws elbv2 describe-load-balancers --query \u0026#39;LoadBalancers[?contains(LoadBalancerName, `k8s-ui-uinlb`) == `true`].LoadBalancerArn\u0026#39; | jq -r \u0026#39;.[0]\u0026#39;) $ TARGET_GROUP_ARN=$(aws elbv2 describe-target-groups --load-balancer-arn $ALB_ARN | jq -r \u0026#39;.TargetGroups[0].TargetGroupArn\u0026#39;) $ aws elbv2 describe-target-health --target-group-arn $TARGET_GROUP_ARN { \u0026#34;TargetHealthDescriptions\u0026#34;: [ { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;10.42.180.183\u0026#34;, \u0026#34;Port\u0026#34;: 8080, \u0026#34;AvailabilityZone\u0026#34;: \u0026#34;us-west-2a\u0026#34; }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;8080\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;initial\u0026#34;, \u0026#34;Reason\u0026#34;: \u0026#34;Elb.RegistrationInProgress\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;Target registration is in progress\u0026#34; } } ] } Chú ý: Chúng ta đã chuyển từ 3 mục tiêu mà chúng ta đã quan sát trong phần trước đó thành chỉ một mục tiêu. Tại sao lại như vậy? Thay vì đăng ký các EC2 instances trong cụm EKS của chúng ta, bộ điều khiển cân bằng tải hiện đang đăng ký các Pods cá nhân và gửi lưu lượng trực tiếp, tận dụng AWS VPC CNI và sự thật rằng mỗi Pod đều có địa chỉ IP VPC cấp đầu.\nHãy mở rộng thành phần ui lên 3 bản sao và xem điều gì xảy ra:\n$ kubectl scale -n ui deployment/ui --replicas=3 $ kubectl wait --for=condition=Ready pod -n ui -l app.kubernetes.io/name=ui --timeout=60s Bây giờ hãy kiểm tra lại các mục tiêu của cân bằng tải:\n$ ALB_ARN=$(aws elbv2 describe-load-balancers --query \u0026#39;LoadBalancers[?contains(LoadBalancerName, `k8s-ui-uinlb`) == `true`].LoadBalancerArn\u0026#39; | jq -r \u0026#39;.[0]\u0026#39;) $ TARGET_GROUP_ARN=$(aws elbv2 describe-target-groups --load-balancer-arn $ALB_ARN | jq -r \u0026#39;.TargetGroups[0].TargetGroupArn\u0026#39;) $ aws elbv2 describe-target-health --target-group-arn $TARGET_GROUP_ARN { \u0026#34;TargetHealthDescriptions\u0026#34;: [ { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;10.42.180.181\u0026#34;, \u0026#34;Port\u0026#34;: 8080, \u0026#34;AvailabilityZone\u0026#34;: \u0026#34;us -west-2c\u0026#34; }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;8080\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;initial\u0026#34;, \u0026#34;Reason\u0026#34;: \u0026#34;Elb.RegistrationInProgress\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;Target registration is in progress\u0026#34; } }, { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;10.42.140.129\u0026#34;, \u0026#34;Port\u0026#34;: 8080, \u0026#34;AvailabilityZone\u0026#34;: \u0026#34;us-west-2a\u0026#34; }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;8080\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;healthy\u0026#34; } }, { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;10.42.105.38\u0026#34;, \u0026#34;Port\u0026#34;: 8080, \u0026#34;AvailabilityZone\u0026#34;: \u0026#34;us-west-2a\u0026#34; }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;8080\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;initial\u0026#34;, \u0026#34;Reason\u0026#34;: \u0026#34;Elb.RegistrationInProgress\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;Target registration is in progress\u0026#34; } } ] } Như dự kiến, bây giờ chúng ta có 3 mục tiêu, khớp với số lượng bản sao trong Deployment ui.\nNếu bạn muốn chờ đợi để đảm bảo ứng dụng vẫn hoạt động như trước, hãy chạy lệnh sau. Nếu không, bạn có thể tiếp tục sang module tiếp theo.\n$ wait-for-lb $(kubectl get service -n ui ui-nlb -o jsonpath=\u0026#34;{.status.loadBalancer.ingress[*].hostname}{\u0026#39;\\n\u0026#39;}\u0026#34;) "
},
{
	"uri": "//localhost:1313/vi/4-ingress/4.3-multiple-ingress-pattern/",
	"title": "Multiple Ingress pattern",
	"tags": [],
	"description": "",
	"content": "Multiple Ingress pattern Trong một EKS cluster, việc tận dụng nhiều đối tượng Ingress là điều phổ biến, ví dụ để tiếp cận nhiều workloads khác nhau. Theo mặc định, mỗi Ingress sẽ dẫn đến việc tạo ra một ALB riêng biệt, nhưng chúng ta có thể tận dụng tính năng IngressGroup để nhóm nhiều tài nguyên Ingress lại với nhau. Controller sẽ tự động hợp nhất các quy tắc Ingress cho tất cả các Ingress trong IngressGroup và hỗ trợ chúng với một ALB duy nhất. Ngoài ra, hầu hết các chú thích được định nghĩa trên một Ingress chỉ áp dụng cho các đường dẫn được xác định bởi Ingress đó.\nTrong ví dụ này, chúng ta sẽ tiếp cận API catalog thông qua cùng một ALB như thành phần ui, tận dụng định tuyến dựa trên đường dẫn để chuyển hướng các yêu cầu đến dịch vụ Kubernetes phù hợp. Hãy kiểm tra xem chúng ta đã có thể truy cập API catalog chưa:\n$ ADDRESS=$(kubectl get ingress -n ui ui -o jsonpath=\u0026#34;{.status.loadBalancer.ingress[*].hostname}{\u0026#39;\\n\u0026#39;}\u0026#34;) $ curl $ADDRESS/catalogue Điều đầu tiên chúng ta sẽ làm là tạo lại Ingress cho thành phần ui, thêm chú thích alb.ingress.kubernetes.io/group.name:\nmanifests/modules/exposing/ingress/multiple-ingress/ingress-ui.yaml Bây giờ, hãy tạo một Ingress riêng cho thành phần catalog cũng tận dụng group.name tương tự:\nmanifests/modules/exposing/ingress/multiple-ingress/ingress-catalog.yaml Ingress này cũng cấu hình quy tắc để định tuyến các yêu cầu có tiền tố /catalogue đến thành phần catalog.\nÁp dụng các tài nguyên này vào cluster:\n$ kubectl apply -k ~/environment/eks-workshop/modules/exposing/ingress/multiple-ingress Bây giờ chúng ta sẽ có hai đối tượng Ingress riêng biệt trong cluster của chúng ta:\n$ kubectl get ingress -l app.kubernetes.io/created-by=eks-workshop -A NAMESPACE NAME CLASS HOSTS ADDRESS PORTS AGE catalog catalog alb * k8s-retailappgroup-2c24c1c4bc-17962260.us-west-2.elb.amazonaws.com 80 2m21s ui ui alb * k8s-retailappgroup-2c24c1c4bc-17962260.us-west-2.elb.amazonaws.com 80 2m21s Chú ý rằng ADDRESS của cả hai đều là cùng một URL, điều này là vì cả hai đối tượng Ingress này đang được nhóm lại với nhau sau một ALB duy nhất.\nChúng ta có thể xem Listener của ALB để hiểu cách hoạt động này:\n$ ALB_ARN=$(aws elbv2 describe-load-balancers --query \u0026#39;LoadBalancers[?contains(LoadBalancerName, `k8s-retailappgroup`) == `true`].LoadBalancerArn\u0026#39; | jq -r \u0026#39;.[0]\u0026#39;) $ LISTENER_ARN=$(aws elbv2 describe-listeners --load-balancer-arn $ALB_ARN | jq -r \u0026#39;.Listeners[0].ListenerArn\u0026#39;) $ aws elbv2 describe-rules --listener-arn $LISTENER_ARN Kết quả của lệnh này sẽ minh họa rằng:\nCác yêu cầu có tiền tố đường dẫn /catalogue sẽ được gửi đến một nhóm mục tiêu cho dịch vụ catalog Tất cả mọi thứ khác sẽ được gửi đến một nhóm mục tiêu cho dịch vụ ui Là một lựa chọn mặc định backup, có một 404 cho bất kỳ yêu cầu nào rơi vào những khe hở Bạn cũng có thể kiểm tra cấu hình ALB mới trong AWS console:\nhttps://console.aws.amazon.com/ec2/home#LoadBalancers:tag:ingress.k8s.aws/stack=retail-app-group;sort=loadBalancerName\nĐể chờ cho đến khi load balancer hoàn thành triển khai, bạn có thể chạy lệnh này:\n$ wait-for-lb $(kubectl get ingress -n ui ui -o jsonpath=\u0026#34;{.status.loadBalancer.ingress[*].hostname}{\u0026#39;\\n\u0026#39;}\u0026#34;) Thử truy cập URL Ingress mới trong trình duyệt như trước để kiểm tra giao diện web vẫn hoạt động:\n$ kubectl get ingress -n ui ui -o jsonpath=\u0026#34;{.status.loadBalancer.ingress[*].hostname}{\u0026#39;\\n\u0026#39;}\u0026#34; k8s-ui-uinlb-a9797f0f61.elb.us-west-2.amazonaws.com Bây giờ hãy thử truy cập vào đường dẫn cụ thể mà chúng ta đã chuyển hướng đến dịch vụ catalog:\nADDRESS=$(kubectl get ingress -n ui ui -o jsonpath=\u0026#34;{.status.loadBalancer.ingress[*].hostname}{\u0026#39;\\n\u0026#39;}\u0026#34;) curl $ADDRESS/catalogue | jq . Bạn sẽ nhận lại một tải dữ liệu JSON từ dịch vụ catalog, chứng tỏ chúng ta đã có thể tiếp cận nhiều dịch vụ Kubernetes qua cùng một ALB.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.3-namespaces/",
	"title": "Namespaces",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về Namespaces trong Kubernetes Trong phần này, chúng ta sẽ tìm hiểu về Namespaces.\nKể từ khi bắt đầu workshop, đến thời điểm này, chúng ta đã tạo ra các đối tượng như PODs, Deployments và Services trong cluster của chúng ta. Mọi thứ chúng ta đã làm, đều nằm trong một NAMESPACE.\nNamespace mặc định trong Kubernetes là không gian mặc định được tạo tự động khi Kubernetes được thiết lập ban đầu.\nkubectl get namespaces Bạn cũng có thể tạo các Namespaces của riêng mình.\nkubectl create namespace dev Để liệt kê các POD trong namespace mặc định:\nkubectl get pods Để liệt kê các POD trong một namespace khác, sử dụng lệnh kubectl get pods cùng với cờ hoặc đối số --namespace.\nkubectl get pods --namespace=kube-system Khi tạo một POD từ một tệp định nghĩa POD, POD sẽ được tạo trong namespace mặc định.\napiVersion: v1 kind: Pod metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx kubectl create -f pod-definition.yaml Để tạo POD với tệp định nghĩa POD trong một namespace khác, sử dụng tùy chọn --namespace.\nkubectl create -f pod-definition.yaml --namespace=dev Nếu bạn muốn đảm bảo rằng POD này luôn được tạo trong môi trường dev, thậm chí khi không chỉ định trong dòng lệnh, bạn có thể di chuyển định nghĩa --namespace vào tệp định nghĩa POD.\napiVersion: v1 kind: Pod metadata: name: myapp-pod namespace: dev labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx Để tạo một namespace mới, tạo một định nghĩa namespace như dưới đây và sau đó chạy lệnh kubectl create.\napiVersion: v1 kind: Namespace metadata: name: dev kubectl create -f namespace-dev.yaml Hoặc có thể sử dụng lệnh ngắn gọn:\nkubectl create namespace dev Mặc định, chúng ta sẽ ở trong một namespace mặc định. Để chuyển đổi sang một namespace cụ thể một cách vĩnh viễn, chạy lệnh sau:\nkubectl config set-context $(kubectl config current-context) --namespace=dev Để xem các POD trong tất cả các namespaces:\nkubectl get pods --all-namespaces Để giới hạn tài nguyên trong một namespace, tạo một resource quota. Để tạo một, bắt đầu với tệp định nghĩa ResourceQuota.\napiVersion: v1 kind: ResourceQuota metadata: name: compute-quota namespace: dev spec: hard: pods: \u0026#34;10\u0026#34; requests.cpu: \u0026#34;4\u0026#34; requests.memory: 5Gi limits.cpu: \u0026#34;10\u0026#34; limits.memory: 10Gi kubectl create -f compute-quota.yaml Tài liệu tham khảo Kubernetes: Kubernetes - Overview - Working with Objects - Namespaces Kubernetes - Tasks - Administer Cluster - Namespaces Walkthrough Kubernetes - Tasks - Administer Cluster - Namespaces Kubernetes - Tasks - Administer Cluster - Manage Resources - Quota Memory CPU - Namespace Kubernetes - Tasks - Access Application Cluster - List All Running Container Images "
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.4-kubernetes-services/",
	"title": "Dịch vụ Kubernetes",
	"tags": [],
	"description": "",
	"content": "Dịch vụ (Services) Dịch vụ Kubernetes cho phép giao tiếp giữa các thành phần khác nhau trong và ngoài ứng dụng.\nHãy xem qua một số khía cạnh khác về mạng lưới.\nGiao Tiếp Bên Ngoài (External Communication) Làm thế nào chúng ta, như một người dùng bên ngoài, có thể truy cập trang web?\nTừ node (Có thể tiếp cận ứng dụng như mong đợi) Từ thế giới bên ngoài (Điều này là mong đợi của chúng ta, mà không có gì ở giữa thì sẽ không thể tiếp cận được ứng dụng) Các Loại Dịch Vụ (Service Types) Có 3 loại dịch vụ trong Kubernetes:\n1. NodePort Nơi mà dịch vụ làm cho một cổng nội bộ có thể tiếp cận trên một cổng trên node.\napiVersion: v1 kind: Service metadata: name: myapp-service spec: type: NodePort ports: - targetPort: 80 port: 80 nodePort: 30008 Để kết nối dịch vụ với pod:\napiVersion: v1 kind: Service metadata: name: myapp-service spec: type: NodePort ports: - targetPort: 80 port: 80 nodePort: 30008 selector: app: myapp type: front-end Để tạo dịch vụ:\n$ kubectl create -f service-definition.yaml Để liệt kê các dịch vụ:\n$ kubectl get services Để truy cập ứng dụng từ dòng lệnh thay vì trình duyệt web:\n$ curl http://192.168.1.2:30008 2. ClusterIP Trong trường hợp này, dịch vụ tạo một Địa chỉ IP ảo trong cụm để cho phép giao tiếp giữa các dịch vụ khác nhau như một bộ máy chủ frontend và một bộ máy chủ backend.\n3. LoadBalancer Nơi mà dịch vụ cung cấp một trình cân bằng tải cho ứng dụng của chúng ta trong các nhà cung cấp đám mây được hỗ trợ.\n"
},
{
	"uri": "//localhost:1313/vi/4-ingress/",
	"title": "Ingress",
	"tags": [],
	"description": "",
	"content": "Chuẩn bị môi trường cho phần này: $ prepare-environment exposing/ingress Thao tác này sẽ thực hiện các thay đổi sau đây trong môi trường thí nghiệm của bạn:\nCài đặt AWS Load Balancer Controller trong cụm Amazon EKS Kubernetes Ingress là một tài nguyên API cho phép bạn quản lý truy cập HTTP(S) bên ngoài hoặc bên trong đến các dịch vụ Kubernetes đang chạy trong một cụm. Amazon Elastic Load Balancing Application Load Balancer (ALB) là một dịch vụ AWS phổ biến load balance lưu lượng vào đến lớp ứng dụng (lớp 7) qua nhiều mục tiêu, chẳng hạn như các instance Amazon EC2, trong một khu vực. ALB hỗ trợ nhiều tính năng bao gồm định tuyến dựa trên host hoặc đường dẫn, kết thúc TLS (Transport Layer Security), WebSockets, HTTP/2, tích hợp AWS WAF (Web Application Firewall), ghi nhật ký truy cập tích hợp và kiểm tra sức khỏe.\nTrong bài tập thực hành này, chúng ta sẽ tiết lộ ứng dụng mẫu của chúng ta bằng cách sử dụng một ALB với mô hình ingress của Kubernetes.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.5--clusterip/",
	"title": "ClusterIP trong Kubernetes",
	"tags": [],
	"description": "",
	"content": "Dịch vụ Kubernetes - ClusterIP Trong phần này, chúng ta sẽ tìm hiểu về dịch vụ ClusterIP trong Kubernetes.\nClusterIP Trong ngữ cảnh này, ClusterIP tạo ra một địa chỉ IP ảo bên trong cụm để cho phép các dịch vụ khác nhau giao tiếp với nhau như một nhóm máy chủ frontend và một nhóm máy chủ backend.\nCách thức tốt nhất để thiết lập kết nối giữa các dịch vụ hoặc tầng này là gì?\nDịch vụ Kubernetes có thể giúp chúng ta nhóm các pod lại với nhau và cung cấp một giao diện duy nhất để truy cập pod trong một nhóm.\nĐể tạo một dịch vụ loại ClusterIP:\napiVersion: v1 kind: Service metadata: name: back-end spec: type: ClusterIP ports: - targetPort: 80 port: 80 selector: app: myapp type: back-end Sau đó chạy lệnh sau để tạo dịch vụ:\n$ kubectl create -f service-definition.yaml Để liệt kê các dịch vụ:\n$ kubectl get services "
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]