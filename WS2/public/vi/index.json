[
{
	"uri": "/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu Kubernetes là một nền tảng nguồn mở, khả chuyển, có thể mở rộng để quản lý các ứng dụng được đóng gói và các service, giúp thuận lợi trong việc cấu hình và tự động hoá việc triển khai ứng dụng. Kubernetes là một hệ sinh thái lớn và phát triển nhanh chóng. Các dịch vụ, sự hỗ trợ và công cụ có sẵn rộng rãi.\nTên gọi Kubernetes có nguồn gốc từ tiếng Hy Lạp, có ý nghĩa là người lái tàu hoặc hoa tiêu. Google mở mã nguồn Kubernetes từ năm 2014. Kubernetes xây dựng dựa trên một thập kỷ rưỡi kinh nghiệm mà Google có được với việc vận hành một khối lượng lớn workload trong thực tế, kết hợp với các ý tưởng và thực tiễn tốt nhất từ cộng đồng.\nQuay ngược thời gian Chúng ta hãy xem tại sao Kubernetes rất hữu ích bằng cách quay ngược thời gian.\nThời đại triển khai theo cách truyền thống: Ban đầu, các ứng dụng được chạy trên các máy chủ vật lý. Không có cách nào để xác định ranh giới tài nguyên cho các ứng dụng trong máy chủ vật lý và điều này gây ra sự cố phân bổ tài nguyên. Ví dụ, nếu nhiều ứng dụng cùng chạy trên một máy chủ vật lý, có thể có những trường hợp một ứng dụng sẽ chiếm phần lớn tài nguyên hơn và kết quả là các ứng dụng khác sẽ hoạt động kém đi. Một giải pháp cho điều này sẽ là chạy từng ứng dụng trên một máy chủ vật lý khác nhau. Nhưng giải pháp này không tối ưu vì tài nguyên không được sử dụng đúng mức và rất tốn kém cho các tổ chức để có thể duy trì nhiều máy chủ vật lý như vậy.\nThời đại triển khai ảo hóa: Như một giải pháp, ảo hóa đã được giới thiệu. Nó cho phép bạn chạy nhiều Máy ảo (VM) trên CPU của một máy chủ vật lý. Ảo hóa cho phép các ứng dụng được cô lập giữa các VM và cung cấp mức độ bảo mật vì thông tin của một ứng dụng không thể được truy cập tự do bởi một ứng dụng khác.\nẢo hóa cho phép sử dụng tốt hơn các tài nguyên trong một máy chủ vật lý và cho phép khả năng mở rộng tốt hơn vì một ứng dụng có thể được thêm hoặc cập nhật dễ dàng, giảm chi phí phần cứng và hơn thế nữa. Với ảo hóa, bạn có thể có một tập hợp các tài nguyên vật lý dưới dạng một cụm các máy ảo sẵn dùng.\nMỗi VM là một máy tính chạy tất cả các thành phần, bao gồm cả hệ điều hành riêng của nó, bên trên phần cứng được ảo hóa.\nThời đại triển khai Container: Các container tương tự như VM, nhưng chúng có tính cô lập để chia sẻ Hệ điều hành (HĐH) giữa các ứng dụng. Do đó, container được coi là nhẹ (lightweight). Tương tự như VM, một container có hệ thống tệp (filesystem), CPU, bộ nhớ, process space, v.v. Khi chúng được tách rời khỏi cơ sở hạ tầng bên dưới, chúng có thể khả chuyển (portable) trên cloud hoặc các bản phân phối Hệ điều hành.\nCác container đã trở nên phổ biến vì chúng có thêm nhiều lợi ích, chẳng hạn như:\nTạo mới và triển khai ứng dụng Agile: gia tăng tính dễ dàng và hiệu quả của việc tạo các container image so với việc sử dụng VM image. Phát triển, tích hợp và triển khai liên tục: cung cấp khả năng build và triển khai container image thường xuyên và đáng tin cậy với việc rollbacks dễ dàng, nhanh chóng. Phân biệt giữa Dev và Ops: tạo các images của các application container tại thời điểm build/release thay vì thời gian triển khai, do đó phân tách các ứng dụng khỏi hạ tầng. Khả năng quan sát không chỉ hiển thị thông tin và các metric ở mức Hệ điều hành, mà còn cả application health và các tín hiệu khác. Tính nhất quán về môi trường trong suốt quá trình phát triển, testing và trong production: Chạy tương tự trên laptop như trên cloud. Tính khả chuyển trên cloud và các bản phân phối HĐH: Chạy trên Ubuntu, RHEL, CoreOS, on-premises, Google Kubernetes Engine và bất kì nơi nào khác. Quản lý tập trung ứng dụng: Tăng mức độ trừu tượng từ việc chạy một Hệ điều hành trên phần cứng ảo hóa sang chạy một ứng dụng trên một HĐH bằng logical resources. Các micro-services phân tán, elastic: ứng dụng được phân tách thành các phần nhỏ hơn, độc lập và thể được triển khai và quản lý một cách linh hoạt - chứ không phải một app nguyên khối (monolithic). Cô lập các tài nguyên: dự đoán hiệu năng ứng dụng Sử dụng tài nguyên: hiệu quả Tại sao bạn cần Kubernetes và nó có thể làm những gì? Các container là một cách tốt để đóng gói và chạy các ứng dụng của bạn. Trong môi trường production, bạn cần quản lý các container chạy các ứng dụng và đảm bảo rằng không có khoảng thời gian downtime. Ví dụ, nếu một container bị tắt đi, một container khác cần phải khởi động lên. Điều này sẽ dễ dàng hơn nếu được xử lý bởi một hệ thống.\nĐó là cách Kubernetes đến với chúng ta. Kubernetes cung cấp cho bạn một framework để chạy các hệ phân tán một cách mạnh mẽ. Nó đảm nhiệm việc nhân rộng và chuyển đổi dự phòng cho ứng dụng của bạn, cung cấp các mẫu deployment và hơn thế nữa. Ví dụ, Kubernetes có thể dễ dàng quản lý một triển khai canary cho hệ thống của bạn.\nKubernetes cung cấp cho bạn:\nService discovery và cân bằng tải\nKubernetes có thể expose một container sử dụng DNS hoặc địa chỉ IP của riêng nó. Nếu lượng traffic truy cập đến một container cao, Kubernetes có thể cân bằng tải và phân phối lưu lượng mạng (network traffic) để việc triển khai được ổn định. Điều phối bộ nhớ\nKubernetes cho phép bạn tự động mount một hệ thống lưu trữ mà bạn chọn, như local storages, public cloud providers, v.v. Tự động rollouts và rollbacks\nBạn có thể mô tả trạng thái mong muốn cho các container được triển khai dùng Kubernetes và nó có thể thay đổi trạng thái thực tế sang trạng thái mong muốn với tần suất được kiểm soát. Ví dụ, bạn có thể tự động hoá Kubernetes để tạo mới các container cho việc triển khai của bạn, xoá các container hiện có và áp dụng tất cả các resource của chúng vào container mới. Đóng gói tự động\nBạn cung cấp cho Kubernetes một cluster gồm các node mà nó có thể sử dụng để chạy các tác vụ được đóng gói (containerized task). Bạn cho Kubernetes biết mỗi container cần bao nhiêu CPU và bộ nhớ (RAM). Kubernetes có thể điều phối các container đến các node để tận dụng tốt nhất các resource của bạn. Tự phục hồi\nKubernetes khởi động lại các containers bị lỗi, thay thế các container, xoá các container không phản hồi lại cấu hình health check do người dùng xác định và không cho các client biết đến chúng cho đến khi chúng sẵn sàng hoạt động. Quản lý cấu hình và bảo mật\nKubernetes cho phép bạn lưu trữ và quản lý các thông tin nhạy cảm như: password, OAuth token và SSH key. Bạn có thể triển khai và cập nhật lại secret và cấu hình ứng dụng mà không cần build lại các container image và không để lộ secret trong cấu hình stack của bạn. Kubernetes không phải là gì? Kubernetes không phải là một hệ thống PaaS (Nền tảng như một Dịch vụ) truyền thống, toàn diện. Do Kubernetes hoạt động ở tầng container chứ không phải ở tầng phần cứng, nó cung cấp một số tính năng thường áp dụng chung cho các dịch vụ PaaS, như triển khai, nhân rộng, cân bằng tải, ghi nhật ký và giám sát. Tuy nhiên, Kubernetes không phải là cấu trúc nguyên khối và các giải pháp mặc định này là tùy chọn và có thể cắm được (pluggable).\nKubernetes:\nKhông giới hạn các loại ứng dụng được hỗ trợ. Kubernetes nhằm mục đích hỗ trợ một khối lượng công việc cực kỳ đa dạng, bao gồm cả stateless, stateful và xử lý dữ liệu. Nếu một ứng dụng có thể chạy trong một container, nó sẽ chạy rất tốt trên Kubernetes. Không triển khai mã nguồn và không build ứng dụng của bạn. Quy trình CI/CD được xác định bởi tổ chức cũng như các yêu cầu kỹ thuật. Không cung cấp các service ở mức ứng dụng, như middleware (ví dụ, các message buses), các framework xử lý dữ liệu (ví dụ, Spark), cơ sở dữ liệu (ví dụ, MySQL), bộ nhớ cache, cũng như hệ thống lưu trữ của cluster (ví dụ, Ceph). Các thành phần như vậy có thể chạy trên Kubernetes và/hoặc có thể được truy cập bởi các ứng dụng chạy trên Kubernetes thông qua các cơ chế di động, chẳng hạn như Open Service Broker. Không bắt buộc các giải pháp ghi lại nhật ký (logging), giám sát (monitoring) hoặc cảnh báo (alerting). Nó cung cấp một số sự tích hợp như proof-of-concept, và cơ chế để thu thập và xuất các số liệu. Không cung cấp, không bắt buộc một cấu hình ngôn ngữ/hệ thống (ví dụ: Jsonnet). Nó cung cấp một API khai báo có thể được targeted bởi các hình thức khai báo tùy ý. Không cung cấp cũng như áp dụng bất kỳ cấu hình toàn diện, bảo trì, quản lý hoặc hệ thống tự phục hồi. Ngoài ra, Kubernetes không phải là một hệ thống điều phối đơn thuần. Trong thực tế, nó loại bỏ sự cần thiết của việc điều phối. Định nghĩa kỹ thuật của điều phối là việc thực thi một quy trình công việc được xác định: đầu tiên làm việc A, sau đó là B rồi sau chót là C. Ngược lại, Kubernetes bao gồm một tập các quy trình kiểm soát độc lập, có thể kết hợp, liên tục điều khiển trạng thái hiện tại theo trạng thái mong muốn đã cho. Nó không phải là vấn đề làm thế nào bạn có thể đi được từ A đến C. Kiểm soát tập trung cũng không bắt buộc. Điều này dẫn đến một hệ thống dễ sử dụng hơn, mạnh mẽ hơn, linh hoạt hơn và có thể mở rộng. "
},
{
	"uri": "/vi/3-aws-load-balancer-controller/3.1-introduction/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Chúng tôi xác nhận rằng các dịch vụ microservices của chúng tôi chỉ có thể truy cập nội bộ bằng cách nhìn vào các tài nguyên Dịch vụ hiện tại trong cụm:\n$ kubectl get svc -l app.kubernetes.io/created-by=eks-workshop -A NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE assets assets ClusterIP 172.20.119.246 \u0026lt;none\u0026gt; 80/TCP 1h carts carts ClusterIP 172.20.180.149 \u0026lt;none\u0026gt; 80/TCP 1h carts carts-dynamodb ClusterIP 172.20.92.137 \u0026lt;none\u0026gt; 8000/TCP 1h catalog catalog ClusterIP 172.20.83.84 \u0026lt;none\u0026gt; 80/TCP 1h catalog catalog-mysql ClusterIP 172.20.181.252 \u0026lt;none\u0026gt; 3306/TCP 1h checkout checkout ClusterIP 172.20.77.176 \u0026lt;none\u0026gt; 80/TCP 1h checkout checkout-redis ClusterIP 172.20.32.208 \u0026lt;none\u0026gt; 6379/TCP 1h orders orders ClusterIP 172.20.146.72 \u0026lt;none\u0026gt; 80/TCP 1h orders orders-mysql ClusterIP 172.20.54.235 \u0026lt;none\u0026gt; 3306/TCP 1h rabbitmq rabbitmq ClusterIP 172.20.107.54 \u0026lt;none\u0026gt; 5672/TCP,4369/TCP,25672/TCP,15672/TCP 1h ui ui ClusterIP 172.20.62.119 \u0026lt;none\u0026gt; 80/TCP 1h Tất cả các thành phần ứng dụng của chúng tôi hiện đang sử dụng các dịch vụ ClusterIP, chỉ cho phép truy cập đến các công việc khác trong cùng một cụm Kubernetes. Để người dùng có thể truy cập ứng dụng của chúng tôi, chúng tôi cần phải tiết lộ ứng dụng ui, và trong ví dụ này, chúng tôi sẽ làm điều đó bằng cách sử dụng Dịch vụ Kubernetes loại LoadBalancer.\nTrước tiên, hãy xem xét cẩn thận thông số kỹ thuật hiện tại của Dịch vụ cho thành phần ui:\n$ kubectl -n ui describe service ui Name: ui Namespace: ui Labels: app.kubernetes.io/component=service app.kubernetes.io/created-by: eks-workshop app.kubernetes.io/instance=ui app.kubernetes.io/managed-by=Helm app.kubernetes.io/name=ui helm.sh/chart=ui-0.0.1 Annotations: \u0026lt;none\u0026gt; Selector: app.kubernetes.io/component=service,app.kubernetes.io/instance=ui,app.kubernetes.io/name=ui Type: ClusterIP IP Family Policy: SingleStack IP Families: IPv4 IP: 172.20.62.119 IPs: 172.20.62.119 Port: http 80/TCP TargetPort: http/TCP Endpoints: 10.42.105.38:8080 Session Affinity: None Events: \u0026lt;none\u0026gt; Như chúng ta đã thấy trước đó, hiện đang sử dụng loại ClusterIP và nhiệm vụ của chúng tôi trong module này là thay đổi điều này để giao diện người dùng của cửa hàng bán lẻ có thể truy cập thông qua Internet công cộng.\n"
},
{
	"uri": "/vi/4-ingress/4.1-introduction/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Hiện tại không có tài nguyên Ingress nào trong cụm của chúng ta, bạn có thể kiểm tra bằng lệnh sau:\n$ kubectl get ingress -n ui Không tìm thấy tài nguyên nào trong không gian tên ui. Cũng không có tài nguyên Dịch vụ kiểu LoadBalancer, bạn có thể xác nhận bằng lệnh sau:\n$ kubectl get svc -n ui TÊN LOẠI ĐỊA CHỈ CLUSTER ĐỊA CHỈ NGOẠI CỔNG(S) TUỔI ui ClusterIP 10.100.221.103 \u0026lt;none\u0026gt; 80/TCP 29 phút "
},
{
	"uri": "/vi/",
	"title": "Kubernetes trên AWS",
	"tags": [],
	"description": "",
	"content": "Kubernetes trên AWS Kubernetes là một nền tảng mã nguồn mở, linh hoạt, có khả năng mở rộng, phục vụ việc quản lý các ứng dụng được đóng gói và các dịch vụ liên quan, giúp việc cấu hình và tự động hóa quá trình triển khai ứng dụng trở nên thuận tiện hơn. Được biết đến như một hệ sinh thái lớn và phát triển nhanh chóng, Kubernetes cung cấp sự hỗ trợ rộng rãi qua các dịch vụ và công cụ đa dạng.\nTên Kubernetes bắt nguồn từ tiếng Hy Lạp, nghĩa là người lái tàu hoặc hoa tiêu. Kubernetes được Google công bố mã nguồn vào năm 2014, dựa trên gần một thập kỷ kinh nghiệm quản lý workload lớn trong thực tế của Google, kết hợp với các ý tưởng và best practices từ cộng đồng.\nQuay ngược thời gian Hãy xem xét tại sao Kubernetes lại quan trọng thông qua việc nhìn lại quá khứ.\nThời kỳ triển khai truyền thống: Ban đầu, các ứng dụng được chạy trực tiếp trên máy chủ vật lý, khiến việc phân bổ tài nguyên gặp khó khăn do không có cơ chế xác định ranh giới tài nguyên cho từng ứng dụng. Cách tiếp cận này dẫn đến nguy cơ một ứng dụng có thể sử dụng quá nhiều tài nguyên, ảnh hưởng đến hoạt động của các ứng dụng khác. Giải pháp là chạy mỗi ứng dụng trên một máy chủ vật lý riêng biệt, nhưng điều này lại không hiệu quả về mặt chi phí và tài nguyên.\nThời kỳ triển khai ảo hóa: Ảo hóa được giới thiệu như một giải pháp cho phép chạy nhiều Máy ảo (VM) trên cùng một máy chủ vật lý, giúp cô lập ứng dụng và tăng cường bảo mật. Ảo hóa cũng giúp cải thiện hiệu quả sử dụng tài nguyên và khả năng mở rộng.\nThời kỳ triển khai Container: Container giống như VM nhưng nhẹ hơn và chia sẻ Hệ điều hành (HĐH) với nhau. Container mang lại nhiều lợi ích như tạo mới và triển khai ứng dụng nhanh chóng, phát triển và triển khai liên tục, phân biệt rõ ràng giữa quá trình phát triển và vận hành, cung cấp tính nhất quán qua các môi trường, khả năng di chuyển giữa các cloud và HĐH, và quản lý ứng dụng tập trung.\nTại sao bạn cần Kubernetes và nó có thể làm gì? Container là phương tiện hiệu quả để đóng gói và chạy ứng dụng của bạn. Trong môi trường sản xuất, cần có cơ chế quản lý các container một cách hiệu quả, đảm bảo không có downtime. Kubernetes giúp quản lý các hệ thống phân tán mạnh mẽ, tự động hóa việc nhân rộng, cung cấp các mẫu triển khai và nhiều hơn nữa.\nKubernetes mang lại:\nPhát hiện dịch vụ và cân bằng tải Điều phối bộ nhớ Tự động rollouts và rollbacks Đóng gói tự động Tự phục hồi Quản lý cấu hình và bảo mật Những gì Kubernetes không phải là Kubernetes không phải là một hệ thống PaaS truyền thống, toàn diện. Nó hoạt động ở tầng container, cung cấp tính năng giống như PaaS như triển khai, nhân rộng, cân bằng tải, nhưng là một giải pháp linh hoạt và có thể mở rộng, không giới hạn loại ứng dụng được hỗ trợ, không triển khai mã nguồn hoặc build ứng dụng, không cung cấp dịch vụ ứng dụng cấp cao như middleware, databases, không bắt buộc sử dụng các giải pháp ghi nhật ký, giám sát hoặc cảnh báo, và không cung cấp hoặc áp dụng bất kỳ cấu hình toàn diện, bảo trì, quản lý hoặc hệ thống tự phục hồi. Kubernetes loại bỏ nhu cầu về điều phối truyền thống, thay vào đó là kiểm soát liên tục từ trạng thái hiện tại sang trạng thái mong muốn.\n"
},
{
	"uri": "/vi/1-introduce/1.1-replicasets/",
	"title": "ReplicaSets",
	"tags": [],
	"description": "",
	"content": "Trong phần này, chúng ta sẽ tìm hiểu về các khái niệm sau:\nReplicaSet Controllers là bộ não đằng sau Kubernetes. Replica là gì và tại sao chúng ta cần một replication controller?\nSự khác biệt giữa ReplicaSet và Replication Controller Replication Controller là công nghệ cũ được thay thế bằng ReplicaSet. ReplicaSet là cách mới để thiết lập replication. Tạo một Replication Controller File Định nghĩa Replication Controller\napiVersion: v1 kind: ReplicationController metadata: name: myapp-rc labels: app: myapp type: front-end spec: template: metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx replicas: 3 Để tạo replication controller\n$ kubectl create -f rc-definition.yaml Để liệt kê tất cả các replication controllers\n$ kubectl get replicationcontroller Để liệt kê các pod được khởi chạy bởi replication controller\n$ kubectl get pods Tạo một ReplicaSet File Định nghĩa ReplicaSet\napiVersion: apps/v1\rkind: ReplicaSet\rmetadata:\rname: myapp-replicaset\rlabels:\rapp: myapp\rtype: front-end\rspec:\rtemplate:\rmetadata:\rname: myapp-pod\rlabels:\rapp: myapp\rtype: front-end\rspec:\rcontainers:\r- name: nginx-container\rimage: nginx\rreplicas: 3\rselector:\rmatchLabels:\rtype: front-end ReplicaSet yêu cầu một định nghĩa selector so với Replication Controller. Để tạo ReplicaSet\n$ kubectl create -f replicaset-definition.yaml Để liệt kê tất cả các ReplicaSet\n$ kubectl get replicaset Để liệt kê các pod được khởi chạy bởi ReplicaSet\n$ kubectl get pods Nhãn và Selector Vấn đề với Nhãn và Selector là gì? Tại sao chúng ta đánh dấu các pod và đối tượng trong Kubernetes?\nLàm thế nào để mở rộng ReplicaSet Có nhiều cách để mở rộng ReplicaSet Cách đầu tiên là cập nhật số lượng bản sao trong file định nghĩa replicaset-definition.yaml. Ví dụ: replicas: 6 và sau đó chạy apiVersion: apps/v1\rkind: ReplicaSet\rmetadata:\rname: myapp-replicaset\rlabels:\rapp: myapp\rtype: front-end\rspec:\rtemplate:\rmetadata:\rname: myapp-pod\rlabels:\rapp: myapp\rtype: front-end\rspec:\rcontainers:\r- name: nginx-container\rimage: nginx\rreplicas: 6\rselector:\rmatchLabels:\rtype: front-end $ kubectl apply -f replicaset-definition.yaml Cách thứ hai là sử dụng lệnh kubectl scale.\n$ kubectl scale --replicas=6 -f replicaset-definition.yaml Cách thứ ba là sử dụng lệnh kubectl scale với loại và tên\n$ kubectl scale --replicas=6 replicaset myapp-replicaset Tài liệu Tham khảo K8s: https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/ https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/ "
},
{
	"uri": "/vi/2-prerequiste/",
	"title": "Các Bước Chuẩn Bị",
	"tags": [],
	"description": "",
	"content": "Các Bước Chuẩn Bị Chuẩn bị môi trường cho phần này: $ prepare-environment exposing/load-balancer Thao tác này sẽ thực hiện các thay đổi sau vào môi trường thí nghiệm của bạn:\nCài đặt AWS Load Balancer Controller trong cụm Amazon EKS Bạn có thể xem Terraform áp dụng các thay đổi này tại đây.\nKubernetes sử dụng dịch vụ để phơi bày các pod ra bên ngoài một cụm. Một trong những cách phổ biến nhất để sử dụng dịch vụ trong AWS là với kiểu LoadBalancer. Với một tệp YAML đơn giản khai báo tên dịch vụ, cổng và bộ chọn nhãn, bộ điều khiển đám mây sẽ tự động cung cấp một bộ cân bằng tải cho bạn.\napiVersion: v1 kind: Service metadata: name: search-svc # tên của dịch vụ của chúng tôi spec: type: loadBalancer selector: app: SearchApp # các pod được triển khai với nhãn app=SearchApp ports: - port: 80 Điều này rất tuyệt vì tính đơn giản của việc đặt một bộ cân bằng tải trước ứng dụng của bạn. Đặc tả dịch vụ đã được mở rộng qua các năm với các chú thích và cấu hình bổ sung. Một lựa chọn thứ hai là sử dụng quy tắc nhập và một bộ điều khiển nhập để định tuyến lưu lượng bên ngoài vào các pod Kubernetes.\nTrong chương này, chúng tôi sẽ thể hiện cách phơi bày một ứng dụng đang chạy trong cụm EKS ra Internet bằng cách sử dụng một Bộ cân bằng Tải Mạng ở tầng 4.\n"
},
{
	"uri": "/vi/1-introduce/1.2-deployments/",
	"title": "Deployments",
	"tags": [],
	"description": "",
	"content": "Kubernetes Deployments Trong phần này, chúng ta sẽ tìm hiểu về các triển khai (deployments) trong Kubernetes.\nTriển khai (Deployment) là một đối tượng trong Kubernetes.\napiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: myapp-deployment\rlabels:\rapp: myapp\rtype: front-end\rspec:\rtemplate:\rmetadata:\rname: myapp-pod\rlabels:\rapp: myapp\rtype: front-end\rspec:\rcontainers:\r- name: nginx-container\rimage: nginx\rreplicas: 3\rselector:\rmatchLabels:\rtype: front-end Sau khi tệp này đã sẵn sàng, tạo triển khai bằng cách sử dụng tệp định nghĩa triển khai:\n$ kubectl create -f deployment-definition.yaml Để xem triển khai đã được tạo:\n$ kubectl get deployment Triển khai tự động tạo một ReplicaSet. Để xem các ReplicaSet:\n$ kubectl get replicaset Các ReplicaSet cuối cùng sẽ tạo ra các POD. Để xem các POD:\n$ kubectl get pods Để xem tất cả các đối tượng cùng một lúc:\n$ kubectl get all K8s Reference Docs: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/ https://kubernetes.io/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/ https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/ https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/ "
},
{
	"uri": "/vi/4-ingress/4.2-creating-the-ingress/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Hãy tạo một tài nguyên Ingress với bản mẫu sau:\nmanifests/modules/exposing/ingress/creating-ingress/ingress.yaml Điều này sẽ khiến AWS Load Balancer Controller tạo ra một Application Load Balancer và cấu hình nó để định tuyến lưu lượng vào các Pod cho ứng dụng ui.\n$ kubectl apply -k ~/environment/eks-workshop/modules/exposing/ingress/creating-ingress Hãy kiểm tra đối tượng Ingress đã được tạo:\n$ kubectl get ingress ui -n ui NAME CLASS HOSTS ADDRESS PORTS AGE ui alb * k8s-ui-ui-1268651632.us-west-2.elb.amazonaws.com 80 15s ALB sẽ mất vài phút để cấu hình và đăng ký các mục tiêu của nó, vì vậy hãy dành chút thời gian để xem xét kỹ hơn về ALB được tạo cho Ingress này để xem cách nó được cấu hình:\n$ aws elbv2 describe-load-balancers --query \u0026#39;LoadBalancers[?contains(LoadBalancerName, `k8s-ui-ui`) == `true`]\u0026#39; [ { \u0026#34;LoadBalancerArn\u0026#34;: \u0026#34;arn:aws:elasticloadbalancing:us-west-2:1234567890:loadbalancer/app/k8s-ui-ui-cb8129ddff/f62a7bc03db28e7c\u0026#34;, \u0026#34;DNSName\u0026#34;: \u0026#34;k8s-ui-ui-cb8129ddff-1888909706.us-west-2.elb.amazonaws.com\u0026#34;, \u0026#34;CanonicalHostedZoneId\u0026#34;: \u0026#34;Z1H1FL5HABSF5\u0026#34;, \u0026#34;CreatedTime\u0026#34;: \u0026#34;2022-09-30T03:40:00.950000+00:00\u0026#34;, \u0026#34;LoadBalancerName\u0026#34;: \u0026#34;k8s-ui-ui-cb8129ddff\u0026#34;, \u0026#34;Scheme\u0026#34;: \u0026#34;internet-facing\u0026#34;, \u0026#34;VpcId\u0026#34;: \u0026#34;vpc-0851f873025a2ece5\u0026#34;, \u0026#34;State\u0026#34;: { \u0026#34;Code\u0026#34;: \u0026#34;active\u0026#34; }, \u0026#34;Type\u0026#34;: \u0026#34;application\u0026#34;, \u0026#34;AvailabilityZones\u0026#34;: [ { \u0026#34;ZoneName\u0026#34;: \u0026#34;us-west-2b\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;subnet-00415f527bbbd999b\u0026#34;, \u0026#34;LoadBalancerAddresses\u0026#34;: [] }, { \u0026#34;ZoneName\u0026#34;: \u0026#34;us-west-2a\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;subnet-0264d4b9985bd8691\u0026#34;, \u0026#34;LoadBalancerAddresses\u0026#34;: [] }, { \u0026#34;ZoneName\u0026#34;: \u0026#34;us-west-2c\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;subnet-05cda6deed7f3da65\u0026#34;, \u0026#34;LoadBalancerAddresses\u0026#34;: [] } ], \u0026#34;SecurityGroups\u0026#34;: [ \u0026#34;sg-0f8e704ee37512eb2\u0026#34;, \u0026#34;sg-02af06ec605ef8777\u0026#34; ], \u0026#34;IpAddressType\u0026#34;: \u0026#34;ipv4\u0026#34; } ] Điều này nói cho chúng ta điều gì?\nALB có thể truy cập qua internet công cộng Nó sử dụng các subnet công cộng trong VPC của chúng ta Kiểm tra các mục tiêu trong nhóm mục tiêu đã được tạo bởi bộ điều khiển:\n$ ALB_ARN=$(aws elbv2 describe-load-balancers --query \u0026#39;LoadBalancers[?contains(LoadBalancerName, `k8s-ui-ui`) == `true`].LoadBalancerArn\u0026#39; | jq -r \u0026#39;.[0]\u0026#39;) $ TARGET_GROUP_ARN=$(aws elbv2 describe-target-groups --load-balancer-arn $ALB_ARN | jq -r \u0026#39;.TargetGroups[0].TargetGroupArn\u0026#39;) $ aws elbv2 describe-target-health --target-group-arn $TARGET_GROUP_ARN { \u0026#34;TargetHealthDescriptions\u0026#34;: [ { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;10.42.180.183\u0026#34;, \u0026#34;Port\u0026#34;: 8080, \u0026#34;AvailabilityZone\u0026#34;: \u0026#34;us-west-2c\u0026#34; }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;8080\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;healthy\u0026#34; } } ] } Vì chúng ta đã chỉ định sử dụng chế độ IP trong đối tượng Ingress của chúng ta, mục tiêu được đăng ký bằng địa chỉ IP của pod ui và cổng mà nó phục vụ lưu lượng.\nBạn cũng có thể kiểm tra ALB và các nhóm mục tiêu của nó trong bảng điều khiển bằng cách nhấp vào liên kết này:\nhttps://console.aws.amazon.com/ec2/home#LoadBalancers:tag:ingress.k8s.aws/stack=ui/ui;sort=loadBalancerName\nLấy URL từ tài nguyên Ingress:\n$ kubectl get ingress -n ui ui -o jsonpath=\u0026#34;{.status.loadBalancer.ingress[*].hostname}{\u0026#39;\\n\u0026#39;}\u0026#34; k8s-ui-uinlb-a9797f0f61.elb.us-west-2.amazonaws.com Để chờ cho đến khi cân bằng tải đã hoàn thành cấu hình, bạn có thể chạy lệnh này:\n$ wait-for-lb $(kubectl get ingress -n ui ui -o jsonpath=\u0026#34;{.status.loadBalancer.ingress[*].hostname}{\u0026#39;\\n\u0026#39;}\u0026#34;) Và truy cập vào trình duyệt web của bạn. Bạn sẽ thấy giao diện người dùng từ cửa hàng web được hiển thị và có thể duyệt qua trang web như một người dùng.\n"
},
{
	"uri": "/vi/3-aws-load-balancer-controller/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/vi/4-ingress/4.3-multiple-ingress-pattern/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Thường xuyên sử dụng nhiều đối tượng Ingress trong cùng một cụm EKS, ví dụ để tiết lộ nhiều khối lượng công việc khác nhau. Theo mặc định, mỗi Ingress sẽ dẫn đến việc tạo ra một ALB riêng biệt, nhưng chúng ta có thể tận dụng tính năng IngressGroup cho phép bạn nhóm nhiều nguồn tài nguyên Ingress lại với nhau. Bộ điều khiển sẽ tự động hợp nhất các quy tắc Ingress cho tất cả các Ingress trong IngressGroup và hỗ trợ chúng với một ALB duy nhất. Ngoài ra, hầu hết các chú thích được định nghĩa trên một Ingress chỉ áp dụng cho các đường dẫn được định nghĩa bởi Ingress đó.\nTrong ví dụ này, chúng ta sẽ tiết lộ API catalog thông qua cùng một ALB như thành phần ui, tận dụng định tuyến dựa trên đường dẫn để gửi yêu cầu đến dịch vụ Kubernetes phù hợp. Hãy kiểm tra xem chúng ta đã có thể truy cập vào API catalog chưa:\n$ ADDRESS=$(kubectl get ingress -n ui ui -o jsonpath=\u0026#34;{.status.loadBalancer.ingress[*].hostname}{\u0026#39;\\n\u0026#39;}\u0026#34;) $ curl $ADDRESS/catalogue Điều đầu tiên chúng ta sẽ làm là tạo lại Ingress cho thành phần ui, thêm chú thích alb.ingress.kubernetes.io/group.name:\nmanifests/modules/exposing/ingress/multiple-ingress/ingress-ui.yaml Bây giờ, hãy tạo một Ingress riêng cho thành phần catalog cũng sử dụng group.name tương tự:\nmanifests/modules/exposing/ingress/multiple-ingress/ingress-catalog.yaml Ingress này cũng đang cấu hình các quy tắc để định tuyến yêu cầu với tiền tố /catalogue đến thành phần catalog.\nÁp dụng các tài liệu này vào cụm:\n$ kubectl apply -k ~/environment/eks-workshop/modules/exposing/ingress/multiple-ingress Bây giờ chúng ta sẽ có hai đối tượng Ingress riêng biệt trong cụm của chúng ta:\n$ kubectl get ingress -l app.kubernetes.io/created-by=eks-workshop -A NAMESPACE NAME CLASS HOSTS ADDRESS PORTS AGE catalog catalog alb * k8s-retailappgroup-2c24c1c4bc-17962260.us-west-2.elb.amazonaws.com 80 2m21s ui ui alb * k8s-retailappgroup-2c24c1c4bc-17962260.us-west-2.elb.amazonaws.com 80 2m21s Lưu ý rằng ADDRESS của cả hai là cùng một URL, điều này là do cả hai đối tượng Ingress này đang được nhóm lại với nhau phía sau cùng một ALB.\nChúng ta có thể xem xét listener ALB để hiểu cách hoạt động này:\n$ ALB_ARN=$(aws elbv2 describe-load-balancers --query \u0026#39;LoadBalancers[?contains(LoadBalancerName, `k8s-retailappgroup`) == `true`].LoadBalancerArn\u0026#39; | jq -r \u0026#39;.[0]\u0026#39;) $ LISTENER_ARN=$(aws elbv2 describe-listeners --load-balancer-arn $ALB_ARN | jq -r \u0026#39;.Listeners[0].ListenerArn\u0026#39;) $ aws elbv2 describe-rules --listener-arn $LISTENER_ARN Kết quả của lệnh này sẽ cho thấy:\nCác yêu cầu với tiền tố đường dẫn /catalogue sẽ được gửi đến một nhóm mục tiêu cho dịch vụ catalog Mọi thứ khác sẽ được gửi đến một nhóm mục tiêu cho dịch vụ giao diện người dùng Như một dự phòng mặc định, có một mã lỗi 404 cho bất kỳ yêu cầu nào rơi vào các khe hở Bạn cũng có thể kiểm tra cấu hình ALB mới trong bảng điều khiển AWS:\nhttps://console.aws.amazon.com/ec2/home#LoadBalancers:tag:ingress.k8s.aws/stack=retail-app-group;sort=loadBalancerName\nĐể chờ cho đến khi cân bằng tải hoàn thành việc cung cấp, bạn có thể chạy lệnh này:\n$ wait-for-lb $(kubectl get ingress -n ui ui -o jsonpath=\u0026#34;{.status.loadBalancer.ingress[*].hostname}{\u0026#39;\\n\u0026#39;}\u0026#34;) Thử truy cập URL Ingress mới trong trình duyệt như trước để kiểm tra giao diện web vẫn hoạt động:\n$ kubectl get ingress -n ui ui -o jsonpath=\u0026#34;{.status.loadBalancer.ingress[*].hostname}{\u0026#39;\\n\u0026#39;}\u0026#34; k8s-ui-uinlb-a9797f0f61.elb.us-west-2.amazonaws.com Bây giờ hãy thử truy cập đường dẫn cụ thể mà chúng tôi đã định hướng đến dịch vụ catalog:\n$ ADDRESS=$(kubectl get ingress -n ui ui -o jsonpath=\u0026#34;{.status.loadBalancer.ingress[*].hostname}{\u0026#39;\\n\u0026#39;}\u0026#34;) $ curl $ADDRESS/catalogue | jq . Bạn sẽ nhận lại một tải về JSON từ dịch vụ catalog, minh họa rằng chúng tôi đã có thể tiếp cận nhiều dịch vụ Kubernetes thông qua cùng một ALB.\n"
},
{
	"uri": "/vi/1-introduce/1.3-namespaces/",
	"title": "Namespaces",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về Namespaces trong Kubernetes Trong phần này, chúng ta sẽ tìm hiểu về Namespaces.\nCho đến nay trong khóa học này, chúng ta đã tạo ra các đối tượng như PODs, Deployments và Services trong cluster của chúng ta. Mọi thứ chúng ta đã làm, chúng ta đã thực hiện trong một NAMESPACE.\nNamespace mặc định trong Kubernetes là không gian mặc định được tạo tự động khi Kubernetes được thiết lập ban đầu.\nkubectl get namespaces Bạn cũng có thể tạo các Namespaces của riêng mình.\nkubectl create namespace dev Để liệt kê các POD trong namespace mặc định:\nkubectl get pods Để liệt kê các POD trong một namespace khác, sử dụng lệnh kubectl get pods cùng với cờ hoặc đối số \u0026ndash;namespace.\nkubectl get pods --namespace=kube-system Khi tạo một POD từ một tệp định nghĩa POD, POD sẽ được tạo trong namespace mặc định.\napiVersion: v1\rkind: Pod\rmetadata:\rname: myapp-pod\rlabels:\rapp: myapp\rtype: front-end\rspec:\rcontainers:\r- name: nginx-container\rimage: nginx kubectl create -f pod-definition.yaml Để tạo POD với tệp định nghĩa POD trong một namespace khác, sử dụng tùy chọn \u0026ndash;namespace.\nkubectl create -f pod-definition.yaml --namespace=dev Nếu bạn muốn đảm bảo rằng POD này luôn được tạo trong môi trường dev, thậm chí khi không chỉ định trong dòng lệnh, bạn có thể di chuyển định nghĩa \u0026ndash;namespace vào tệp định nghĩa POD.\napiVersion: v1\rkind: Pod\rmetadata:\rname: myapp-pod\rnamespace: dev\rlabels:\rapp: myapp\rtype: front-end\rspec:\rcontainers:\r- name: nginx-container\rimage: nginx Để tạo một namespace mới, tạo một định nghĩa namespace như dưới đây và sau đó chạy lệnh kubectl create\napiVersion: v1\rkind: Namespace\rmetadata:\rname: dev kubectl create -f namespace-dev.yaml Hoặc có thể sử dụng lệnh ngắn gọn:\nkubectl create namespace dev Mặc định, chúng ta sẽ ở trong một namespace mặc định. Để chuyển đổi sang một namespace cụ thể một cách vĩnh viễn, chạy lệnh sau:\nkubectl config set-context $(kubectl config current-context) --namespace=dev Để xem các POD trong tất cả các namespaces:\nkubectl get pods --all-namespaces Để giới hạn tài nguyên trong một namespace, tạo một resource quota. Để tạo một, bắt đầu với tệp định nghĩa ResourceQuota.\napiVersion: v1\rkind: ResourceQuota\rmetadata:\rname: compute-quota\rnamespace: dev\rspec:\rhard:\rpods: \u0026#34;10\u0026#34;\rrequests.cpu: \u0026#34;4\u0026#34;\rrequests.memory: 5Gi\rlimits.cpu: \u0026#34;10\u0026#34;\rlimits.memory: 10Gi kubectl create -f compute-quota.yaml Tài liệu tham khảo Kubernetes: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/ https://kubernetes.io/docs/tasks/administer-cluster/namespaces-walkthrough/ https://kubernetes.io/docs/tasks/administer-cluster/namespaces/ https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/quota-memory-cpu-namespace/ https://kubernetes.io/docs/tasks/access-application-cluster/list-all-running-container-images/\n"
},
{
	"uri": "/vi/4-ingress/",
	"title": "Ingress",
	"tags": [],
	"description": "",
	"content": "Chuẩn bị môi trường cho phần này: $ prepare-environment exposing/ingress Thao tác này sẽ thực hiện các thay đổi sau đây trong môi trường thí nghiệm của bạn:\nCài đặt AWS Load Balancer Controller trong cụm Amazon EKS Bạn có thể xem Terraform áp dụng các thay đổi này tại đây.\nKubernetes Ingress là một tài nguyên API cho phép bạn quản lý truy cập HTTP(S) bên ngoài hoặc bên trong đến các dịch vụ Kubernetes đang chạy trong một cụm. Amazon Elastic Load Balancing Application Load Balancer (ALB) là một dịch vụ AWS phổ biến load balance lưu lượng vào đến lớp ứng dụng (lớp 7) qua nhiều mục tiêu, chẳng hạn như các instance Amazon EC2, trong một khu vực. ALB hỗ trợ nhiều tính năng bao gồm định tuyến dựa trên host hoặc đường dẫn, kết thúc TLS (Transport Layer Security), WebSockets, HTTP/2, tích hợp AWS WAF (Web Application Firewall), ghi nhật ký truy cập tích hợp và kiểm tra sức khỏe.\nTrong bài tập thực hành này, chúng ta sẽ tiết lộ ứng dụng mẫu của chúng ta bằng cách sử dụng một ALB với mô hình ingress của Kubernetes.\n"
},
{
	"uri": "/vi/1-introduce/1.4-kubernetes-services/",
	"title": "Kubernetes Services",
	"tags": [],
	"description": "",
	"content": "Dịch vụ (Services) Dịch vụ Kubernetes cho phép giao tiếp giữa các thành phần khác nhau trong và ngoài ứng dụng.\nHãy xem qua một số khía cạnh khác về mạng lưới.\nGiao Tiếp Bên Ngoài (External Communication) Làm thế nào chúng ta, như một người dùng bên ngoài, có thể truy cập trang web?\nTừ nút (Có thể tiếp cận ứng dụng như mong đợi) Từ thế giới bên ngoài (Điều này là mong đợi của chúng ta, mà không có gì ở giữa thì sẽ không thể tiếp cận được ứng dụng)\nCác Loại Dịch Vụ (Service Types) Có 3 loại dịch vụ trong Kubernetes:\n1. NodePort Nơi mà dịch vụ làm cho một cổng nội bộ có thể tiếp cận trên một cổng trên NÚT.\napiVersion: v1\rkind: Service\rmetadata:\rname: myapp-service\rspec:\rtype: NodePort\rports:\r- targetPort: 80\rport: 80\rnodePort: 30008 Để kết nối dịch vụ với pod:\napiVersion: v1\rkind: Service\rmetadata:\rname: myapp-service\rspec:\rtype: NodePort\rports:\r- targetPort: 80\rport: 80\rnodePort: 30008\rselector:\rapp: myapp\rtype: front-end Để tạo dịch vụ:\n$ kubectl create -f service-definition.yaml Để liệt kê các dịch vụ:\n$ kubectl get services Để truy cập ứng dụng từ dòng lệnh thay vì trình duyệt web:\n$ curl http://192.168.1.2:30008 2. ClusterIP Trong trường hợp này, dịch vụ tạo một Địa chỉ IP ảo trong cụm để cho phép giao tiếp giữa các dịch vụ khác nhau như một bộ máy chủ frontend và một bộ máy chủ backend.\n3. LoadBalancer Nơi mà dịch vụ cung cấp một trình cân bằng tải cho ứng dụng của chúng ta trong các nhà cung cấp đám mây được hỗ trợ.\n"
},
{
	"uri": "/vi/1-introduce/1.5-clusterip/",
	"title": "ClusterIP",
	"tags": [],
	"description": "",
	"content": "Kubernetes Services - ClusterIP Trong phần này, chúng ta sẽ xem xét về dịch vụ - ClusterIP trong Kubernetes.\nClusterIP Trong trường hợp này, dịch vụ tạo một IP ảo bên trong cụm để cho phép giao tiếp giữa các dịch vụ khác nhau như một tập hợp các máy chủ frontend và một tập hợp các máy chủ backend.\nCách thức phù hợp để thiết lập kết nối giữa các dịch vụ hoặc tầng này là gì?\nDịch vụ Kubernetes có thể giúp chúng ta nhóm các pod lại với nhau và cung cấp một giao diện duy nhất để truy cập pod trong một nhóm.\nĐể tạo một dịch vụ loại ClusterIP\napiVersion: v1\rkind: Service\rmetadata:\rname: back-end\rspec:\rtype: ClusterIP\rports:\r- targetPort: 80\rport: 80\rselector:\rapp: myapp\rtype: back-end Sau đó chạy lệnh sau để tạo dịch vụ:\n$ kubectl create -f service-definition.yaml Để liệt kê các dịch vụ\n$ kubectl get services "
},
{
	"uri": "/vi/3-aws-load-balancer-controller/3.2-creating-the-load-balancer/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "title: \u0026ldquo;Tạo load balancer\u0026rdquo; date: \u0026ldquo;r Sys.Date()\u0026rdquo; weight: 2 chapter: false pre: \u0026ldquo; 3.2 \u0026rdquo; Tạo load balancer Tạo một Dịch vụ Bổ sung để triển khai một Trình cân bằng tải với kustomization sau: manifests/modules/exposing/load-balancer/nlb/nlb.yaml Dịch vụ này sẽ tạo ra một Trình cân bằng tải Mạng lắng nghe trên cổng 80 và chuyển tiếp kết nối đến các Pod ui trên cổng 8080. Một NLB là một trình cân bằng tải tầng 4 hoạt động ở tầng TCP trong trường hợp của chúng tôi.\n$ kubectl apply -k ~/environment/eks-workshop/modules/exposing/load-balancer/nlb Hãy kiểm tra lại tài nguyên Dịch vụ cho ứng dụng ui:\n$ kubectl get service -n ui Chúng ta thấy hai tài nguyên riêng biệt, với mục nhập ui-nlb mới có kiểu LoadBalancer. Quan trọng nhất là lưu ý rằng nó có giá trị \u0026ldquo;địa chỉ IP bên ngoài\u0026rdquo;, đây là mục nhập DNS có thể được sử dụng để truy cập ứng dụng của chúng ta từ bên ngoài cụm Kubernetes.\nNLB sẽ mất vài phút để triển khai và đăng ký các mục tiêu của nó nên hãy dành thời gian để kiểm tra các tài nguyên trình cân bằng tải mà bộ điều khiển đã tạo ra.\nTrước tiên, hãy xem xét trình cân bằng tải:\n$ aws elbv2 describe-load-balancers --query \u0026#39;LoadBalancers[?contains(LoadBalancerName, `k8s-ui-uinlb`) == `true`]\u0026#39; [ { \u0026#34;LoadBalancerArn\u0026#34;: \u0026#34;arn:aws:elasticloadbalancing:us-west-2:1234567890:loadbalancer/net/k8s-ui-uinlb-e1c1ebaeb4/28a0d1a388d43825\u0026#34;, \u0026#34;DNSName\u0026#34;: \u0026#34;k8s-ui-uinlb-e1c1ebaeb4-28a0d1a388d43825.elb.us-west-2.amazonaws.com\u0026#34;, \u0026#34;CanonicalHostedZoneId\u0026#34;: \u0026#34;Z18D5FSROUN65G\u0026#34;, \u0026#34;CreatedTime\u0026#34;: \u0026#34;2022-11-17T04:47:30.516000+00:00\u0026#34;, \u0026#34;LoadBalancerName\u0026#34;: \u0026#34;k8s-ui-uinlb-e1c1ebaeb4\u0026#34;, \u0026#34;Scheme\u0026#34;: \u0026#34;internet-facing\u0026#34;, \u0026#34;VpcId\u0026#34;: \u0026#34;vpc-00be6fc048a845469\u0026#34;, \u0026#34;State\u0026#34;: { \u0026#34;Code\u0026#34;: \u0026#34;active\u0026#34; }, \u0026#34;Type\u0026#34;: \u0026#34;network\u0026#34;, \u0026#34;AvailabilityZones\u0026#34;: [ { \u0026#34;ZoneName\u0026#34;: \u0026#34;us-west-2c\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;subnet-0a2de0809b8ee4e39\u0026#34;, \u0026#34;LoadBalancerAddresses\u0026#34;: [] }, { \u0026#34;ZoneName\u0026#34;: \u0026#34;us-west-2a\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;subnet-0ff71604f5b58b2ba\u0026#34;, \u0026#34;LoadBalancerAddresses\u0026#34;: [] }, { \u0026#34;ZoneName\u0026#34;: \u0026#34;us-west-2b\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;subnet-0c584c4c6a831e273\u0026#34;, \u0026#34;LoadBalancerAddresses\u0026#34;: [] } ], \u0026#34;IpAddressType\u0026#34;: \u0026#34;ipv4\u0026#34; } ] Điều này nói với chúng ta gì?\nNLB có thể truy cập qua internet công cộng Nó sử dụng các mạng con công cộng trong VPC của chúng tôi Chúng ta cũng có thể kiểm tra các mục tiêu trong nhóm mục tiêu được tạo ra bởi bộ điều khiển:\n$ ALB_ARN=$(aws elbv2 describe-load-balancers --query \u0026#39;LoadBalancers[?contains(LoadBalancerName, `k8s-ui-uinlb`) == `true`].LoadBalancerArn\u0026#39; | jq -r \u0026#39;.[0]\u0026#39;) $ TARGET_GROUP_ARN=$(aws elbv2 describe-target-groups --load-balancer-arn $ALB_ARN | jq -r \u0026#39;.TargetGroups[0].TargetGroupArn\u0026#39;) $ aws elbv2 describe-target-health --target-group-arn $TARGET_GROUP_ARN { \u0026#34;TargetHealthDescriptions\u0026#34;: [ { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;i-06a12e62c14e0c39a\u0026#34;, \u0026#34;Port\u0026#34;: 31338 }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;31338\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;healthy\u0026#34; } }, { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;i-088e21d0af0f2890c\u0026#34;, \u0026#34;Port\u0026#34;: 31338 }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;31338\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;healthy\u0026#34; } }, { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;i-0fe2202d18299816f\u0026#34;, \u0026#34;Port\u0026#34;: 31338 }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;31338\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;healthy\u0026#34; } } ] } Đầu ra trên cho thấy chúng ta có 3 mục tiêu đã đăng ký vào trình cân bằng tải bằng các ID instance EC2 (i-) mỗi cái trên cùng một cổng. Lý do cho điều này là mặc định, Bộ Điều khiển Trình Cân bằng Tải AWS hoạt động ở \u0026ldquo;chế độ instance\u0026rdquo;, chuyển hướng lưu lượng đến các nút worker trong cụm EKS và cho phép kube-proxy chuyển tiếp lưu lượng đến các Pod cá nhân.\nBạn cũng có thể kiểm tra NLB trong bảng điều khiển bằng cách nhấp vào liên kết này:\nhttps://console.aws.amazon.com/ec2/home#LoadBalancers:tag:service.k8s.aws/stack=ui/ui-nlb;sort=loadBalancerName\n"
},
{
	"uri": "/vi/3-aws-load-balancer-controller/3.3-ip-mode/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "title: \u0026ldquo;IP mode\u0026rdquo; date: \u0026ldquo;r Sys.Date()\u0026rdquo; weight: 3 chapter: false pre: \u0026ldquo; 3.3 \u0026rdquo; IP mode Như đã đề cập trước đó, NLB chúng ta đã tạo đang hoạt động ở chế độ \u0026ldquo;instance mode\u0026rdquo;. Chế độ mục tiêu instance hỗ trợ các pod đang chạy trên các máy EC2 của AWS. Trong chế độ này, AWS NLB gửi lưu lượng đến các instance và kube-proxy trên các nút làm việc cá nhân chuyển tiếp nó đến các pod thông qua một hoặc nhiều nút làm việc trong cụm Kubernetes.\nBộ điều khiển Cân bằng Tải AWS cũng hỗ trợ tạo NLB hoạt động ở chế độ \u0026ldquo;IP mode\u0026rdquo;. Trong chế độ này, AWS NLB gửi lưu lượng trực tiếp đến các pod Kubernetes đằng sau dịch vụ, loại bỏ nhu cầu cho một bước nhảy mạng phụ qua các nút làm việc trong cụm Kubernetes. Chế độ mục tiêu IP hỗ trợ các pod đang chạy trên cả các máy EC2 của AWS và AWS Fargate.\nCó một số lý do mà chúng ta có thể muốn cấu hình NLB để hoạt động ở chế độ mục tiêu IP:\nTạo một đường mạng hiệu quả hơn cho các kết nối đến, bỏ qua kube-proxy trên nút làm việc EC2 Loại bỏ nhu cầu xem xét các khía cạnh như externalTrafficPolicy và các tùy chọn cấu hình khác nhau của nó Một ứng dụng đang chạy trên Fargate thay vì EC2 Tái cấu hình NLB Hãy tái cấu hình NLB của chúng ta để sử dụng chế độ IP và xem xét tác động của nó đối với cơ sở hạ tầng.\nĐây là đoạn mã patch chúng ta sẽ áp dụng để tái cấu hình Dịch vụ:\nmodules/exposing/load-balancer/ip-mode/nlb.yaml\rService/ui-nlb Áp dụng các bản mẫu với kustomize:\n$ kubectl apply -k ~/environment/eks-workshop/modules/exposing/load-balancer/ip-mode Sẽ mất vài phút để cấu hình của cân bằng tải được cập nhật. Chạy lệnh sau để đảm bảo chú thích được cập nhật:\n$ kubectl describe service/ui-nlb -n ui ... Annotations: service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip ... Bạn nên có thể truy cập ứng dụng bằng cùng một URL như trước đó, với NLB bây giờ sử dụng chế độ IP để tiết lộ ứng dụng của bạn.\n$ ALB_ARN=$(aws elbv2 describe-load-balancers --query \u0026#39;LoadBalancers[?contains(LoadBalancerName, `k8s-ui-uinlb`) == `true`].LoadBalancerArn\u0026#39; | jq -r \u0026#39;.[0]\u0026#39;) $ TARGET_GROUP_ARN=$(aws elbv2 describe-target-groups --load-balancer-arn $ALB_ARN | jq -r \u0026#39;.TargetGroups[0].TargetGroupArn\u0026#39;) $ aws elbv2 describe-target-health --target-group-arn $TARGET_GROUP_ARN { \u0026#34;TargetHealthDescriptions\u0026#34;: [ { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;10.42.180.183\u0026#34;, \u0026#34;Port\u0026#34;: 8080, \u0026#34;AvailabilityZone\u0026#34;: \u0026#34;us-west-2a\u0026#34; }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;8080\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;initial\u0026#34;, \u0026#34;Reason\u0026#34;: \u0026#34;Elb.RegistrationInProgress\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;Target registration is in progress\u0026#34; } } ] } Chú ý: Chúng ta đã chuyển từ 3 mục tiêu mà chúng ta đã quan sát trong phần trước đó thành chỉ một mục tiêu. Tại sao lại như vậy? Thay vì đăng ký các EC2 instances trong cụm EKS của chúng ta, bộ điều khiển cân bằng tải hiện đang đăng ký các Pods cá nhân và gửi lưu lượng trực tiếp, tận dụng AWS VPC CNI và sự thật rằng mỗi Pod đều có địa chỉ IP VPC cấp đầu.\nHãy mở rộng thành phần ui lên 3 bản sao và xem điều gì xảy ra:\n$ kubectl scale -n ui deployment/ui --replicas=3 $ kubectl wait --for=condition=Ready pod -n ui -l app.kubernetes.io/name=ui --timeout=60s Bây giờ hãy kiểm tra lại các mục tiêu của cân bằng tải:\n$ ALB_ARN=$(aws elbv2 describe-load-balancers --query \u0026#39;LoadBalancers[?contains(LoadBalancerName, `k8s-ui-uinlb`) == `true`].LoadBalancerArn\u0026#39; | jq -r \u0026#39;.[0]\u0026#39;) $ TARGET_GROUP_ARN=$(aws elbv2 describe-target-groups --load-balancer-arn $ALB_ARN | jq -r \u0026#39;.TargetGroups[0].TargetGroupArn\u0026#39;) $ aws elbv2 describe-target-health --target-group-arn $TARGET_GROUP_ARN { \u0026#34;TargetHealthDescriptions\u0026#34;: [ { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;10.42.180.181\u0026#34;, \u0026#34;Port\u0026#34;: 8080, \u0026#34;AvailabilityZone\u0026#34;: \u0026#34;us-west-2c\u0026#34; }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;8080\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;initial\u0026#34;, \u0026#34;Reason\u0026#34;: \u0026#34;Elb.RegistrationInProgress\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;Target registration is in progress\u0026#34; } }, { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;10.42.140.129\u0026#34;, \u0026#34;Port\u0026#34;: 8080, \u0026#34;AvailabilityZone\u0026#34;: \u0026#34;us-west-2a\u0026#34; }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;8080\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;healthy\u0026#34; } }, { \u0026#34;Target\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;10.42.105.38\u0026#34;, \u0026#34;Port\u0026#34;: 8080, \u0026#34;AvailabilityZone\u0026#34;: \u0026#34;us-west-2a\u0026#34; }, \u0026#34;HealthCheckPort\u0026#34;: \u0026#34;8080\u0026#34;, \u0026#34;TargetHealth\u0026#34;: { \u0026#34;State\u0026#34;: \u0026#34;initial\u0026#34;, \u0026#34;Reason\u0026#34;: \u0026#34;Elb.RegistrationInProgress\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;Target registration is in progress\u0026#34; } } ] } Như dự kiến, bây giờ chúng ta có 3 mục tiêu, khớp với số lượng bản sao trong Deployment ui.\nNếu bạn muốn chờ đợi để đảm bảo ứng dụng vẫn hoạt động như trước, hãy chạy lệnh sau. Nếu không, bạn có thể tiếp tục sang module tiếp theo.\n$ wait-for-lb $(kubectl get service -n ui ui-nlb -o jsonpath=\u0026#34;{.status.loadBalancer.ingress[*].hostname}{\u0026#39;\\n\u0026#39;}\u0026#34;) "
},
{
	"uri": "/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]