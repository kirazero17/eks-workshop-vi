[
{
	"uri": "/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu Trong bài wworkshop trước, chúng ta đã xác định các khái niệm về autoscaling compute, giờ đây chúng ta sẽ đi sâu vào các cách khác nhau để mở rộng tài nguyên và quản lý các công việc trong một cụm. Chúng ta sẽ tập trung vào hai cơ chế chính để tự động mở rộng:\nHorizontal Pod Autoscaler (HPA) Cluster Proportional Autoscaler (CPA) Trong chương này, chúng ta sẽ khám phá quá trình cấu hình và sử dụng Horizontal Pod Autoscaler (HPA) và Cluster Proportional Autoscaler (CPA) để quản lý các công việc trong một cụm.\n"
},
{
	"uri": "/vi/",
	"title": "Tự Động Mở Rộng trên AWS với Kubernetes",
	"tags": [],
	"description": "",
	"content": "Tự Động Mở Rộng trên AWS với Kubernetes Tự động mở rộng giám sát các khối công việc của bạn và tự động điều chỉnh dung lượng để duy trì hiệu suất ổn định, dự đoán được đồng thời tối ưu hóa chi phí. Khi sử dụng Kubernetes, có hai cơ chế chính có liên quan mà có thể được sử dụng để tự động mở rộng:\nCompute (Tính toán): Khi các pods được mở rộng, tính toán cơ bản trong một cụm Kubernetes cũng phải thích ứng bằng cách điều chỉnh số lượng hoặc kích thước của các nút worker được sử dụng để chạy các Pods. Pods: Vì các pods được sử dụng để chạy các khối công việc trong một cụm Kubernetes, việc mở rộng một khối công việc chủ yếu được thực hiện bằng cách mở rộng Pods theo chiều ngang hoặc theo chiều dọc để phản ứng với các tình huống như thay đổi tải trên một ứng dụng cụ thể. Trong chương này, chúng ta sẽ khám phá các cơ chế khác nhau có sẵn để tự động mở rộng cả số lượng pods và khả năng tính toán của một cụm.\n"
},
{
	"uri": "/vi/2-prerequiste/",
	"title": "Các Bước Chuẩn Bị",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/vi/3-horizontal-pod-autoscaler/",
	"title": "Horizontal Pod Autoscaler",
	"tags": [],
	"description": "",
	"content": "Horizontal Pod Autoscaler Trong bài lab này, chúng ta sẽ tìm hiểu về Horizontal Pod Autoscaler (HPA) để điều chỉnh tỷ lệ pod trong một deployment hoặc replica set. Nó được thực hiện như một tài nguyên API của Kubernetes và một controller. Tài nguyên xác định hành vi của controller. Bộ quản lý Controller thực hiện truy vấn sử dụng tài nguyên đối với các chỉ số được xác định trong mỗi định nghĩa HorizontalPodAutoscaler. Controller định kỳ điều chỉnh số lượng bản sao trong một replication controller hoặc deployment đến mục tiêu được chỉ định bởi người dùng bằng cách quan sát các chỉ số như sử dụng CPU trung bình, sử dụng bộ nhớ trung bình hoặc bất kỳ chỉ số tùy chỉnh nào khác. Nó lấy các chỉ số từ API tài nguyên (cho các chỉ số tài nguyên trên mỗi pod), hoặc API chỉ số tùy chỉnh (cho tất cả các chỉ số khác).\nBước chuẩn bị môi trường cho phần này:\n$ prepare-environment autoscaling/workloads/hpa Điều này sẽ thực hiện các thay đổi sau đây trong môi trường lab của bạn:\nCài đặt Kubernetes Metrics Server trong cluster Amazon EKS Kubernetes Metrics Server là một bộ tổng hợp có khả năng mở rộng và hiệu quả về dữ liệu sử dụng tài nguyên trong cluster của bạn. Nó cung cấp các chỉ số container cần thiết cho Horizontal Pod Autoscaler. Metrics server không được triển khai mặc định trong các cluster Amazon EKS.\n"
},
{
	"uri": "/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]