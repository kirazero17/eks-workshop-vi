[
{
	"uri": "//localhost:1313/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu Kubernetes là một nền tảng nguồn mở, khả chuyển, có thể mở rộng để quản lý các ứng dụng được đóng gói và các service, giúp thuận lợi trong việc cấu hình và tự động hoá việc triển khai ứng dụng. Kubernetes là một hệ sinh thái lớn và phát triển nhanh chóng. Các dịch vụ, sự hỗ trợ và công cụ có sẵn rộng rãi.\nTên gọi Kubernetes có nguồn gốc từ tiếng Hy Lạp, có ý nghĩa là người lái tàu hoặc hoa tiêu. Google mở mã nguồn Kubernetes từ năm 2014. Kubernetes xây dựng dựa trên một thập kỷ rưỡi kinh nghiệm mà Google có được với việc vận hành một khối lượng lớn workload trong thực tế, kết hợp với các ý tưởng và thực tiễn tốt nhất từ cộng đồng.\nQuay ngược thời gian Chúng ta hãy xem tại sao Kubernetes rất hữu ích bằng cách quay ngược thời gian.\nThời đại triển khai theo cách truyền thống: Ban đầu, các ứng dụng được chạy trên các máy chủ vật lý. Không có cách nào để xác định ranh giới tài nguyên cho các ứng dụng trong máy chủ vật lý và điều này gây ra sự cố phân bổ tài nguyên. Ví dụ, nếu nhiều ứng dụng cùng chạy trên một máy chủ vật lý, có thể có những trường hợp một ứng dụng sẽ chiếm phần lớn tài nguyên hơn và kết quả là các ứng dụng khác sẽ hoạt động kém đi. Một giải pháp cho điều này sẽ là chạy từng ứng dụng trên một máy chủ vật lý khác nhau. Nhưng giải pháp này không tối ưu vì tài nguyên không được sử dụng đúng mức và rất tốn kém cho các tổ chức để có thể duy trì nhiều máy chủ vật lý như vậy.\nThời đại triển khai ảo hóa: Như một giải pháp, ảo hóa đã được giới thiệu. Nó cho phép bạn chạy nhiều Máy ảo (VM) trên CPU của một máy chủ vật lý. Ảo hóa cho phép các ứng dụng được cô lập giữa các VM và cung cấp mức độ bảo mật vì thông tin của một ứng dụng không thể được truy cập tự do bởi một ứng dụng khác.\nẢo hóa cho phép sử dụng tốt hơn các tài nguyên trong một máy chủ vật lý và cho phép khả năng mở rộng tốt hơn vì một ứng dụng có thể được thêm hoặc cập nhật dễ dàng, giảm chi phí phần cứng và hơn thế nữa. Với ảo hóa, bạn có thể có một tập hợp các tài nguyên vật lý dưới dạng một cụm các máy ảo sẵn dùng.\nMỗi VM là một máy tính chạy tất cả các thành phần, bao gồm cả hệ điều hành riêng của nó, bên trên phần cứng được ảo hóa.\nThời đại triển khai Container: Các container tương tự như VM, nhưng chúng có tính cô lập để chia sẻ Hệ điều hành (HĐH) giữa các ứng dụng. Do đó, container được coi là nhẹ (lightweight). Tương tự như VM, một container có hệ thống tệp (filesystem), CPU, bộ nhớ, process space, v.v. Khi chúng được tách rời khỏi cơ sở hạ tầng bên dưới, chúng có thể khả chuyển (portable) trên cloud hoặc các bản phân phối Hệ điều hành.\nCác container đã trở nên phổ biến vì chúng có thêm nhiều lợi ích, chẳng hạn như:\nTạo mới và triển khai ứng dụng Agile: gia tăng tính dễ dàng và hiệu quả của việc tạo các container image so với việc sử dụng VM image. Phát triển, tích hợp và triển khai liên tục: cung cấp khả năng build và triển khai container image thường xuyên và đáng tin cậy với việc rollbacks dễ dàng, nhanh chóng. Phân biệt giữa Dev và Ops: tạo các images của các application container tại thời điểm build/release thay vì thời gian triển khai, do đó phân tách các ứng dụng khỏi hạ tầng. Khả năng quan sát không chỉ hiển thị thông tin và các metric ở mức Hệ điều hành, mà còn cả application health và các tín hiệu khác. Tính nhất quán về môi trường trong suốt quá trình phát triển, testing và trong production: Chạy tương tự trên laptop như trên cloud. Tính khả chuyển trên cloud và các bản phân phối HĐH: Chạy trên Ubuntu, RHEL, CoreOS, on-premises, Google Kubernetes Engine và bất kì nơi nào khác. Quản lý tập trung ứng dụng: Tăng mức độ trừu tượng từ việc chạy một Hệ điều hành trên phần cứng ảo hóa sang chạy một ứng dụng trên một HĐH bằng logical resources. Các micro-services phân tán, elastic: ứng dụng được phân tách thành các phần nhỏ hơn, độc lập và thể được triển khai và quản lý một cách linh hoạt - chứ không phải một app nguyên khối (monolithic). Cô lập các tài nguyên: dự đoán hiệu năng ứng dụng Sử dụng tài nguyên: hiệu quả Tại sao bạn cần Kubernetes và nó có thể làm những gì? Các container là một cách tốt để đóng gói và chạy các ứng dụng của bạn. Trong môi trường production, bạn cần quản lý các container chạy các ứng dụng và đảm bảo rằng không có khoảng thời gian downtime. Ví dụ, nếu một container bị tắt đi, một container khác cần phải khởi động lên. Điều này sẽ dễ dàng hơn nếu được xử lý bởi một hệ thống.\nĐó là cách Kubernetes đến với chúng ta. Kubernetes cung cấp cho bạn một framework để chạy các hệ phân tán một cách mạnh mẽ. Nó đảm nhiệm việc nhân rộng và chuyển đổi dự phòng cho ứng dụng của bạn, cung cấp các mẫu deployment và hơn thế nữa. Ví dụ, Kubernetes có thể dễ dàng quản lý một triển khai canary cho hệ thống của bạn.\nKubernetes cung cấp cho bạn:\nService discovery và cân bằng tải\nKubernetes có thể expose một container sử dụng DNS hoặc địa chỉ IP của riêng nó. Nếu lượng traffic truy cập đến một container cao, Kubernetes có thể cân bằng tải và phân phối lưu lượng mạng (network traffic) để việc triển khai được ổn định. Điều phối bộ nhớ\nKubernetes cho phép bạn tự động mount một hệ thống lưu trữ mà bạn chọn, như local storages, public cloud providers, v.v. Tự động rollouts và rollbacks\nBạn có thể mô tả trạng thái mong muốn cho các container được triển khai dùng Kubernetes và nó có thể thay đổi trạng thái thực tế sang trạng thái mong muốn với tần suất được kiểm soát. Ví dụ, bạn có thể tự động hoá Kubernetes để tạo mới các container cho việc triển khai của bạn, xoá các container hiện có và áp dụng tất cả các resource của chúng vào container mới. Đóng gói tự động\nBạn cung cấp cho Kubernetes một cluster gồm các node mà nó có thể sử dụng để chạy các tác vụ được đóng gói (containerized task). Bạn cho Kubernetes biết mỗi container cần bao nhiêu CPU và bộ nhớ (RAM). Kubernetes có thể điều phối các container đến các node để tận dụng tốt nhất các resource của bạn. Tự phục hồi\nKubernetes khởi động lại các containers bị lỗi, thay thế các container, xoá các container không phản hồi lại cấu hình health check do người dùng xác định và không cho các client biết đến chúng cho đến khi chúng sẵn sàng hoạt động. Quản lý cấu hình và bảo mật\nKubernetes cho phép bạn lưu trữ và quản lý các thông tin nhạy cảm như: password, OAuth token và SSH key. Bạn có thể triển khai và cập nhật lại secret và cấu hình ứng dụng mà không cần build lại các container image và không để lộ secret trong cấu hình stack của bạn. Kubernetes không phải là gì? Kubernetes không phải là một hệ thống PaaS (Nền tảng như một Dịch vụ) truyền thống, toàn diện. Do Kubernetes hoạt động ở tầng container chứ không phải ở tầng phần cứng, nó cung cấp một số tính năng thường áp dụng chung cho các dịch vụ PaaS, như triển khai, nhân rộng, cân bằng tải, ghi nhật ký và giám sát. Tuy nhiên, Kubernetes không phải là cấu trúc nguyên khối và các giải pháp mặc định này là tùy chọn và có thể cắm được (pluggable).\nKubernetes:\nKhông giới hạn các loại ứng dụng được hỗ trợ. Kubernetes nhằm mục đích hỗ trợ một khối lượng công việc cực kỳ đa dạng, bao gồm cả stateless, stateful và xử lý dữ liệu. Nếu một ứng dụng có thể chạy trong một container, nó sẽ chạy rất tốt trên Kubernetes. Không triển khai mã nguồn và không build ứng dụng của bạn. Quy trình CI/CD được xác định bởi tổ chức cũng như các yêu cầu kỹ thuật. Không cung cấp các service ở mức ứng dụng, như middleware (ví dụ, các message buses), các framework xử lý dữ liệu (ví dụ, Spark), cơ sở dữ liệu (ví dụ, MySQL), bộ nhớ cache, cũng như hệ thống lưu trữ của cluster (ví dụ, Ceph). Các thành phần như vậy có thể chạy trên Kubernetes và/hoặc có thể được truy cập bởi các ứng dụng chạy trên Kubernetes thông qua các cơ chế di động, chẳng hạn như Open Service Broker. Không bắt buộc các giải pháp ghi lại nhật ký (logging), giám sát (monitoring) hoặc cảnh báo (alerting). Nó cung cấp một số sự tích hợp như proof-of-concept, và cơ chế để thu thập và xuất các số liệu. Không cung cấp, không bắt buộc một cấu hình ngôn ngữ/hệ thống (ví dụ: Jsonnet). Nó cung cấp một API khai báo có thể được targeted bởi các hình thức khai báo tùy ý. Không cung cấp cũng như áp dụng bất kỳ cấu hình toàn diện, bảo trì, quản lý hoặc hệ thống tự phục hồi. Ngoài ra, Kubernetes không phải là một hệ thống điều phối đơn thuần. Trong thực tế, nó loại bỏ sự cần thiết của việc điều phối. Định nghĩa kỹ thuật của điều phối là việc thực thi một quy trình công việc được xác định: đầu tiên làm việc A, sau đó là B rồi sau chót là C. Ngược lại, Kubernetes bao gồm một tập các quy trình kiểm soát độc lập, có thể kết hợp, liên tục điều khiển trạng thái hiện tại theo trạng thái mong muốn đã cho. Nó không phải là vấn đề làm thế nào bạn có thể đi được từ A đến C. Kiểm soát tập trung cũng không bắt buộc. Điều này dẫn đến một hệ thống dễ sử dụng hơn, mạnh mẽ hơn, linh hoạt hơn và có thể mở rộng. "
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.1-cluster/",
	"title": "Kiến trúc Cluster",
	"tags": [],
	"description": "",
	"content": "Kiến trúc Cluster Kiến trúc của một cluster Kubernetes\nKiến trúc của một cluster Kubernetes bao gồm các thành phần chính sau:\nMaster Node: Master node quản lý và điều khiển toàn bộ cluster. Các thành phần chính trên master node bao gồm:\nAPI Server: API server là giao diện chính để tương tác với cluster. Tất cả các yêu cầu API từ các thành phần khác đều được xử lý thông qua API server.\nScheduler: Scheduler quyết định nơi chạy các pod mới dựa trên yêu cầu tài nguyên, các ràng buộc và chính sách đã được định nghĩa.\nController Manager: Controller manager chịu trách nhiệm kiểm soát trạng thái của các đối tượng trong cluster (ví dụ: pods, services, replication controllers).\netcd: etcd là một cơ sở dữ liệu phân tán dùng để lưu trữ trạng thái của toàn bộ cluster.\nWorker Node: Các worker node là nơi chứa các container và nơi mà các ứng dụng thực sự chạy. Mỗi worker node có các thành phần sau:\nKubelet: Kubelet là một agent chạy trên mỗi node và quản lý việc chạy các container trên node đó.\nKube-proxy: Kube-proxy quản lý việc giao tiếp mạng giữa các pod và các dịch vụ khác trong cluster.\nContainer Runtime: Container runtime (như Docker hoặc containerd) là phần mềm chịu trách nhiệm quản lý các container.\nPods: Pod là đơn vị nhỏ nhất trong Kubernetes, mỗi pod chứa một hoặc nhiều container. Các container trong cùng một pod chia sẻ cùng một không gian mạng và lưu trữ.\nServices: Services định tuyến yêu cầu đến các pod. Một service đại diện cho một nhóm các pod và cung cấp cách truy cập đồng nhất đến chúng.\nVolumes: Volumes là cách để lưu trữ dữ liệu dạng trên đĩa mà các container có thể chia sẻ và truy cập.\nNamespace: Namespace cho phép chia cluster thành các phần nhỏ hơn, mỗi phần có thể có các tài nguyên riêng biệt và được cấu hình riêng.\nIngress Controller: Ingress controller quản lý việc điều hướng yêu cầu HTTP/HTTPS đến các dịch vụ trong cluster dựa trên các quy tắc cấu hình.\nStorage Classes: Storage classes định nghĩa các loại lưu trữ khác nhau mà có thể được yêu cầu bởi các persistent volume.\nTất cả các thành phần này làm việc cùng nhau để tạo ra một môi trường chạy ứng dụng linh hoạt và mạnh mẽ trên Kubernetes cluster.\n"
},
{
	"uri": "//localhost:1313/vi/",
	"title": "Kubernetes trên AWS",
	"tags": [],
	"description": "",
	"content": "Kubernetes trên AWS Kubernetes là một nền tảng mã nguồn mở, linh hoạt, có khả năng mở rộng, phục vụ việc quản lý các ứng dụng được đóng gói và các dịch vụ liên quan, giúp việc cấu hình và tự động hóa quá trình triển khai ứng dụng trở nên thuận tiện hơn. Được biết đến như một hệ sinh thái lớn và phát triển nhanh chóng, Kubernetes cung cấp sự hỗ trợ rộng rãi qua các dịch vụ và công cụ đa dạng.\nTên Kubernetes bắt nguồn từ tiếng Hy Lạp, nghĩa là người lái tàu hoặc hoa tiêu. Kubernetes được Google công bố mã nguồn vào năm 2014, dựa trên gần một thập kỷ kinh nghiệm quản lý workload lớn trong thực tế của Google, kết hợp với các ý tưởng và best practices từ cộng đồng.\nQuay ngược thời gian Hãy xem xét tại sao Kubernetes lại quan trọng thông qua việc nhìn lại quá khứ.\nThời kỳ triển khai truyền thống: Ban đầu, các ứng dụng được chạy trực tiếp trên máy chủ vật lý, khiến việc phân bổ tài nguyên gặp khó khăn do không có cơ chế xác định ranh giới tài nguyên cho từng ứng dụng. Cách tiếp cận này dẫn đến nguy cơ một ứng dụng có thể sử dụng quá nhiều tài nguyên, ảnh hưởng đến hoạt động của các ứng dụng khác. Giải pháp là chạy mỗi ứng dụng trên một máy chủ vật lý riêng biệt, nhưng điều này lại không hiệu quả về mặt chi phí và tài nguyên.\nThời kỳ triển khai ảo hóa: Ảo hóa được giới thiệu như một giải pháp cho phép chạy nhiều Máy ảo (VM) trên cùng một máy chủ vật lý, giúp cô lập ứng dụng và tăng cường bảo mật. Ảo hóa cũng giúp cải thiện hiệu quả sử dụng tài nguyên và khả năng mở rộng.\nThời kỳ triển khai Container: Container giống như VM nhưng nhẹ hơn và chia sẻ Hệ điều hành (HĐH) với nhau. Container mang lại nhiều lợi ích như tạo mới và triển khai ứng dụng nhanh chóng, phát triển và triển khai liên tục, phân biệt rõ ràng giữa quá trình phát triển và vận hành, cung cấp tính nhất quán qua các môi trường, khả năng di chuyển giữa các cloud và HĐH, và quản lý ứng dụng tập trung.\nTại sao bạn cần Kubernetes và nó có thể làm gì? Container là phương tiện hiệu quả để đóng góp và chạy ứng dụng của bạn. Trong môi trường sản xuất, cần có cơ chế quản lý các container một cách hiệu quả, đảm bảo không có downtime. Kubernetes giúp quản lý các hệ thống phân tán mạnh mẽ, tự động hóa việc nhân rộng, cung cấp các mẫu triển khai và nhiều hơn nữa.\nKubernetes mang lại:\nPhát hiện dịch vụ và cân bằng tải Điều phối bộ nhớ Tự động rollouts và rollbacks Đóng gói tự động Tự phục hồi Quản lý cấu hình và bảo mật Những gì Kubernetes không phải là Kubernetes không phải là một hệ thống PaaS truyền thống, toàn diện. Nó hoạt động ở tầng container, cung cấp tính năng giống như PaaS như triển khai, nhân rộng, cân bằng tải, nhưng là một giải pháp linh hoạt và có thể mở rộng, không giới hạn loại ứng dụng được hỗ trợ, không triển khai mã nguồn hoặc build ứng dụng, không cung cấp dịch vụ ứng dụng cấp cao như middleware, databases, không bắt buộc sử dụng các giải pháp ghi nhật ký, giám sát hoặc cảnh báo, và không cung cấp hoặc áp dụng bất kỳ cấu hình toàn diện, bảo trì, quản lý hoặc hệ thống tự phục hồi. Kubernetes loại bỏ nhu cầu về điều phối truyền thống, thay vào đó là kiểm soát liên tục từ trạng thái hiện tại sang trạng thái mong muốn.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.1-cluster/1.1.1-node/",
	"title": "Nodes",
	"tags": [],
	"description": "",
	"content": "Nodes Kubernetes chạy các tác vụ của bạn bằng cách đặt các container vào trong Pods để chạy trên Nodes. Một node có thể là máy ảo hoặc máy vật lý, tùy thuộc vào cụm. Mỗi node được quản lý bởi bộ điều khiển và chứa các dịch vụ cần thiết để chạy Pods. Thông thường, bạn sẽ có nhiều nodes trong một cụm; trong một môi trường học tập hoặc môi trường có hạn chế về tài nguyên, bạn có thể chỉ có một node.\nCác thành phần trên một node bao gồm kubelet, một runtime container, và kube-proxy.\n"
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.1-using-eksctl/",
	"title": "Sử dụng eksctl",
	"tags": [],
	"description": "",
	"content": "Xây dựng một cluster cho các bài thực hành lab sử dụng công cụ eksctl. Đây là cách dễ nhất để bắt đầu, và được khuyến nghị cho hầu hết các người học. Tiện ích eksctl đã được cài đặt sẵn trong Môi trường Amazon Cloud9 của bạn, vì vậy chúng ta có thể ngay lập tức tạo ra cluster. Đây là cấu hình sẽ được sử dụng để xây dựng cluster:\nmanifests/../cluster/eksctl/cluster.yaml Dựa trên cấu hình này, eksctl sẽ:\nTạo một VPC trên ba AZ Tạo một cluster EKS Tạo một nhà cung cấp IAM OIDC Thêm một nhóm node quản lý có tên là default Cấu hình VPC CNI để sử dụng việc ủy quyền tiền tố Áp dụng tệp cấu hình như sau:\n$ export EKS_CLUSTER_NAME=eks-workshop $ curl -fsSL https://raw.githubusercontent.com/aws-samples/eks-workshop-v2/stable/cluster/eksctl/cluster.yaml | \\ envsubst | eksctl create cluster -f - Thường mất khoảng 20 phút. Khi cluster được tạo, chạy lệnh sau để sử dụng cluster cho các bài thực hành lab:\n$ use-cluster $EKS_CLUSTER_NAME Bước Tiếp Theo Bây giờ cluster đã sẵn sàng, hãy đi đến Bắt đầu module hoặc nhảy tới bất kỳ module nào trong workshop với thanh điều hướng trên cùng. Khi bạn hoàn thành workshop, làm theo các bước dưới đây để dọn dẹp môi trường của bạn.\nDọn Dẹp (các bước sau khi bạn hoàn thành Workshop) Dưới đây là cách bạn sẽ dọn dẹp tài nguyên sau này khi bạn đã sử dụng xong Cluster EKS bạn đã tạo trong các bước trước để hoàn thành các module.\nTrước khi xóa môi trường Cloud9, chúng ta cần dọn dẹp cluster mà chúng ta đã thiết lập trong các bước trước đó.\nĐầu tiên sử dụng delete-environment để đảm bảo rằng ứng dụng mẫu và bất kỳ cơ sở hạ tầng lab còn lại nào được loại bỏ:\n$ delete-environment Tiếp theo, xóa cluster bằng eksctl:\n$ eksctl delete cluster $EKS_CLUSTER_NAME --wait "
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/",
	"title": "Các Bước Chuẩn Bị",
	"tags": [],
	"description": "",
	"content": "Các Bước Chuẩn Bị Hướng dẫn thiết lập môi trường chạy lab trong tài khoản AWS của bạn Phần này trình bày cách thiết lập môi trường để chạy các workshop trong tài khoản AWS của bạn. Hướng dẫn này đã được kiểm tra ở các khu vực (Region) AWS sau đây và không đảm bảo hoạt động ở các khu vực khác mà không cần chỉnh sửa:\nus-west-2 eu-west-1 Bước đầu tiên là tạo một IDE với mẫu CloudFormation được cung cấp. Cách đơn giản nhất để làm điều này là sử dụng AWS CloudShell trong tài khoản mà bạn sẽ chạy các bài workshop. Mở CloudShell với liên kết bên dưới hoặc tuân theo tài liệu này:\nhttps://console.aws.amazon.com/cloudshell/home\nNếu sử dụng liên kết ở trên, đảm bảo bảng điều khiển AWS đã mở ở khu vực mà bạn muốn chạy các bài workshop.\nKhi CloudShell đã tải xong, chạy các lệnh sau:\n$ wget -q https://raw.githubusercontent.com/aws-samples/eks-workshop-v2/stable/lab/cfn/eks-workshop-ide-cfn.yaml -O eks-workshop-ide-cfn.yaml $ aws cloudformation deploy --stack-name eks-workshop-ide \\ --template-file ./eks-workshop-ide-cfn.yaml \\ --parameter-overrides RepositoryRef=stable \\ --capabilities CAPABILITY_NAMED_IAM Waiting for changeset to be created.. Waiting for stack create/update to complete Successfully created/updated stack - eks-workshop-ide CloudFormation Stack sẽ mất khoảng 5 phút để triển khai, và khi hoàn tất, bạn có thể lấy URL cho Cloud9 IDE như sau:\n$ aws cloudformation describe-stacks --stack-name eks-workshop-ide \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`Cloud9Url`].OutputValue\u0026#39; --output text https://us-west-2.console.aws.amazon.com/cloud9/ide/7b05513358534d11afeb7119845c5461?region=us-west-2 Mở URL này trong trình duyệt web để truy cập vào IDE.\nBạn có thể đóng CloudShell ngay bây giờ, tất cả các lệnh tiếp theo sẽ được thực hiện trong phần terminal ở dưới cùng của Cloud9 IDE. AWS CLI đã được cài đặt sẵn và sẽ nhận các thông tin xác thực được gắn với Cloud9 IDE:\n$ aws sts get-caller-identity Bước tiếp theo là tạo một cụm EKS để thực hiện các bài workshop. Vui lòng tuân theo một trong các hướng dẫn dưới đây để cung cấp một cụm phù hợp với yêu cầu của các bài workshop này:\n(Được khuyến nghị) eksctl Terraform (Sắp ra mắt!) CDK "
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.2--docker-vs.-containerd/",
	"title": "Docker và ContainerD",
	"tags": [],
	"description": "",
	"content": "Docker và ContainerD Trong phần này, chúng ta sẽ xem xét sự khác biệt giữa Docker và ContainerD.\nKhi bạn bắt đầu tìm hiểu, bạn sẽ thường xuyên bắt gặp Docker và containerd. Khi đọc các bài blog cũ hoặc trang tài liệu, bạn sẽ thấy Docker được nhắc đến cùng với Kubernetes. Còn khi đọc blog mới, bạn sẽ thấy containerd và tự hỏi sự khác biệt giữa chúng là gì. Có một số công cụ CLI như ctr, crictl hay nerdctl, và bạn sẽ tự hỏi những công cụ CLI này là gì và bạn nên sử dụng cái nào. Đó chính là những gì tôi sẽ giải thích.\nHãy quay lại thời điểm bắt đầu của kỷ nguyên container. Ban đầu, chỉ có Docker. Có một số công cụ khác như Rocket (rkt), nhưng trải nghiệm người dùng của Docker đã làm cho việc làm việc với container trở nên cực kỳ đơn giản và do đó, Docker trở thành công cụ container chiếm ưu thế nhất. Sau đó, Kubernetes ra đời để điều phối Docker, vì vậy Kubernetes được xây dựng để điều phối cụ thể Docker ngay từ đầu. Docker và Kubernetes được kết hợp chặt chẽ và vào thời điểm đó, Kubernetes chỉ hoạt động với Docker và không hỗ trợ bất kỳ giải pháp container nào khác.\nSau đó, Kubernetes ngày càng phổ biến như một công cụ điều phối container và bây giờ các runtime container khác như rkt muốn được hỗ trợ. Vì vậy, người dùng Kubernetes cần nó hoạt động với các runtime container khác ngoài Docker. Do đó, Kubernetes giới thiệu một giao diện gọi là giao diện runtime container (CRI), cho phép bất kỳ nhà cung cấp nào hoạt động như một runtime container cho Kubernetes miễn là họ tuân thủ các tiêu chuẩn OCI. OCI là viết tắt của Open Container Initiative, bao gồm một thông số kỹ thuật hình ảnh và một thông số kỹ thuật runtime. Thông số kỹ thuật hình ảnh định nghĩa cách một hình ảnh được xây dựng. Thông số kỹ thuật runtime định nghĩa các tiêu chuẩn về cách phát triển bất kỳ runtime container nào. Với những tiêu chuẩn này, bất kỳ ai cũng có thể xây dựng một runtime container có thể được sử dụng bởi bất kỳ ai để làm việc với Kubernetes.\nRkt và các runtime container khác tuân thủ các tiêu chuẩn OCI giờ đây được hỗ trợ làm runtime container cho Kubernetes thông qua CRI. Tuy nhiên, Docker không được xây dựng để hỗ trợ các tiêu chuẩn CRI. Docker được xây dựng trước khi CRI được giới thiệu và Docker vẫn là công cụ container chiếm ưu thế được sử dụng nhiều nhất. Vì vậy, Kubernetes phải tiếp tục hỗ trợ Docker và do đó giới thiệu dockershim, một cách tạm thời nhưng không hoàn hảo để hỗ trợ Docker ngoài CRI.\nTrong khi hầu hết các runtime container khác làm việc theo CRI, Docker tiếp tục hoạt động mà không cần nó. Vì vậy, Docker không chỉ đơn thuần là một runtime container. Docker bao gồm nhiều công cụ được kết hợp lại, ví dụ như Docker CLI, Docker API, các công cụ xây dựng giúp xây dựng hình ảnh. Có hỗ trợ cho volumes, bảo mật, và cuối cùng là runtime container gọi là runc, và daemon quản lý runc được gọi là containerd. Containerd tương thích với CRI và có thể làm việc trực tiếp với Kubernetes như tất cả các runtime khác, vì vậy containerd có thể được sử dụng như một runtime riêng biệt, tách biệt khỏi Docker.\nVì vậy, bây giờ bạn có containerd như một runtime riêng biệt và Docker riêng biệt. Kubernetes tiếp tục duy trì hỗ trợ trực tiếp cho Docker engine, tuy nhiên, việc duy trì dockershim là một nỗ lực không cần thiết và gây ra rắc rối nên đã quyết định trong phiên bản 1.24 của **\nKubernetes** loại bỏ hoàn toàn dockershim và do đó hỗ trợ cho Docker đã được loại bỏ. Nhưng tất cả các hình ảnh được xây dựng trước khi Docker bị loại bỏ vẫn tiếp tục hoạt động vì Docker tuân thủ thông số kỹ thuật hình ảnh từ các tiêu chuẩn OCI, vì vậy tất cả các hình ảnh được xây dựng bởi Docker tuân thủ tiêu chuẩn và tiếp tục hoạt động với containerd nhưng Docker bản thân đã bị loại bỏ làm runtime được hỗ trợ bởi Kubernetes. Đó chính là toàn bộ câu chuyện, giờ hãy xem xét cụ thể hơn về containerd.\nContainerd, mặc dù là một phần của Docker, giờ đây là một dự án riêng biệt và là thành viên của CNCF với tư cách là thành viên đã tốt nghiệp, vì vậy bạn có thể cài đặt containerd mà không cần phải cài đặt Docker. Nếu bạn không thực sự cần các tính năng khác của Docker, bạn có thể lý tưởng chỉ cài đặt containerd. Thông thường, chúng ta chạy container bằng lệnh docker run khi có Docker. Nếu Docker không được cài đặt thì làm thế nào để chạy container chỉ với containerd? Sau khi cài đặt containerd, nó đi kèm với một công cụ dòng lệnh gọi là ctr, và công cụ này được tạo ra chỉ để gỡ lỗi containerd và không thân thiện với người dùng vì nó chỉ hỗ trợ một số tính năng hạn chế và đây là tất cả những gì bạn có thể thấy trong các trang tài liệu cho công cụ này. Vì vậy, ngoài bộ tính năng hạn chế, bất kỳ cách tương tác nào khác với containerd bạn phải dựa vào việc gọi API trực tiếp, không phải là cách thân thiện nhất để chúng ta vận hành.\nChỉ để bạn có một ý tưởng, lệnh ctr có thể được sử dụng để thực hiện các hoạt động liên quan đến container cơ bản như kéo hình ảnh, ví dụ để kéo hình ảnh redis bạn sẽ chạy\nctr images pull docker.io/library/redis:alpine Để chạy một container, chúng ta sử dụng lệnh ctr run\nctr run docker.io/library/redis:alpine redis Nhưng như tôi đã đề cập, công cụ này chỉ dành cho gỡ lỗi containerd và không thân thiện với người dùng, không nên được sử dụng để quản lý container trong môi trường sản xuất. Một lựa chọn tốt hơn được khuyến nghị là công cụ nerdctl. Công cụ nerdctl là một công cụ dòng lệnh rất giống với Docker, vì vậy đây là một CLI giống như Docker cho containerd. Nó hỗ trợ hầu hết các tùy chọn CLI mà Docker hỗ trợ và ngoài ra, nó còn có lợi ích bổ sung là có thể truy cập vào các tính năng mới nhất được triển khai trong containerd, ví dụ như chúng ta có thể làm việc với hình ảnh container được mã hóa hoặc các tính năng mới khác sẽ cuối cùng được triển khai vào lệnh Docker thông thường trong tương lai. Nó cũng hỗ trợ kéo hình ảnh lười biếng, phân phối hình ảnh P2P, ký và xác minh hình ảnh và không gian tên trong Kubernetes, những thứ không có sẵn trong Docker. Vì vậy, công cụ nerdctl hoạt động rất giống với CLI Docker, vì vậy thay vì Docker, bạn chỉ cần thay thế nó bằng nerdctl để có thể chạy hầu hết các lệnh Docker tương tác với container như thế này.\nVì vậy, đó khá dễ dàng và trực tiếp. Bây giờ chúng ta đã nói về ctr và công cụ nerdctl, điều quan trọng là phải nói về một công cụ dòng lệnh khác được gọi là crictl. Trước đó chúng ta đã nói về CRI, là một giao diện đơn lẻ được sử dụng để kết nối với các runtime container tương thích với CRI, containerd, rkt và các runtime khác. Crictl là một tiện ích dòng lệnh được sử dụng để tương tác với runtime container tương thích với CRI, vì vậy đây là loại tương tác từ góc độ Kubernetes. Công cụ này được phát triển và b\nảo trì bởi cộng đồng Kubernetes và công cụ này hoạt động trên tất cả các runtime container khác nhau. Vì trước đây bạn có ctr và tiện ích nerdctl được xây dựng bởi cộng đồng containerd cụ thể cho containerd, nhưng công cụ cụ thể này là từ góc độ Kubernetes hoạt động trên các runtime container khác nhau.\nNó phải được cài đặt riêng và được sử dụng để kiểm tra và gỡ lỗi các runtime container vì vậy một lần nữa không lý tưởng được sử dụng để tạo container không giống như tiện ích Docker hoặc nerdctl nhưng lại là một công cụ gỡ lỗi. Bạn có thể kỹ thuật tạo container với tiện ích crictl nhưng không dễ dàng. Nó chỉ được sử dụng cho một số mục đích gỡ lỗi đặc biệt. Và nhớ rằng nó hoạt động cùng với kubelet vì vậy chúng ta biết rằng kubelet chịu trách nhiệm đảm bảo một số lượng nhất định container hoặc pod có sẵn trên một node tại một thời điểm, vì vậy nếu bạn đi qua tiện ích crictl và cố gắng tạo container với nó, cuối cùng kubelet sẽ xóa chúng vì kubelet không biết về một số container hoặc pod đó được tạo ra bên ngoài kiến thức của nó vì vậy bất cứ thứ gì nó thấy, nó sẽ đi và xóa nó, vì những lý do đó nhớ rằng tiện ích crictl chỉ được sử dụng cho mục đích gỡ lỗi và tiếp cận vào container và tất cả những điều đó.\nHãy xem một số ví dụ về lệnh dòng lệnh vì vậy bạn chỉ cần chạy lệnh crictl cho điều này và điều này có thể được sử dụng để thực hiện các hoạt động liên quan đến container cơ bản như kéo hình ảnh, hoặc liệt kê hình ảnh hiện có, liệt kê container, rất giống với lệnh Docker khi bạn sử dụng các lệnh PS, vì vậy trong Docker bạn chạy lệnh ps, và ở đây bạn chạy lệnh crictl ps và để chạy một lệnh trong một container Docker nhớ rằng chúng ta sử dụng lệnh exec và nó giống nhau ở đây và cùng với các tùy chọn giống như -i và -t và bạn chỉ định id container. Để xem nhật ký, bạn sử dụng lệnh crictl logs, một lần nữa rất giống với lệnh Docker.\nMột sự khác biệt lớn là lệnh crictl cũng biết đến các pod vì vậy bạn có thể liệt kê các pod bằng cách chạy lệnh crictl pods vì vậy điều này không phải là điều mà Docker biết đến. Vì vậy, khi làm việc với Kubernetes trong quá khứ, chúng ta đã sử dụng rất nhiều lệnh Docker để khắc phục sự cố container và xem nhật ký đặc biệt là trên các node worker và bây giờ bạn sẽ sử dụng lệnh crictl để làm điều đó. Cú pháp rất giống nhau vì vậy nó không thực sự khó. Đây là một biểu đồ liệt kê so sánh giữa công cụ dòng lệnh Docker và crictl. Như bạn có thể thấy, rất nhiều lệnh như attach exec, images, info, inspect, logs, ps, stats, version, v.v., hoạt động chính xác cùng một cách, và một số lệnh để tạo, xóa và bắt đầu và dừng hình ảnh hoạt động tương tự. Một danh sách đầy đủ các sự khác biệt có thể được tìm thấy trong liên kết này.\nVì vậy, như tôi đã đề cập, crictl có thể được sử dụng để kết nối với bất kỳ runtime container nào tương thích với CRI, nhớ đặt điểm cuối phù hợp nếu bạn có nhiều runtime container được cấu hình, hoặc nếu bạn muốn crictl tương tác với một runtime cụ thể, ví dụ nếu bạn không cấu hình gì mặc định nó sẽ kết nối với các socket theo thứ tự cụ thể này, vì vậy nó sẽ cố gắng kết nối với dockershim trước, sau đó là containerd, sau đó là CRI-O, sau đó là CRI-dockerd – đó là thứ tự mà nó tuân theo. Nhưng nếu bạn muốn ghi đè điều đó và\nmuốn nó kết nối với containerd, bạn có thể chỉ định một điểm cuối, hoặc nếu bạn muốn nó kết nối với CRI-O, bạn có thể chỉ định một điểm cuối khác. Vì vậy, điều này chỉ đơn giản là cần thiết khi bạn cấu hình nhiều runtime container, nếu bạn chỉ có một runtime container, bạn không cần phải lo lắng về điều này.\nVì vậy, đó là một cái nhìn tổng quan về những khái niệm cơ bản và công cụ mà bạn cần phải hiểu để có thể làm việc với containerd và CRI và Kubernetes.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.1-cluster/1.1.2-communitcation/",
	"title": "Giao tiếp giữa các Node và Control Plane",
	"tags": [],
	"description": "",
	"content": "Giao tiếp giữa các Node và Control Plane Workshop này liệt kê các con đường giao tiếp giữa máy chủ API và cụm Kubernetes. Mục đích là để cho phép người dùng tùy chỉnh cài đặt của mình nhằm tăng cường cấu hình mạng, từ đó cụm có thể được vận hành trên một mạng không tin cậy (hoặc trên các IP công cộng hoàn toàn trên nhà cung cấp đám mây). Từ Node đến Control Plane Kubernetes áp dụng mô hình API \u0026ldquo;hub-and-spoke\u0026rdquo;. Tất cả việc sử dụng API từ các node (hoặc các pod được chúng chạy) đều kết thúc tại máy chủ API. Không có thành phần nào khác của control plane được thiết kế để tiết lộ dịch vụ từ xa. Máy chủ API được cấu hình để lắng nghe các kết nối từ xa trên cổng HTTPS an toàn (thông thường là 443) với một hoặc nhiều hình thức xác thực khách hàng được kích hoạt. Một hoặc nhiều hình thức ủy quyền nên được kích hoạt, đặc biệt nếu cho phép yêu cầu ẩn danh hoặc token tài khoản dịch vụ.\nCác node nên được cung cấp chứng chỉ gốc công khai cho cụm để chúng có thể kết nối một cách an toàn đến máy chủ API cùng với các thông tin đăng nhập khách hàng hợp lệ. Một cách tiếp cận tốt là thông tin đăng nhập khách hàng được cung cấp cho kubelet dưới dạng một chứng chỉ khách hàng. Xem khoản bootstrap TLS kubelet để tự động cung cấp chứng chỉ khách hàng cho kubelet.\nCác pod muốn kết nối đến máy chủ API có thể làm như vậy một cách an toàn bằng cách tận dụng một tài khoản dịch vụ sao cho Kubernetes sẽ tự động tiêm chứng chỉ gốc công khai và token bearer hợp lệ vào pod khi nó được khởi tạo. Dịch vụ Kubernetes (trong namespace mặc định) được cấu hình với một địa chỉ IP ảo được chuyển hướng (thông qua kube-proxy) đến điểm cuối HTTPS trên máy chủ API.\nCác thành phần của control plane cũng giao tiếp với máy chủ API qua cổng an toàn.\nKết quả là, chế độ vận hành mặc định cho các kết nối từ các node và pod chạy trên các node đến control plane được bảo mật theo mặc định và có thể vận hành trên các mạng không tin cậy và/hoặc công cộng.\nTừ Control Plane đến Node Có hai con đường giao tiếp chính từ control plane (máy chủ API) đến các node. Đầu tiên là từ máy chủ API đến quy trình kubelet chạy trên mỗi node trong cụm. Thứ hai là từ máy chủ API đến bất kỳ node, pod, hoặc dịch vụ nào thông qua chức năng proxy của máy chủ API. Máy chủ API đến kubelet Các kết nối từ máy chủ API đến kubelet được sử dụng cho:\nLấy nhật ký (logs) cho các pod. Đính kèm (thường qua kubectl) vào các pod đang chạy. Cung cấp chức năng chuyển tiếp cổng của kubelet. Những kết nối này kết thúc tại điểm cuối HTTPS của kubelet. Theo mặc định, máy chủ API không xác minh chứng chỉ phục vụ của kubelet, điều này khiến kết nối dễ bị tấn công man-in-the-middle và không an toàn để vận hành trên các mạng không tin cậy và/hoặc công cộng. Để xác minh kết nối này, sử dụng cờ \u0026ndash;kubelet-certificate-authority để cung cấp cho máy chủ API một gói chứng chỉ gốc để sử dụng để xác minh chứng chỉ phục vụ của kubelet. Nếu điều đó không khả thi, sử dụng SSH Tunnel giữa máy chủ API và kubelet nếu cần thiết để tránh kết nối qua một mạng không tin cậy hoặc công cộng. Cuối cùng, xác thực và/hoặc ủy quyền kubelet nên được kích hoạt để bảo mật API của kubelet. Máy chủ API đến Node, Pod, và Dịch vụ Các kết nối từ máy chủ API đến một node, pod, hoặc dịch vụ mặc định là các kết nối HTTP đơn giản và do đó không được xác thực hoặc mã hóa. Chúng có thể được vận hành qua một kết nối HTTPS an toàn bằng cách thêm tiền t ố https: vào tên node, pod, hoặc dịch vụ trong URL API, nhưng chúng sẽ không xác minh chứng chỉ được cung cấp bởi điểm cuối HTTPS cũng như không cung cấp thông tin đăng nhập khách hàng. Vì vậy, mặc dù kết nối sẽ được mã hóa, nó không cung cấp bất kỳ bảo đảm nào về tính toàn vẹn. Những kết nối này hiện không an toàn để vận hành trên các mạng không tin cậy hoặc công cộng.\nSSH Tunnel Kubernetes hỗ trợ SSH Tunnel để bảo vệ các con đường giao tiếp từ control plane đến node. Trong cấu hình này, máy chủ API khởi tạo một SSH Tunnel đến mỗi node trong cụm (kết nối với máy chủ SSH lắng nghe trên cổng 22) và chuyển tất cả lưu lượng truy cập dành cho kubelet, node, pod, hoặc dịch vụ qua đường hầm. Đường hầm này đảm bảo rằng lưu lượng truy cập không bị tiết lộ ra ngoài mạng mà các node đang vận hành. "
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.2-using-terraform/",
	"title": "Sử dụng Terraform",
	"tags": [],
	"description": "",
	"content": "Xây dựng một cụm cho các bài thực hành Lab sử dụng Hashicorp Terraform. Đây nhằm mục đích phục vụ cho những người học đã quen với việc làm việc với hạ tầng mã nguồn mở của Terraform.\nCLI terraform đã được cài đặt sẵn trong Môi trường Amazon Cloud9 của bạn, vì vậy chúng ta có thể ngay lập tức tạo ra cụm. Hãy xem qua các tập tin cấu hình Terraform chính sẽ được sử dụng để xây dựng cụm và hạ tầng hỗ trợ của nó.\nHiểu các tập tin cấu hình Terraform Tập tin providers.tf cấu hình các nhà cung cấp Terraform mà sẽ cần để xây dựng hạ tầng. Trong trường hợp của chúng ta, chúng tôi sử dụng các nhà cung cấp aws, kubernetes và helm:\nmanifests/../cluster/terraform/providers.tf Tập tin main.tf thiết lập một số nguồn dữ liệu Terraform để chúng ta có thể lấy thông tin tài khoản AWS và region hiện đang được sử dụng, cũng như một số thẻ mặc định:\nmanifests/../cluster/terraform/main.tf Cấu hình vpc.tf sẽ đảm bảo hạ tầng VPC của chúng ta được tạo ra:\nmanifests/../cluster/terraform/vpc.tf Cuối cùng, tập tin eks.tf chỉ định cấu hình cụm EKS của chúng tôi, bao gồm một Nhóm Node Quản lý:\nmanifests/../cluster/terraform/eks.tf Tạo môi trường workshop với Terraform Đối với cấu hình đã cho, terraform sẽ tạo ra Môi trường Workshop với các bước sau:\nTạo một VPC qua ba AZ Tạo ra một cụm EKS Tạo một nhà cung cấp IAM OIDC Thêm một nhóm node quản lý có tên là default Cấu hình VPC CNI để sử dụng ủy quyền tiền tố Tải các tập tin Terraform về:\n$ mkdir -p ~/environment/terraform; cd ~/environment/terraform $ curl --remote-name-all https://raw.githubusercontent.com/aws-samples/eks-workshop-v2/stable/cluster/terraform/{main.tf,variables.tf,providers.tf,vpc.tf,eks.tf} Chạy các lệnh Terraform sau để triển khai môi trường workshop của bạn.\n$ terraform init $ terraform apply -var=\u0026#34;cluster_name=$EKS_CLUSTER_NAME\u0026#34; -auto-approve Thường mất khoảng 20-25 phút để hoàn thành. Sau khi cụm được tạo ra, chạy lệnh này để sử dụng cụm cho các bài thực hành Lab:\n$ use-cluster $EKS_CLUSTER_NAME Bước Tiếp Theo Bây giờ cụm đã sẵn sàng, hãy đi đến Bắt Đầu hoặc nhảy qua bất kỳ mô-đun nào trong workshop với thanh điều hướng hàng đầu. Khi bạn hoàn thành với workshop, làm theo các bước dưới đây để dọn dẹp môi trường của bạn.\nDọn dẹp Phần sau đây sẽ hướng dẫn cách dọn dẹp các tài nguyên sau khi bạn đã hoàn thành các bài thực hành mong muốn. Những bước này sẽ xóa hết tất cả hạ tầng được cung cấp.\nTrước khi xóa môi trường Cloud9, chúng ta cần dọn dẹp cụm mà chúng ta đã thiết lập ở trên.\nĐầu tiên, sử dụng delete-environment để đảm bảo rằng ứng dụng mẫu và bất kỳ hạ tầng Lab nào còn sót lại đều được loại bỏ:\n$ delete-environment Tiếp theo, xóa cụm với terraform:\n$ cd ~/environment/terraform $ terraform destroy -var=\u0026#34;cluster_name=$EKS_CLUSTER_NAME\u0026#34; -auto-approve "
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.3-structure/",
	"title": "Cấu trúc",
	"tags": [],
	"description": "",
	"content": "Hướng dẫn sử dụng trang web và nội dung được cung cấp Nội dung của hội thảo này bao gồm:\nCác bài tập thực hành cá nhân Nội dung hỗ trợ giải thích các khái niệm liên quan đến các bài thực hành Các bài tập thực hành được thiết kế một cách sao cho bạn có thể chạy bất kỳ modules nào như một bài tập độc lập. Các bài tập thực hành sẽ được hiển thị trong thanh bên trái và được đánh dấu bằng biểu tượng ở đây:\nModule này chứa một bài lab duy nhất có tên là Bắt đầu sẽ được hiển thị ở phía trái màn hình của bạn.\nBạn nên bắt đầu mỗi bài lab từ trang được chỉ định bằng huy hiệu này. Bắt đầu ở giữa một bài lab sẽ gây ra hành vi không đoán trước được.\nCloud9 IDE Sau khi bạn đã truy cập vào Cloud9 IDE, chúng tôi khuyến nghị bạn sử dụng nút + và chọn New Terminal để mở một cửa sổ terminal mới toàn màn hình.\nĐiều này sẽ mở một tab mới với một terminal mới.\nBạn cũng có thể đóng terminal nhỏ ở dưới nếu bạn muốn.\nCác lệnh Terminal Hầu hết các tương tác mà bạn sẽ thực hiện trong hội thảo này sẽ được thực hiện bằng các lệnh terminal, mà bạn có thể gõ thủ công hoặc sao chép/dán vào terminal Cloud9 IDE. Bạn sẽ thấy các lệnh terminal được hiển thị như sau:\n$ echo \u0026#34;Đây là một ví dụ lệnh\u0026#34; Di chuột qua echo \u0026quot;Đây là một ví dụ lệnh\u0026quot; và nhấp vào biểu tượng để sao chép lệnh đó vào clipboard của bạn.\nBạn cũng sẽ gặp phải các lệnh có kết quả mẫu như sau:\n$ kubectl get nodes NAME STATUS ROLES AGE VERSION ip-10-42-10-104.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 6h vVAR::KUBERNETES_NODE_VERSION ip-10-42-10-210.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 6h vVAR::KUBERNETES_NODE_VERSION ip-10-42-11-198.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 6h vVAR::KUBERNETES_NODE_VERSION Giữ chuột, kéo qua lệnh cần sao chép và nhấn Ctrl+C để sao chép. Hãy thử xem!\nThiết lập lại EKS cluster của bạn Trong trường hợp bạn cấu hình cluster theo cách khiến nó không hoạt động, bạn được cung cấp một cơ chế để thiết lập lại EKS cluster của mình sao cho tốt nhất có thể, có thể chạy bất kỳ lúc nào. Đơn giản chỉ cần chạy lệnh prepare-environment và đợi cho đến khi nó hoàn tất. Điều này có thể mất vài phút tùy thuộc vào trạng thái của cluster của bạn khi chạy lệnh này.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.1-cluster/1.1.3-controllers/",
	"title": "Controllers",
	"tags": [],
	"description": "",
	"content": "Controllers Trong lĩnh vực robot và tự động hóa, một vòng lặp điều khiển là vòng lặp không kết thúc giúp điều chỉnh trạng thái của một hệ thống.\nDưới đây là một ví dụ về vòng lặp điều khiển: một bộ điều chỉnh nhiệt độ trong phòng.\nKhi bạn thiết lập nhiệt độ, điều đó nghĩa là bạn đang thông báo cho bộ điều chỉnh nhiệt về trạng thái mong muốn của bạn. Nhiệt độ thực tế của phòng là trạng thái hiện tại. - Bộ điều chỉnh nhiệt hoạt động để đưa trạng thái hiện tại gần hơn với trạng thái mong muốn, bằng cách bật hoặc tắt thiết bị.\nTrong Kubernetes, các controller là các vòng lặp điều khiển quan sát trạng thái của cluster của bạn, sau đó thực hiện hoặc yêu cầu các thay đổi khi cần thiết. Mỗi controller cố gắng di chuyển trạng thái hiện tại của cluster gần hơn với trạng thái mong muốn.\nMô hình Controller Một controller theo dõi ít nhất một loại tài nguyên Kubernetes. Những đối tượng này có một trường spec đại diện cho trạng thái mong muốn. Các controller cho tài nguyên đó chịu trách nhiệm làm cho trạng thái hiện tại gần hơn với trạng thái mong muốn.\nController có thể tự thực hiện hành động; thường thấy hơn, trong Kubernetes, một controller sẽ gửi tin nhắn tới máy chủ API mang lại hiệu ứng hữu ích. Bạn sẽ thấy ví dụ về điều này bên dưới.\nĐiều khiển qua Máy chủ API Controller Job là một ví dụ về controller tích hợp sẵn của Kubernetes. Các controller tích hợp sẵn quản lý trạng thái bằng cách tương tác với máy chủ API của cluster.\nJob là một tài nguyên Kubernetes chạy một Pod, hoặc có thể là nhiều Pods, để thực hiện một nhiệm vụ và sau đó dừng lại.\n(Một khi được lên lịch, các đối tượng Pod trở thành phần của trạng thái mong muốn cho một kubelet).\nKhi controller Job thấy một nhiệm vụ mới, nó đảm bảo rằng, ở đâu đó trong cluster của bạn, các kubelet trên một nhóm Nodes đang chạy số lượng Pods đúng để hoàn thành công việc. Controller Job không chạy bất kỳ Pod hoặc container nào. Thay vào đó, controller Job yêu cầu máy chủ API tạo hoặc xóa Pods. Các thành phần khác trong bộ điều khiển thực hiện theo thông tin mới (có Pods mới cần được lên lịch và chạy), và cuối cùng công việc được hoàn thành.\nSau khi bạn tạo một Job mới, trạng thái mong muốn là cho Job đó được hoàn thành. Controller Job làm cho trạng thái hiện tại của Job đó gần hơn với trạng thái mong muốn: tạo Pods thực hiện công việc bạn muốn cho Job đó, để Job gần hơn với việc hoàn thành.\nCác controller cũng cập nhật các đối tượng cấu hình cho chúng. Ví dụ: một khi công việc được hoàn thành cho một Job, controller Job cập nhật đối tượng Job đó để đánh dấu nó đã hoàn thành.\n(Điều này giống như cách một số bộ điều chỉnh nhiệt tắt đèn để chỉ ra rằng phòng của bạn hiện ở nhiệt độ bạn đã thiết lập).\nĐiều khiển Trực tiếp Trái ngược với Job, một số controller cần thực hiện thay đổi đối với những thứ bên ngoài cluster của bạn.\nVí dụ, nếu bạn sử dụng một vòng lặp điều khiển để đảm bảo có đủ Nodes trong cluster của bạn, thì controller đó cần một thứ gì đó bên ngoài cluster hiện tại để thiết lập Nodes mới khi cần thiết.\nCác controller tương tác với trạng thái bên ngoài tìm trạng thái mong muốn từ máy chủ API, sau đó trực tiếp giao tiếp với một hệ thống bên ngoài để đưa trạng thái hiện tại gần hơn.\n(Thực tế có một controller điều chỉnh quy mô các nodes trong cluster của bạn theo chiều ngang).\nĐiểm quan trọng ở đây là controller thực hiện một số thay đổi để đạt được trạng thái mong muốn, sau đó báo cáo trạng thái hiện tại trở lại máy chủ API của cluster. Các vòng lặp điều khiển khác có thể quan sát dữ liệu được báo cáo và thực hiện các hành động của riêng mình.\nTrong ví dụ về bộ điều chỉnh nhiệt, nếu phòng rất lạnh thì một controller khác cũng có thể bật máy sưởi chống đóng băng. Đối với các cluster Kubernetes, bộ điều khiển gián tiếp làm việc với các công cụ quản lý địa chỉ IP, dịch vụ lưu trữ, API của nhà cung cấp dịch vụ đám mây và các dịch vụ khác bằng cách mở rộng Kubernetes để triển khai điều đó. "
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.3-etcd/",
	"title": "ETCD",
	"tags": [],
	"description": "",
	"content": "ETCD ETCD là một hệ thống lưu trữ key-value phân tán, đáng tin cậy, đơn giản, an toàn và nhanh chóng. Key-Value Store là gì? Truyền thống, cơ sở dữ liệu được lưu trữ dưới dạng bảng, bạn có thể đã nghe về SQL hoặc cơ sở dữ liệu quan hệ. Chúng lưu trữ dữ liệu theo dòng và cột.\nMột Key-Value Store lưu trữ thông tin dưới dạng Key và Value.\nCài đặt ETCD Việc cài đặt và bắt đầu với ETCD rất dễ dàng.\nTải xuống file nhị phân phù hợp cho hệ điều hành của bạn từ trang phát hành trên Github (ETCD Releases)\nVí dụ: Để tải xuống ETCD v3.5.6, chạy lệnh curl sau:\n$ curl -LO https://github.com/etcd-io/etcd/releases/download/v3.5.6/etcd-v3.5.6-linux-amd64.tar.gz Giải nén nó. $ tar xvzf etcd-v3.5.6-linux-amd64.tar.gz Chạy dịch vụ ETCD. $ ./etcd Khi bạn khởi động ETCD, mặc định nó sẽ lắng nghe trên cổng 2379.\nClient mặc định đi kèm với ETCD là etcdctl. Bạn có thể sử dụng nó để lưu trữ và truy xuất cặp key-value.\nCú pháp: Để lưu một cặp Key-Value.\n$ ./etcdctl put key1 value1 Cú pháp: Để truy xuất dữ liệu đã lưu. $ ./etcdctl get key1 Cú pháp: Để xem thêm các lệnh. Chạy etcdctl mà không cần bất kỳ đối số nào. $ ./etcdctl Tài liệu tham khảo về Kubernetes: Kubernetes Components Overview ETCD Documentation Configure and Upgrade ETCD Kho Dữ Liệu ETCD Kho dữ liệu ETCD lưu trữ thông tin về cluster như Nodes, PODS, Configs, Secrets, Accounts, Roles, Bindings và các thông tin khác. Mọi thông tin bạn thấy khi chạy lệnh kubectl get đều đến từ Máy chủ ETCD.\nCài đặt - Thủ công Nếu bạn thiết lập cluster từ đầu, bạn sẽ triển khai ETCD bằng cách tự tải xuống các tệp nhị phân ETCD.\nCài đặt các tệp nhị phân và cấu hình ETCD như một dịch vụ trên node master của bạn.\n$ wget -q --https-only \u0026#34;https://github.com/etcd-io/etcd/releases/download/v3.3.11/etcd-v3.3.11-linux-amd64.tar.gz\u0026#34; etcd Cài đặt - Kubeadm Nếu bạn thiết lập cluster sử dụng kubeadm, thì kubeadm sẽ triển khai máy chủ etcd cho bạn dưới dạng một pod trong không gian tên kube-system. $ kubectl get pods -n kube-system etcd1 Khám Phá ETCD Để liệt kê tất cả các khóa được lưu trữ bởi kubernetes, chạy lệnh dưới đây: $ kubectl exec etcd-master -n kube-system -- sh -c \u0026#34;ETCDCTL_API=3 etcdctl --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key --cacert=/etc/kubernetes/pki/etcd/ca.crt get / --prefix --keys-only\u0026#34; Kubernetes lưu trữ dữ liệu trong một cấu trúc thư mục cụ thể, thư mục gốc là registry và dưới đó bạn có các cấu trúc kubernetes khác như minions, nodes, pods, replicasets, deployments, roles, secrets và các thông tin khác. ETCD trong Môi Trường HA (High Availability) Trong một môi trường có khả năng cao sẵn sàng, cluster của bạn sẽ có nhiều node master, sẽ có nhiều thể hiện ETCD được phân bố trên các node master này.\nĐảm bảo các thể hiện ETCD biết về nhau bằng cách thiết lập tham số đúng trong cấu hình etcd.service. Tùy chọn \u0026ndash;initial-cluster nơi bạn cần chỉ định các thể hiện khác nhau của dịch vụ etcd.\n"
},
{
	"uri": "//localhost:1313/vi/3-sample-application/",
	"title": "Ứng dụng mẫu",
	"tags": [],
	"description": "",
	"content": "Chào mừng bạn đến với lab thực hành đầu tiên trong workshop EKS. Mục tiêu của bài tập này là làm quen với ứng dụng mẫu mà chúng ta sẽ sử dụng cho nhiều bài lab tiếp theo và qua đó đề cập đến một số khái niệm cơ bản liên quan đến triển khai workloads trên EKS. Chúng ta sẽ khám phá kiến trúc của ứng dụng và triển khai các thành phần vào cluster EKS của chúng ta.\nHãy triển khai workload đầu tiên của bạn vào cluster EKS trong môi trường lab của bạn và khám phá!\nTrước khi chúng ta bắt đầu, chúng ta cần chạy lệnh sau để chuẩn bị môi trường Cloud9 và cluster EKS của chúng ta:\n$ prepare-environment introduction/getting-started Lệnh này làm gì? Đối với lab này, nó sao chép kho Git Workshop EKS vào môi trường Cloud9 để các tệp Kubernetes Manifest cần thiết tồn tại trên hệ thống tệp.\nBạn sẽ thấy trong các lab tiếp theo, chúng ta cũng sẽ chạy lệnh này, nơi nó sẽ thực hiện hai chức năng quan trọng bổ sung:\nThiết lập lại cluster EKS về trạng thái ban đầu của nó Cài đặt các thành phần bổ sung cần thiết vào cluster cho bài lab tiếp theo Sử Dụng Ứng Dụng Mẫu Trong AWS và Kubernetes Đa số các lab trong workshop này sử dụng một ứng dụng mẫu chung để cung cấp các thành phần container thực tế mà chúng ta có thể làm việc trong suốt các bài tập. Ứng dụng mẫu mô hình một ứng dụng cửa hàng web đơn giản, nơi khách hàng có thể duyệt một danh mục, thêm các mặt hàng vào giỏ hàng của họ và hoàn tất một đơn hàng thông qua quá trình thanh toán.\nỨng dụng có một số thành phần và phụ thuộc:\nThành Phần Mô Tả UI Cung cấp giao diện người dùng phía trước và tổng hợp cuộc gọi API đến các dịch vụ khác nhau. Catalog API cho việc liệt kê và chi tiết sản phẩm Cart API cho giỏ hàng mua sắm của khách hàng Checkout API để điều phối quá trình thanh toán Orders API để nhận và xử lý đơn hàng của khách hàng Static assets Cung cấp tài nguyên tĩnh như hình ảnh liên quan đến danh mục sản phẩm Ban đầu, chúng ta sẽ triển khai ứng dụng một cách độc lập trong cụm Amazon EKS, mà không sử dụng bất kỳ dịch vụ AWS nào như cân bằng tải hoặc cơ sở dữ liệu được quản lý. Trong suốt các lab, chúng ta sẽ tận dụng các tính năng khác nhau của EKS để tận dụng các dịch vụ và tính năng của AWS rộng lớn hơn cho cửa hàng bán lẻ của chúng ta.\nBạn có thể tìm mã nguồn đầy đủ cho ứng dụng mẫu trên GitHub.\n"
},
{
	"uri": "//localhost:1313/vi/4-packaging-the-components/",
	"title": "Các thành phần",
	"tags": [],
	"description": "",
	"content": "Các thành phần Trước khi một công việc có thể được triển khai lên một bản phân phối Kubernetes như EKS, nó trước tiên phải được đóng gói như một hình ảnh container và xuất bản vào một registry container. Các chủ đề cơ bản về container như này không được bao gồm trong phần workshop này, và ứng dụng mẫu đã có các hình ảnh container sẵn có trong Amazon Elastic Container Registry cho các lab mà chúng ta sẽ hoàn thành hôm nay.\nBảng dưới đây cung cấp các liên kết đến kho chứa công cộng ECR cho mỗi thành phần, cũng như Dockerfile đã được sử dụng để xây dựng từng thành phần.\nComponent ECR Public repository Dockerfile UI Repository Dockerfile Catalog Repository Dockerfile Shopping cart Repository Dockerfile Checkout Repository Dockerfile Orders Repository Dockerfile Assets Repository Dockerfile "
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.4-kube-api-server/",
	"title": "Kube API Server",
	"tags": [],
	"description": "",
	"content": "Kube API Server Kube-apiserver là thành phần chính trong Kubernetes. Kube-apiserver chịu trách nhiệm xác thực, kiểm tra yêu cầu, truy xuất và cập nhật dữ liệu trong cửa hàng khóa-giá trị ETCD. Thực tế, kube-apiserver là thành phần duy nhất tương tác trực tiếp với cơ sở dữ liệu etcd. Các thành phần khác như kube-scheduler, kube-controller-manager và kubelet sử dụng API-Server để cập nhật trong cụm ở các lĩnh vực tương ứng của họ.\nCài đặt kube-apiserver Nếu bạn đang khởi động kube-apiserver sử dụng công cụ kubeadm, thì bạn không cần phải biết điều này, nhưng nếu bạn đang thiết lập theo cách thủ công, thì kube-apiserver có sẵn dưới dạng một tệp nhị phân trên trang phát hành Kubernetes. Ví dụ: Bạn có thể tải xuống nhị phân kube-apiserver v1.13.0 tại đây:\n$ wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-apiserver Xem kube-apiserver - Kubeadm Kubeadm triển khai kube-apiserver dưới dạng một pod trong namespace kube-system trên node master. $ kubectl get pods -n kube-system Xem các tùy chọn của kube-apiserver - Kubeadm Bạn có thể xem các tùy chọn trong tệp định nghĩa pod tại /etc/kubernetes/manifests/kube-apiserver.yaml $ cat /etc/kubernetes/manifests/kube-apiserver.yaml Xem các tùy chọn của kube-apiserver - Cách thủ công Trong một cài đặt không sử dụng kubeadm, bạn có thể kiểm tra các tùy chọn bằng cách xem dịch vụ kube-apiserver.service $ cat /etc/systemd/system/kube-apiserver.service Bạn cũng có thể xem quá trình đang chạy và các tùy chọn hiệu quả bằng cách liệt kê quá trình trên node master và tìm kiếm kube-apiserver $ ps -aux | grep kube-apiserver Tài liệu tham khảo K8s: Kube API Server Command Line Tools Reference Kubernetes Components Overview Kubernetes API Overview Accessing Kubernetes Cluster Accessing Kubernetes Cluster API "
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.5-kube-controller-manager/",
	"title": "Kube Controller Manager",
	"tags": [],
	"description": "",
	"content": "Kube Controller Manager Trình quản lý bộ điều khiển Kube (Kube Controller Manager) quản lý các bộ điều khiển khác nhau trong Kubernetes. Trong thuật ngữ của Kubernetes, một bộ điều khiển là một quá trình liên tục theo dõi trạng thái của các thành phần bên trong hệ thống và làm việc nhằm đưa toàn bộ hệ thống về trạng thái hoạt động mong muốn. Bộ Điều Khiển Nút (Node Controller) Chịu trách nhiệm giám sát trạng thái của các Nút (Nodes) và thực hiện các hành động cần thiết để duy trì ứng dụng hoạt động. Bộ Điều Khiển Sao Chép (Replication Controller) Chịu trách nhiệm theo dõi trạng thái của các replica sets và đảm bảo số lượng pods mong muốn luôn sẵn có trong bộ. Cài Đặt Trình Quản Lý Bộ Điều Khiển Kube (Kube-Controller-Manager) Khi bạn cài đặt kube-controller-manager, các bộ điều khiển khác nhau cũng sẽ được cài đặt. Tải xuống nhị phân kube-controller-manager từ trang phát hành Kubernetes. Ví dụ: Bạn có thể tải xuống kube-controller-manager v1.13.0 tại đây kube-controller-manager $ wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-controller-manager Mặc định, tất cả các bộ điều khiển đều được bật, nhưng bạn có thể chọn bật một số bộ điều khiển cụ thể từ kube-controller-manager.service\n$ cat /etc/systemd/system/kube-controller-manager.service Xem kube-controller-manager - kubeadm Kubeadm triển khai kube-controller-manager dưới dạng một pod trong namespace kube-system $ kubectl get pods -n kube-system Xem các tùy chọn kube-controller-manager - kubeadm Bạn có thể xem các tùy chọn trong pod tại /etc/kubernetes/manifests/kube-controller-manager.yaml $ cat /etc/kubernetes/manifests/kube-controller-manager.yaml Xem các tùy chọn kube-controller-manager - Thủ công Trong cài đặt không phải kubeadm, bạn có thể kiểm tra các tùy chọn bằng cách xem kube-controller-manager.service $ cat /etc/systemd/system/kube-controller-manager.service Bạn cũng có thể xem quá trình đang chạy và các tùy chọn hiệu quả bằng cách liệt kê quá trình trên nút master và tìm kiếm kube-controller-manager. $ ps -aux | grep kube-controller-manager Tài Liệu Tham Khảo K8s: Kubernetes Command Line Tools Reference - kube-controller-manager Kubernetes Concepts Overview - Components "
},
{
	"uri": "//localhost:1313/vi/5-microservices-on-kubernetes/",
	"title": "Microservices trên Kubernetes",
	"tags": [],
	"description": "",
	"content": "Microservices trên Kubernetes Bây giờ khi chúng ta đã quen với kiến trúc tổng quan của ứng dụng mẫu, chúng ta sẽ bắt đầu triển khai vào EKS như thế nào? Hãy khám phá một số khối dựng Kubernetes bằng cách xem component catalog:\nCó một số điều cần xem xét trong biểu đồ này:\nỨng dụng cung cấp catalog API chạy như một Pod, đây là đơn vị triển khai nhỏ nhất trong Kubernetes. Các Application Pods sẽ chạy các container images mà chúng ta đã trình bày trong phần trước đó. Các Pods chạy catalog component được tạo bởi một Deployment có thể quản lý một hoặc nhiều \u0026ldquo;bản sao\u0026rdquo; của catalog Pod, cho phép nó mở rộng theo chiều ngang. Một Service là một cách trừu tượng để tiết lộ một ứng dụng đang chạy dưới dạng một tập hợp các Pods, và điều này cho phép catalog API của chúng ta được gọi bởi các components khác bên trong Kubernetes cluster. Mỗi Service đều có một mục nhập DNS riêng. Chúng ta bắt đầu workshop này với một cơ sở dữ liệu MySQL chạy bên trong Kubernetes cluster của chúng tôi dưới dạng một StatefulSet, được thiết kế để quản lý các stateful workloads. Tất cả các Kubernetes constructs này được nhóm lại trong Namespace catalog riêng của chúng. Mỗi application component đều có Namespace riêng của nó. Mỗi trong số các components trong kiến trúc microservices là một cách khái niệm tương tự catalog, sử dụng Deployments để quản lý application workload Pods và Services để định tuyến lưu lượng đến các Pods đó. Nếu chúng ta mở rộng tầm nhìn của mình về kiến trúc, chúng ta có thể xem xét cách lưu lượng được định tuyến trong toàn hệ thống rộng lớn hơn:\nComponent ui nhận yêu cầu HTTP từ, ví dụ, trình duyệt của người dùng. Sau đó, nó thực hiện các yêu cầu HTTP đến các API components khác trong kiến trúc để thực hiện yêu cầu đó và trả về một phản hồi cho người dùng. Mỗi trong số các downstream components có thể có data stores hoặc cơ sở hạ tầng khác của riêng mình. Namespaces là một nhóm logic của các resources cho mỗi microservice và cũng hoạt động như một ranh giới cách ly mềm, có thể được sử dụng để triển khai hiệu quả các điều khiển sử dụng Kubernetes RBAC và Network Policies.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.6-kube-scheduler/",
	"title": "Kube Scheduler",
	"tags": [],
	"description": "",
	"content": "Kube Scheduler kube-scheduler là gì? kube-scheduler chịu trách nhiệm lên lịch cho các pod trên các node. kube-scheduler chỉ quyết định pod nào sẽ được đặt trên node nào. Nó không thực sự đặt pod lên các node, đó là công việc của kubelet. Tại sao bạn cần một Bộ lập lịch (Scheduler)? kube-scheduler đóng vai trò quan trọng trong việc quản lý tài nguyên và đảm bảo rằng các pod được phân bổ một cách hiệu quả trên các node. Cài đặt kube-scheduler - Thủ công Để tải xuống nhị phân kube-scheduler từ các trang phát hành của Kubernetes, bạn có thể thực hiện như sau. Ví dụ: Để tải xuống kube-scheduler v1.13.0, hãy chạy lệnh dưới đây. $ wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-scheduler Sau đó, giải nén và chạy nó như một dịch vụ. Xem các tùy chọn của kube-scheduler - kubeadm Nếu bạn thiết lập nó bằng công cụ kubeadm, công cụ này sẽ triển khai kube-scheduler dưới dạng pod trong namespace kube-system trên node master. $ kubectl get pods -n kube-system Bạn có thể xem các tùy chọn cho kube-scheduler trong tệp định nghĩa pod tại /etc/kubernetes/manifests/kube-scheduler.yaml. $ cat /etc/kubernetes/manifests/kube-scheduler.yaml Bạn cũng có thể xem quy trình đang chạy và các tùy chọn hiệu quả bằng cách liệt kê quy trình trên node master và tìm kiếm kube-scheduler. $ ps -aux | grep kube-scheduler Tài liệu tham khảo K8s: Tài liệu tham khảo dòng lệnh kube-scheduler Scheduling và Eviction với kube-scheduler Các thành phần tổng quan Cấu hình nhiều bộ lập lịch "
},
{
	"uri": "//localhost:1313/vi/6-deploying-our-first-component/",
	"title": "Triển khai",
	"tags": [],
	"description": "",
	"content": "Triển khai Ứng dụng mẫu Ứng dụng mẫu được tạo thành từ một tập hợp các tuyên bố Kubernetes được tổ chức một cách dễ dàng áp dụng bằng Kustomize. Kustomize là một công cụ mã nguồn mở cũng được cung cấp như một tính năng gốc của CLI kubectl. Hội thảo này sử dụng Kustomize để áp dụng các thay đổi vào các tuyên bố Kubernetes, giúp việc hiểu các thay đổi đối với các tệp tuyên bố mà không cần phải chỉnh sửa YAML thủ công. Khi chúng ta làm việc qua các module khác nhau của hội thảo này, chúng ta sẽ áp dụng các overlay và patch một cách từ từ bằng Kustomize.\nCách dễ nhất để duyệt các tuyên bố YAML cho ứng dụng mẫu và các module trong hội thảo này là sử dụng trình duyệt tệp trong Cloud9:\nMở rộng các mục eks-workshop và sau đó base-application sẽ cho phép bạn duyệt các tuyên bố tạo thành trạng thái ban đầu của ứng dụng mẫu:\nCấu trúc bao gồm một thư mục cho mỗi thành phần ứng dụng được mô tả trong phần Ứng dụng mẫu.\nThư mục modules chứa các bộ tuyên bố mà chúng ta sẽ áp dụng vào cụm trong các bài tập thực hành lab sau:\nTrước khi làm bất kỳ điều gì, hãy kiểm tra các Namespaces hiện tại trong cụm EKS của chúng ta:\n$ kubectl get namespaces NAME STATUS AGE default Active 1h kube-node-lease Active 1h kube-public Active 1h kube-system Active 1h Tất cả các mục liệt kê là Namespaces cho các thành phần hệ thống đã được cài đặt sẵn cho chúng ta. Chúng ta sẽ bỏ qua chúng bằng cách sử dụng nhãn Kubernetes để lọc các Namespaces chỉ xuống các Namespaces mà chúng ta đã tạo:\n$ kubectl get namespaces -l app.kubernetes.io/created-by=eks-workshop No resources found Điều đầu tiên chúng ta sẽ làm là triển khai thành phần catalog một mình. Các tuyên bố cho thành phần này có thể được tìm thấy trong ~/environment/eks-workshop/base-application/catalog.\n$ ls ~/environment/eks-workshop/base-application/catalog configMap.yaml deployment.yaml kustomization.yaml namespace.yaml secrets.yaml service-mysql.yaml service.yaml serviceAccount.yaml statefulset-mysql.yaml Các tuyên bố này bao gồm Deployment cho API catalog:\nmanifests/base-application/catalog/deployment.yaml Deployment này diễn đạt trạng thái mong muốn của thành phần API catalog:\nSử dụng hình ảnh container public.ecr.aws/aws-containers/retail-store-sample-catalog Chạy một bản sao duy nhất Tiếp tục container trên cổng 8080 có tên là http Chạy probes/healthchecks chống lại đường dẫn /health Requests một lượng CPU và bộ nhớ cụ thể để lập lịch Kubernetes có thể đặt nó trên một nút với đủ tài nguyên khả dụng Áp dụng các nhãn cho các Pod để các tài nguyên khác có thể tham chiếu đến chúng Các tuyên bố cũng bao gồm Service được sử dụng bởi các thành phần khác để truy cập API catalog:\nmanifests/base-application/catalog/service.yaml Service này:\nLựa chọn các Pod catalog bằng cách sử dụng các nhãn phù hợp với những gì chúng ta đã diễn đạt trong Deployment ở trên Mở bản thân trên cổng 80 Chỉ định cổng http được mở bởi Deployment, đồng nghĩa với cổng 8080 Hãy tạo thành phần catalog:\n$ kubectl apply -k ~/environment/eks-workshop/base-application/catalog namespace/catalog created serviceaccount/catalog created configmap/catalog created secret/catalog-db created service/catalog created service/catalog-mysql created deployment.apps/catalog created statefulset.apps/catalog-mysql created Bây giờ chúng ta sẽ thấy một Namespace mới:\n$ kubectl get namespaces -l app.kubernetes.io/created-by=eks-workshop NAME STATUS AGE catalog Active 15s Chúng ta có thể xem các Pod đang chạy trong namespace này:\n$ kubectl get pod -n catalog NAME READY STATUS RESTARTS AGE catalog-846479dcdd-fznf5 1/1 Running 2 (43s ago) 46s catalog-mysql-0 1/1 Running 0 46 Bạn đã hoàn thành việc triển khai thành phần catalog thành công.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.7-kubelet/",
	"title": "Kubelet",
	"tags": [],
	"description": "",
	"content": "Kubelet Kubelet là một trong những thành phần quan trọng của Kubernetes. Nó chịu trách nhiệm quản lý và duy trì các container chạy trên mỗi node trong cụm Kubernetes.\nMặc định, Kubeadm không triển khai Kubelet. Bạn cần phải tự tải về và cài đặt nó.\nĐể cài đặt Kubelet, bạn có thể tải file nhị phân từ trang phát hành Kubernetes tại đây. Ví dụ: Để tải về Kubelet v1.13.0, sử dụng lệnh sau.\n$ wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubelet Sau khi tải xuống, giải nén file và chạy nó như một dịch vụ.\nĐể xem các tùy chọn của Kubelet và quá trình đang chạy, bạn có thể sử dụng lệnh sau trên node worker:\n$ ps -aux | grep kubelet Tài liệu tham khảo Kubernetes: Command Line Tools Reference - Kubelet Overview Components Kubeadm Kubelet Integration "
},
{
	"uri": "//localhost:1313/vi/7-other-components/",
	"title": "Thành phần khác",
	"tags": [],
	"description": "",
	"content": "Trong bài thực hành này, chúng ta sẽ triển khai phần còn lại của ứng dụng mẫu một cách hiệu quả bằng cách sử dụng sức mạnh của Kustomize. File kustomization sau đây cho thấy cách bạn có thể tham chiếu đến các kustomizations khác và triển khai nhiều thành phần cùng nhau:\nmanifests/base-application/kustomization.yaml Lưu ý rằng API danh mục nằm trong kustomization này, chúng ta đã triển khai nó chưa?\nBởi vì Kubernetes sử dụng cơ chế khai báo, chúng ta có thể áp dụng các manifests cho API danh mục một lần nữa và mong đợi rằng vì tất cả các tài nguyên đã được tạo ra, Kubernetes sẽ không thực hiện bất kỳ hành động nào.\nÁp dụng kustomization này vào cluster của chúng ta để triển khai các thành phần còn lại:\n$ kubectl apply -k ~/environment/eks-workshop/base-application Sau khi hoàn thành điều này, chúng ta có thể sử dụng kubectl wait để đảm bảo rằng tất cả các thành phần đã được bắt đầu trước khi chúng ta tiếp tục:\n$ kubectl wait --for=condition=Ready --timeout=180s pods \\ -l app.kubernetes.io/created-by=eks-workshop -A Bây giờ chúng ta sẽ có một Namespace cho mỗi thành phần ứng dụng của chúng ta:\n$ kubectl get namespaces -l app.kubernetes.io/created-by=eks-workshop NAME STATUS AGE assets Active 62s carts Active 62s catalog Active 7m17s checkout Active 62s orders Active 62s other Active 62s rabbitmq Active 62s ui Active 62s Chúng ta cũng có thể thấy tất cả các Deployments được tạo ra cho các thành phần:\n$ kubectl get deployment -l app.kubernetes.io/created-by=eks-workshop -A NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE assets assets 1/1 1 1 90s carts carts 1/1 1 1 90s carts carts-dynamodb 1/1 1 1 90s catalog catalog 1/1 1 1 7m46s checkout checkout 1/1 1 1 90s checkout checkout-redis 1/1 1 1 90s orders orders 1/1 1 1 90s orders orders-mysql 1/1 1 1 90s ui ui 1/1 1 1 90s Ứng dụng mẫu hiện đã được triển khai và sẵn sàng cung cấp một nền tảng cho chúng ta để sử dụng trong các bài thực hành khác trong workshop này!\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.8-kube-proxy/",
	"title": "Kube Proxy",
	"tags": [],
	"description": "",
	"content": "Kube Proxy Trong cụm Kubernetes, mỗi pod có thể kết nối với mọi pod khác, điều này được thực hiện bằng cách triển khai một cụm mạng pod vào cụm.\nKube-Proxy là một quy trình chạy trên mỗi node trong cụm Kubernetes.\nCài đặt kube-proxy - Thủ công Tải xuống tệp nhị phân kube-proxy từ trang phát hành Kubernetes tại đây. Ví dụ: Để tải về kube-proxy v1.13.0, chạy lệnh dưới đây. $ wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-proxy Giải nén và chạy nó như một dịch vụ. Xem các tùy chọn kube-proxy - kubeadm Nếu bạn thiết lập nó với công cụ kubeadm, công cụ kubeadm sẽ triển khai kube-proxy dưới dạng pod trong không gian tên kube-system. Thực tế, nó được triển khai dưới dạng một daemonset trên node chủ. $ kubectl get pods -n kube-system Đó là một phần quan trọng trong việc quản lý cụm Kubernetes và đảm bảo sự kết nối mạng chính xác giữa các pod trong cụm.\n"
},
{
	"uri": "//localhost:1313/vi/8-kustomize-optional/",
	"title": "Kustomize (tùy chọn)",
	"tags": [],
	"description": "",
	"content": "Kustomize (tùy chọn) Kustomize cho phép bạn quản lý các tệp mẫu Kubernetes bằng cách sử dụng các tệp \u0026ldquo;kustomization\u0026rdquo; bằng cách khai báo. Nó cung cấp khả năng diễn đạt các tài nguyên Kubernetes \u0026ldquo;cơ bản\u0026rdquo; cho tài nguyên Kubernetes của bạn và sau đó áp dụng các thay đổi bằng cách sử dụng sự hợp thành, tùy chỉnh và dễ dàng thực hiện các thay đổi chéo qua nhiều tài nguyên.\nVí dụ, hãy xem tệp mẫu sau cho checkout Deployment:\nmanifests/base-application/checkout/deployment.yaml Tệp này đã được áp dụng trong bài lab Getting Started trước đó, nhưng giả sử chúng ta muốn mở rộng thành phần này theo chiều ngang bằng cách cập nhật trường replicas sử dụng Kustomize. Thay vì cập nhật tệp YAML này thủ công, chúng ta sẽ sử dụng Kustomize để cập nhật trường spec/replicas từ 1 thành 3.\nĐể làm điều này, chúng ta sẽ áp dụng kustomization sau.\nTab đầu tiên hiển thị kustomization chúng ta đang áp dụng Tab thứ hai hiển thị một bản xem trước về cách tệp Deployment/checkout được cập nhật sau khi kustomization được áp dụng Cuối cùng, tab thứ ba chỉ hiển thị sự khác biệt của những thay đổi đã xảy ra modules/introduction/kustomize/deployment.yaml\rDeployment/checkout Bạn có thể tạo ra YAML Kubernetes cuối cùng áp dụng kustomization này bằng lệnh kubectl kustomize, mà gọi kustomize được gói kèm với CLI kubectl:\n$ kubectl kustomize ~/environment/eks-workshop/modules/introduction/kustomize Điều này sẽ tạo ra nhiều tệp YAML, đại diện cho các tài nguyên cuối cùng bạn có thể áp dụng trực tiếp vào Kubernetes. Hãy minh họa điều này bằng cách chuyển dữ liệu đầu ra từ kustomize trực tiếp sang kubectl apply:\n$ kubectl kustomize ~/environment/eks-workshop/modules/introduction/kustomize | kubectl apply -f - namespace/checkout unchanged serviceaccount/checkout unchanged configmap/checkout unchanged service/checkout unchanged service/checkout-redis unchanged deployment.apps/checkout configured deployment.apps/checkout-redis unchanged Bạn sẽ nhận thấy một số tài nguyên liên quan đến checkout \u0026ldquo;unchanged\u0026rdquo;, với deployment.apps/checkout được \u0026ldquo;cấu hình\u0026rdquo;. Điều này là có chủ ý — chúng ta chỉ muốn áp dụng các thay đổi vào deployment của checkout. Điều này xảy ra vì lệnh trước đó thực sự áp dụng hai tệp: deployment.yaml của Kustomize mà chúng ta đã thấy ở trên, cũng như tệp kustomization.yaml sau đây khớp với tất cả các tệp trong thư mục ~/environment/eks-workshop/base-application/checkout. Trường patches chỉ định tệp cụ thể cần được vá:\nmanifests/modules/introduction/kustomize/kustomization.yaml Để kiểm tra xem số bản sao đã được cập nhật, chạy lệnh sau:\n$ kubectl get pod -n checkout -l app.kubernetes.io/component=service NAME READY STATUS RESTARTS AGE checkout-585c9b45c7-c456l 1/1 Running 0 2m12s checkout-585c9b45c7-b2rrz 1/1 Running 0 2m12s checkout-585c9b45c7-xmx2t 1/1 Running 0 40m Thay vì sử dụng sự kết hợp của kubectl kustomize và kubectl apply, chúng ta có thể thực hiện cùng một việc với kubectl apply -k \u0026lt;thư_mục_kustomization\u0026gt; (chú ý cờ -k thay vì -f). Phương pháp này được sử dụng trong khóa học này để làm cho việc áp dụng các thay đổi vào các tệp mẫu dễ dàng hơn, trong khi rõ ràng hiển thị các thay đổi cần được áp dụng.\nHãy thử:\n$ kubectl apply -k ~/environment/eks-workshop/modules/introduction/kustomize Để đặt lại các tệp mẫu ứng dụng về trạng thái ban đầu của chúng, bạn có thể đơn giản áp dụng bộ tệp mẫu ban đầu:\n$ kubectl apply -k ~/environment/eks-workshop/base-application Mẫu khác bạn sẽ thấy được sử dụng trong một số bài lab có dạng như sau:\n$ kubectl kustomize ~/environment/eks-workshop/base-application \\ | envsubst | kubectl apply -f- Điều này sử dụng envsubst để thay thế các nơi giữ chỗ biến môi trường trong các tệp mẫu Kubernetes bằng các giá trị thực tế dựa trên môi trường cụ thể của bạn. Ví dụ trong một số tệp mẫu, chúng ta cần tham chiếu đến tên cụm EKS với $EKS_CLUSTER_NAME hoặc khu vực AWS với $AWS_REGION.\nBây giờ bạn đã hiểu cách Kustomize hoạt động, tiến hành module Cơ bản.\nĐể tìm hiểu thêm về Kustomize, bạn có thể tham khảo tài liệu chính thức của Kubernetes.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.9-pods/",
	"title": "Pods",
	"tags": [],
	"description": "",
	"content": "Pods Trong hệ thống Kubernetes, Pods là một khái niệm quan trọng. Kubernetes không triển khai trực tiếp các container lên node làm việc (worker node). Thay vào đó, Kubernetes sử dụng Pods để quản lý các container.\nMỗi Pod trong Kubernetes đều chứa một hoặc nhiều container, nhưng thông thường chúng chứa một container đơn, và đó là thể hiện của ứng dụng bạn đang chạy. Pod sẽ có mối quan hệ một-một với các container chạy ứng dụng của bạn.\nPod Đa-Container Một Pod có thể chứa nhiều container, mặc dù thường không phải là nhiều container cùng một loại.\nCách triển khai Pods? Bây giờ, hãy xem cách tạo một Pod nginx sử dụng kubectl.\nĐể triển khai một container Docker bằng cách tạo một Pod, bạn có thể sử dụng lệnh sau:\n$ kubectl run nginx --image nginx Để lấy danh sách các Pods, bạn có thể sử dụng lệnh:\n$ kubectl get pods Tài liệu tham khảo Kubernetes: Kubernetes - Pod Kubernetes - Pod Overview Kubernetes - Explore Introduction "
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]