[
{
	"uri": "/vi/3-compute/3.1-cluster-autoscaler/",
	"title": "Cluster Autoscaler",
	"tags": [],
	"description": "",
	"content": "Cluster Autoscaler Chuẩn bị môi trường cho phần này:\n$ prepare-environment autoscaling/compute/cluster-autoscaler Điều này sẽ thực hiện các thay đổi sau vào môi trường lab của bạn:\nCài đặt Kubernetes Cluster Autoscaler trong cụm Amazon EKS. Trong bài lab này, chúng ta sẽ tìm hiểu về Kubernetes Cluster Autoscaler, một thành phần tự động điều chỉnh kích thước của một Cụm Kubernetes để tất cả các pod có nơi để chạy mà không cần thiết phải có các nút không cần thiết. Cluster Autoscaler là một công cụ tuyệt vời để đảm bảo rằng cơ sở hạ tầng cụm dưới lying là linh hoạt, có thể mở rộng và có thể đáp ứng các yêu cầu thay đổi của công việc.\nKubernetes Cluster Autoscaler tự động điều chỉnh kích thước của một cụm Kubernetes khi một trong các điều kiện sau là đúng:\nCó các pod không thể chạy trong một cụm do tài nguyên không đủ. Có các nút trong một cụm không được sử dụng hiệu quả trong một khoảng thời gian kéo dài và các pod của chúng có thể được đặt trên các nút hiện có khác. Cluster Autoscaler cho AWS cung cấp tích hợp với các nhóm Tự động Mở rộng.\nTrong bài lab này, chúng ta sẽ áp dụng Cluster Autoscaler vào cụm EKS của chúng ta và xem nó hoạt động như thế nào khi chúng ta mở rộng công việc của mình.\n"
},
{
	"uri": "/vi/3-compute/3.2-karpenter/3.2.1-configure-karpenter/",
	"title": "Configure Karpenter",
	"tags": [],
	"description": "",
	"content": "Configure Karpenter Triển khai Karpenter trên Cluster EKS và Cấu Hình IAM Trong dự án của chúng tôi, chúng tôi đã triển khai thành công Karpenter trên cluster EKS và chạy dưới dạng một deployment. Dưới đây là thông tin về trạng thái của deployment:\n$ kubectl get deployment -n karpenter NAME READY UP-TO-DATE AVAILABLE AGE karpenter 2/2 2 2 105s Việc duy nhất chúng ta cần thực hiện là cập nhật các ánh xạ IAM của EKS để cho phép các node của Karpenter tham gia vào cluster:\n$ eksctl create iamidentitymapping --cluster $EKS_CLUSTER_NAME \\ --region $AWS_REGION --arn $KARP_ARN \\ --group system:bootstrappers --group system:nodes \\ --username system:node:{{EC2PrivateDNSName}} Qua đó, chúng ta đã cài đặt và cấu hình Karpenter thành công trên cluster EKS của mình. Điều này sẽ giúp tự động hóa việc quản lý tài nguyên và tăng khả năng mở rộng của hệ thống.\n"
},
{
	"uri": "/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu Tự động mở rộng giám sát các khối công việc của bạn và tự động điều chỉnh dung lượng để duy trì hiệu suất ổn định, dự đoán được đồng thời tối ưu hóa chi phí. Khi sử dụng Kubernetes, có hai cơ chế chính có liên quan mà có thể được sử dụng để tự động mở rộng:\nCompute (Tính toán): Khi các pods được mở rộng, tính toán cơ bản trong một cụm Kubernetes cũng phải thích ứng bằng cách điều chỉnh số lượng hoặc kích thước của các nút worker được sử dụng để chạy các Pods. Pods: Vì các pods được sử dụng để chạy các khối công việc trong một cụm Kubernetes, việc mở rộng một khối công việc chủ yếu được thực hiện bằng cách mở rộng Pods theo chiều ngang hoặc theo chiều dọc để phản ứng với các tình huống như thay đổi tải trên một ứng dụng cụ thể. Trong chương này, chúng ta sẽ khám phá các cơ chế khác nhau có sẵn để tự động mở rộng cả số lượng pods và khả năng tính toán của một cụm.\n"
},
{
	"uri": "/vi/3-compute/3.1-cluster-autoscaler/3.1.1-scale-with-ca/",
	"title": "Scale with CA",
	"tags": [],
	"description": "",
	"content": "Triển khai Cluster Autoscaler trên Amazon EKS Trong khóa thực hành này, chúng ta đã cài đặt thành phần Cluster Autoscaler vào trong cụm EKS của chúng ta như một phần của việc chuẩn bị cho bài lab này. Nó chạy như một deployment trong namespace kube-system:\n$ kubectl get deployment -n kube-system cluster-autoscaler-aws-cluster-autoscaler Trong bài lab này, chúng ta sẽ cập nhật tất cả các thành phần ứng dụng để tăng số lượng replica lên 4. Điều này sẽ làm tăng việc sử dụng tài nguyên hơn so với những gì có sẵn trong một cụm, kích hoạt việc cung cấp thêm tài nguyên tính toán.\nmanifests/modules/autoscaling/compute/cluster-autoscaler/deployment.yaml Hãy áp dụng điều này vào cụm của chúng ta:\n$ kubectl apply -k ~/environment/eks-workshop/modules/autoscaling/compute/cluster-autoscaler Một số pod sẽ ở trạng thái Pending, điều này kích hoạt cluster-autoscaler để mở rộng fllet EC2.\n$ kubectl get pods -n orders -o wide --watch Xem nhật ký của cluster-autoscaler\n$ kubectl -n kube-system logs \\ -f deployment/cluster-autoscaler-aws-cluster-autoscaler Kiểm tra EC2 AWS Management Console để xác nhận rằng các nhóm Auto Scaling đang mở rộng để đáp ứng nhu cầu. Điều này có thể mất vài phút. Bạn cũng có thể theo dõi quá trình triển khai pod từ dòng lệnh. Bạn sẽ thấy các pod chuyển từ trạng thái pending sang running khi các node được mở rộng.\nHoặc bạn có thể sử dụng kubectl:\n$ kubectl get nodes -l workshop-default=yes NAME STATUS ROLES AGE VERSION ip-10-42-10-159.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 3d vVAR::KUBERNETES_NODE_VERSION ip-10-42-11-143.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 3d vVAR::KUBERNETES_NODE_VERSION ip-10-42-11-81.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 3d vVAR::KUBERNETES_NODE_VERSION ip-10-42-12-152.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 3m11s vVAR::KUBERNETES_NODE_VERSION Lưu ý: VAR::KUBERNETES_NODE_VERSION là biến dùng để đại diện cho phiên bản Kubernetes của node.\n"
},
{
	"uri": "/vi/",
	"title": "Tự Động Mở Rộng trên AWS với Kubernetes",
	"tags": [],
	"description": "",
	"content": "Tự Động Mở Rộng trên AWS với Kubernetes Tự động mở rộng giám sát các khối công việc của bạn và tự động điều chỉnh dung lượng để duy trì hiệu suất ổn định, dự đoán được đồng thời tối ưu hóa chi phí. Khi sử dụng Kubernetes, có hai cơ chế chính có liên quan mà có thể được sử dụng để tự động mở rộng:\nCompute (Tính toán): Khi các pods được mở rộng, tính toán cơ bản trong một cụm Kubernetes cũng phải thích ứng bằng cách điều chỉnh số lượng hoặc kích thước của các nút worker được sử dụng để chạy các Pods. Pods: Vì các pods được sử dụng để chạy các khối công việc trong một cụm Kubernetes, việc mở rộng một khối công việc chủ yếu được thực hiện bằng cách mở rộng Pods theo chiều ngang hoặc theo chiều dọc để phản ứng với các tình huống như thay đổi tải trên một ứng dụng cụ thể. Trong chương này, chúng ta sẽ khám phá các cơ chế khác nhau có sẵn để tự động mở rộng cả số lượng pods và khả năng tính toán của một cụm.\n"
},
{
	"uri": "/vi/2-prerequiste/",
	"title": "Các Bước Chuẩn Bị",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/vi/3-compute/3.1-cluster-autoscaler/3.1.2-cluster-over-provisioning/",
	"title": "Cluster Over-Provisioning",
	"tags": [],
	"description": "",
	"content": "Cluster Over-Provisioning Cluster Autoscaler (CA) cho AWS cấu hình nhóm tự động mở rộng EC2 (ASG) của EKS node group để tự động mở rộng các node trong cụm khi có các pod đang chờ được lên lịch.\nQuá trình này của việc thêm các node vào một cụm bằng cách sửa đổi ASG ngầm hiện thêm thời gian phụ trước khi các pod có thể được lên lịch. Ví dụ, trong phần trước đó, bạn đã nhận thấy rằng mất vài phút trước khi các pod được tạo ra khi ứng dụng được mở rộng trở nên có sẵn.\nCó nhiều cách tiếp cận để giải quyết vấn đề này. Bài tập thực hành này giải quyết vấn đề này bằng cách \u0026ldquo;thừa cấp\u0026rdquo; cụm với các node phụ cấp thêm chạy các pod ưu tiên thấp được sử dụng như các vị trí giữ chỗ. Các pod ưu tiên thấp này sẽ bị loại bỏ khi các pod ứng dụng quan trọng được triển khai. Các pod trống không chỉ đảm bảo rằng các tài nguyên CPU và bộ nhớ được dành trước mà còn đảm bảo rằng các địa chỉ IP được gán từ CNI AWS VPC Container Network Interface.\n"
},
{
	"uri": "/vi/3-compute/3.2-karpenter/",
	"title": "Karpenter",
	"tags": [],
	"description": "",
	"content": "Karpenter Chuẩn bị môi trường cho phần này:\n$ prepare-environment autoscaling/compute/karpenter Điều này sẽ thực hiện những thay đổi sau vào môi trường thí nghiệm của bạn:\nCài đặt Karpenter trong cụm Amazon EKS Trong phần thực hành này, chúng ta sẽ tìm hiểu về Karpenter, một dự án tự động co giãn mã nguồn mở được xây dựng cho Kubernetes. Karpenter được thiết kế để cung cấp tài nguyên máy tính phù hợp với nhu cầu của ứng dụng của bạn trong vài giây, không phải vài phút, bằng cách quan sát các yêu cầu tài nguyên tổng hợp của các pod không thể lập lịch và đưa ra quyết định để khởi chạy và kết thúc các nút để giảm thiểu độ trễ lập lịch.\nMục tiêu của Karpenter là cải thiện hiệu suất và chi phí của việc chạy các khối công việc trên các cụm Kubernetes. Karpenter hoạt động bằng cách:\nTheo dõi các pod mà lập lịch Kubernetes đã đánh dấu là không thể lập lịch Đánh giá các ràng buộc lập lịch (yêu cầu tài nguyên, nodeselectors, affinities, tolerations, và topology spread constraints) được yêu cầu bởi các pod Cung cấp các nút đáp ứng các yêu cầu của các pod Lập lịch các pod để chạy trên các nút mới Loại bỏ các nút khi các nút không còn cần thiết nữa "
},
{
	"uri": "/vi/3-compute/3.1-cluster-autoscaler/3.1.3-how-it-works/",
	"title": "Cách hoạt động",
	"tags": [],
	"description": "",
	"content": "Trong Kubernetes, Pods có thể được gán ưu tiên so với các Pods khác. Lập lịch Kubernetes sẽ sử dụng điều này để ưu tiên Pods khác có ưu tiên thấp hơn để phù hợp với các Pods có ưu tiên cao hơn. PriorityClass là tài nguyên với các giá trị ưu tiên được tạo ra và gán cho Pods, và một PriorityClass mặc định có thể được gán cho một namespace.\nDưới đây là một ví dụ về một lớp ưu tiên cho phép một Pod có ưu tiên cao hơn so với các Pods khác:\napiVersion: scheduling.k8s.io/v1 kind: PriorityClass metadata: name: high-priority value: 1000 globalDefault: false description: \u0026#34;Lớp ưu tiên được sử dụng cho các Pods có ưu tiên cao.\u0026#34; Dưới đây là một ví dụ về đặc tả Pod sử dụng lớp ưu tiên ở trên:\napiVersion: v1 kind: Pod metadata: name: nginx labels: env: test spec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent priorityClassName: high-priority # Đặc tả Lớp Ưu Tiên được chỉ định Tài liệu cho Ưu Tiên và Sự Ưu Tiên Của Pods giải thích cách hoạt động này chi tiết.\nLàm thế nào chúng ta có thể áp dụng điều này để thực hiện việc tăng cường tài nguyên trong cụm EKS của chúng ta?\nMột lớp ưu tiên với giá trị ưu tiên “-1\u0026quot; được tạo ra và gán cho Pods Pause Container trống. Các container \u0026ldquo;pause\u0026rdquo; trống hoạt động như các vị trí trống.\nMột lớp ưu tiên mặc định được tạo ra với giá trị ưu tiên “0”. Điều này được gán toàn cầu cho một cụm, vì vậy bất kỳ triển khai nào không có lớp ưu tiên sẽ được gán lớp ưu tiên mặc định này.\nKhi một công việc thực sự được lập lịch, các container trống sẽ bị loại bỏ và các Pods ứng dụng sẽ được cung cấp ngay lập tức.\nKhi có các Pods Pending (Pause Container) trong cụm của chúng ta, Cluster Autoscaler sẽ bắt đầu và cung cấp thêm các nút làm việc Kubernetes dựa trên cấu hình ASG (--max-size) được liên kết với nhóm nút EKS.\nMức độ tăng cường cần thiết có thể được kiểm soát bằng cách:\nSố lượng Pause Pods (replicas) với các yêu cầu tài nguyên CPU và bộ nhớ cần thiết Số lượng tối đa các nút trong nhóm nút EKS (maxsize) "
},
{
	"uri": "/vi/3-compute/",
	"title": "Compute",
	"tags": [],
	"description": "",
	"content": "Compute Trong Kubernetes, một trong những khía cạnh đầu tiên mà chúng ta muốn đảm bảo tự động điều chỉnh là cơ sở hạ tầng tính toán EC2 được sử dụng để chạy các pods của chúng ta. Điều này sẽ điều chỉnh số lượng các instance EC2 có sẵn cho cụm EKS như là các worker nodes một cách linh hoạt khi các pods được thêm hoặc loại bỏ.\nCó nhiều cách để triển khai tự động điều chỉnh quy mô tính toán trong Kubernetes, và tại AWS có hai cơ chế chính được sử dụng:\nCông cụ Kubernetes Cluster Autoscaler Karpenter Trong chương này, chúng ta sẽ khám phá các cách khác nhau để đạt được tự động điều chỉnh quy mô tính toán trong Kubernetes trên AWS bằng cách sử dụng công cụ Kubernetes Cluster Autoscaler và cơ chế Karpenter.\n"
},
{
	"uri": "/vi/3-compute/3.1-cluster-autoscaler/3.1.4-setting-up/",
	"title": "Cách hoạt động",
	"tags": [],
	"description": "",
	"content": "Tạo PriorityClass cho Ứng dụng trên AWS và Kubernetes Tạo Default PriorityClass Toàn cầu Trong quy trình tốt nhất, việc tạo PriorityClass phù hợp cho các ứng dụng của bạn được coi là quan trọng. Bây giờ, chúng ta sẽ tạo một default PriorityClass toàn cầu bằng cách sử dụng trường globalDefault:true. PriorityClass mặc định này sẽ được gán cho các pod/deployment không chỉ định PriorityClassName.\nmanifests/modules/autoscaling/compute/overprovisioning/setup/priorityclass-default.yaml Tạo PriorityClass cho Pause Pods Chúng ta cũng sẽ tạo PriorityClass sẽ được gán cho các pause pod được sử dụng cho việc over-provisioning với giá trị ưu tiên -1.\nmanifests/modules/autoscaling/compute/overprovisioning/setup/priorityclass-pause.yaml Các pause pod đảm bảo rằng có đủ node sẵn có dựa trên mức over-provisioning cần thiết cho môi trường của bạn. Hãy nhớ đến tham số —max-size trong ASG (của nhóm node EKS). Cluster Autoscaler sẽ không tăng số lượng node vượt quá giới hạn tối đa được chỉ định trong ASG này.\nmanifests/modules/autoscaling/compute/overprovisioning/setup/deployment-pause.yaml Trong trường hợp này, chúng ta sẽ lên lịch cho một pause pod duy nhất yêu cầu 7Gi bộ nhớ, điều này có nghĩa là nó sẽ tiêu thụ gần như một toàn bộ instance m5.large. Điều này sẽ dẫn đến việc luôn có 2 node \u0026ldquo;dư\u0026rdquo; sẵn có.\nÁp dụng cập nhật cho cluster của bạn $ kubectl apply -k ~/environment/eks-workshop/modules/autoscaling/compute/overprovisioning/setup priorityclass.scheduling.k8s.io/default created priorityclass.scheduling.k8s.io/pause-pods created deployment.apps/pause-pods created $ kubectl rollout status -n other deployment/pause-pods --timeout 300s Khi quá trình này hoàn thành, các pause pods sẽ được chạy:\n$ kubectl get pods -n other NAME READY STATUS RESTARTS AGE pause-pods-7f7669b6d7-v27sl 1/1 Running 0 5m6s pause-pods-7f7669b6d7-v7hqv 1/1 Running 0 5m6s Và chúng ta có thể thấy các node bổ sung đã được cung cấp bởi CA:\n$ kubectl get nodes -l workshop-default=yes NAME STATUS ROLES AGE VERSION ip-10-42-10-159.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 3d vVAR::KUBERNETES_NODE_VERSION ip-10-42-10-111.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 33s vVAR::KUBERNETES_NODE_VERSION ip-10-42-10-133.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 33s vVAR::KUBERNETES_NODE_VERSION ip-10-42-11-143.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 3d vVAR::KUBERNETES_NODE_VERSION ip-10-42-11-81.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 3d vVAR::KUBERNETES_NODE_VERSION ip-10-42-12-152.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 3m11s vVAR::KUBERNETES_NODE_VERSION Hai node này không chạy bất kỳ workloads nào ngoại trừ các pause pods của chúng tôi, những pods này sẽ bị trục xuất khi workloads \u0026ldquo;thực sự\u0026rdquo; được lên lịch.\n"
},
{
	"uri": "/vi/3-compute/3.1-cluster-autoscaler/3.1.5-scaling-further/",
	"title": "Cách hoạt động",
	"tags": [],
	"description": "",
	"content": "Trong bài thực hành này, chúng ta sẽ mở rộng kiến trúc ứng dụng của mình hơn so với phần CA và xem xét sự khác biệt về khả năng phản hồi.\nmanifests/modules/autoscaling/compute/overprovisioning/scale/deployment.yaml Áp dụng các cập nhật vào cluster của bạn:\n$ kubectl apply -k ~/environment/eks-workshop/modules/autoscaling/compute/overprovisioning/scale $ kubectl wait --for=condition=Ready --timeout=180s pods -l app.kubernetes.io/created-by=eks-workshop -A Khi các pod mới triển khai, cuối cùng sẽ có một xung đột nơi các pod tạm dừng đang tiêu thụ tài nguyên mà các dịch vụ công việc có thể sử dụng. Do cấu hình ưu tiên của chúng tôi, pod tạm dừng sẽ bị đẩy ra để cho phép các pod công việc bắt đầu. Điều này sẽ để lại một số hoặc tất cả các pod tạm dừng ở trạng thái Pending:\n$ kubectl get pod -n other -l run=pause-pods NAME READY STATUS RESTARTS AGE pause-pods-5556d545f7-2pt9g 0/1 Pending 0 16m pause-pods-5556d545f7-k5vj7 0/1 Pending 0 16m Điều này sẽ cho phép các pod công việc của chúng tôi chuyển đổi sang trạng thái ContainerCreating và Running nhanh hơn.\n"
},
{
	"uri": "/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]